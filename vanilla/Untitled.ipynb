{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_PAD = b\"_PAD\"\n",
    "_GO = b\"_GO\"\n",
    "_EOS = b\"_EOS\"\n",
    "_UNK = b\"_UNK\"\n",
    "_START_VOCAB = [_PAD, _GO, _EOS, _UNK]\n",
    "\n",
    "PAD_ID = 0\n",
    "GO_ID = 1\n",
    "EOS_ID = 2\n",
    "UNK_ID = 3\n",
    "\n",
    "_WORD_SPLIT = re.compile(\"([.,!?\\\"':;)(])\")\n",
    "_DIGIT_RE = re.compile(R\"\\d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_tokenizer(sentence):\n",
    "    \"\"\" Split sentence into list of tokens \"\"\"\n",
    "    words = []\n",
    "    for space_separated_item in sentence.strip().split():\n",
    "        words.extend(_WORD_SPLIT.split(space_separated_item))\n",
    "    return [w for w in words if w] # if w removes the \"\"\n",
    "\n",
    "def get_vocab(tokenized, max_vocab_size):\n",
    "    \"\"\"\n",
    "    Get vocab_list, vocab_dict and rev_vocab_dict given the\n",
    "    tokenized sentences.\n",
    "    \"\"\"\n",
    "    # Replace word count\n",
    "    vocab = {}\n",
    "    for sentence in tokenized:\n",
    "        for word in sentence:\n",
    "            if word in vocab:\n",
    "                vocab[word] += 1\n",
    "            else:\n",
    "                vocab[word] = 1\n",
    "    vocab_list = _START_VOCAB + sorted(vocab, key=vocab.get, reverse=True)\n",
    "    if len(vocab_list) > max_vocab_size:\n",
    "        vocab_list = vocab_list[:max_vocab_size]\n",
    "\n",
    "    # Get vocab dict (word -> token) and rev dict (token -> word)\n",
    "    vocab_dict = dict([(x,y) for (y,x) in enumerate(vocab_list)])\n",
    "    rev_vocab_dict = {v: k for k, v in vocab_dict.items()}\n",
    "\n",
    "    return vocab_list, vocab_dict, rev_vocab_dict\n",
    "\n",
    "def sentence_to_token_ids(sentence, vocab_dict, target_lang,\n",
    "    normalize_digits=True):\n",
    "    \"\"\"\n",
    "    Convert a single sentence of words to token ids. If it is the target\n",
    "    language, we will append an EOS token to the end.\n",
    "    \"\"\"\n",
    "    if not normalize_digits:\n",
    "        # replace words not in vocab_dict with UNK_ID\n",
    "        tokens = [vocab_dict.get(w, UNK_ID) for w in sentence]\n",
    "    else:\n",
    "        tokens = [vocab_dict.get(_DIGIT_RE.sub(b\"0\", w), UNK_ID)\n",
    "            for w in sentence]\n",
    "\n",
    "    # Append EOS token if target langauge sentence\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def data_to_token_ids(tokenized, vocab_dict, max_seq_len, normalize_digits=True):\n",
    "    \"\"\"\n",
    "    Convert tokens into ids used vocab_dict and normalize all digits\n",
    "    to 0.\n",
    "    \"\"\"\n",
    "    data_as_tokens = []\n",
    "    seq_lens = []\n",
    "    #max_len = max(len(sentence) for sentence in tokenized) + 1 # +1 for EOS\n",
    "    max_len=max_seq_len+1\n",
    "    for sentence in tokenized:\n",
    "        sentence=sentence[:max_seq_len]\n",
    "        token_ids = sentence_to_token_ids(sentence, vocab_dict, normalize_digits)\n",
    "        # Padding\n",
    "        data_as_tokens.append(token_ids + [PAD_ID]*(max_len - len(token_ids)))\n",
    "        # Store original sequence length\n",
    "        seq_lens.append(len(token_ids))\n",
    "\n",
    "    return np.array(data_as_tokens), np.array(seq_lens)\n",
    "\n",
    "def process_data(datafile, max_vocab_size,max_seq_len):\n",
    "    \"\"\"\n",
    "    Read the sentences from our datafiles.\n",
    "    \"\"\"\n",
    "    with open(datafile, 'rb') as f:\n",
    "        sentences = pickle.load(f)\n",
    "\n",
    "    # Split into tokens\n",
    "    tokenized = []\n",
    "    for i in range(len(sentences)):\n",
    "        tokenized.append(basic_tokenizer(sentences[i]))\n",
    "\n",
    "    # Get vocab information\n",
    "    vocab_list, vocab_dict, rev_vocab_dict = get_vocab(tokenized,\n",
    "        max_vocab_size)\n",
    "\n",
    "    # Convert data to token ids\n",
    "    data_as_tokens, seq_lens = data_to_token_ids(tokenized, vocab_dict, max_seq_len,normalize_digits=True)\n",
    "\n",
    "    return data_as_tokens, seq_lens, vocab_dict, rev_vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tar_token_ids, tar_seq_lens, tar_vocab_dict, tar_rev_vocab_dict = \\\n",
    "        process_data('original.p', max_vocab_size=8000,max_seq_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_token_ids = np.zeros(tar_token_ids.shape,dtype=np.int)\n",
    "src_seq_lens=tar_seq_lens.copy()\n",
    "\n",
    "for x in range(tar_token_ids.shape[0]):\n",
    "    for y in range(0, tar_token_ids.shape[1]):\n",
    "        if tar_token_ids[x, y]==tar_vocab_dict[\"a\"] or tar_token_ids[x, y]==tar_vocab_dict[\"the\"]:\n",
    "            src_token_ids[x,y]=tar_vocab_dict[\"a\"] if random.random()<0.5 else tar_vocab_dict[\"the\"]\n",
    "        else:\n",
    "            src_token_ids[x,y]=tar_token_ids[x,y]\n",
    "    tar_token_ids[x,tar_seq_lens[x]]=EOS_ID\n",
    "    tar_seq_lens[x]+=1\n",
    "src_vocab_dict, src_rev_vocab_dict=tar_vocab_dict, tar_rev_vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example source sequence\n",
      "[[   3  102  872 3057   14    6  725  483    4   33   27  170 1471   19\n",
      "    92   36 2766    9    3   45 5324    4    8    9   33   17   92 5906\n",
      "    63    3  269    4   72   42   66 7409  689    9  194    3    4  106\n",
      "    53  267   44    9 7626    4   11  490    0]\n",
      " [ 528   11  151   81  136   19   18 4357   62   40  471   10 1524    8\n",
      "   760    4   37    6  571 1118    4   19  503    6  347   10 1083  796\n",
      "   348    6  196   68    3    9  534  107  269   32   49   12   14   33\n",
      "   630   19   42 1249   76  101 2351   16    0]\n",
      " [1581   17  118   39  754    9 5818   16    6  128  868   14    6  490\n",
      "     4   42   14  564   11  194 2537    8 6853 1205   16  108 1551    3\n",
      "    11 1593  128    4   17   82  300    9  132   16   14   40  699 2356\n",
      "     4   19   18    6  377  354   27   34    0]]\n",
      "\n",
      "\n",
      "Example target sequence\n",
      "[[   3  102  872 3057   14   11  725  483    4   33   27  170 1471   19\n",
      "    92   36 2766    9    3   45 5324    4    8    9   33   17   92 5906\n",
      "    63    3  269    4   72   42   66 7409  689    9  194    3    4  106\n",
      "    53  267   44    9 7626    4   11  490    2]\n",
      " [ 528   11  151   81  136   19   18 4357   62   40  471   10 1524    8\n",
      "   760    4   37    6  571 1118    4   19  503   11  347   10 1083  796\n",
      "   348    6  196   68    3    9  534  107  269   32   49   12   14   33\n",
      "   630   19   42 1249   76  101 2351   16    2]\n",
      " [1581   17  118   39  754    9 5818   16    6  128  868   14   11  490\n",
      "     4   42   14  564    6  194 2537    8 6853 1205   16  108 1551    3\n",
      "    11 1593  128    4   17   82  300    9  132   16   14   40  699 2356\n",
      "     4   19   18    6  377  354   27   34    2]]\n",
      "(9129, 51)\n"
     ]
    }
   ],
   "source": [
    "source_letter_ids=src_token_ids\n",
    "target_letter_ids=tar_token_ids\n",
    "source_letter_to_int=src_vocab_dict\n",
    "target_letter_to_int=tar_vocab_dict\n",
    "source_int_to_letter=src_rev_vocab_dict\n",
    "target_int_to_letter=tar_rev_vocab_dict   \n",
    "\n",
    "print(\"Example source sequence\")\n",
    "print(source_letter_ids[:3])\n",
    "print(\"\\n\")\n",
    "print(\"Example target sequence\")\n",
    "print(target_letter_ids[:3])\n",
    "\n",
    "print(source_letter_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_length = max(\n",
    "        [len(sentence) for sentence in source_letter_ids] + [len(sentence) for sentence in target_letter_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.2.0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "epochs = 100\n",
    "# Batch Size\n",
    "batch_size = 128\n",
    "# RNN Size\n",
    "rnn_size = 100\n",
    "# Number of Layers\n",
    "num_layers = 2\n",
    "# Embedding Size\n",
    "encoding_embedding_size = 200\n",
    "decoding_embedding_size = 200\n",
    "# Learning Rate\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_inputs():\n",
    "    input_data = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "    target_sequence_length = tf.placeholder(tf.int32, (None,), name='target_sequence_length')\n",
    "    max_target_sequence_length = tf.reduce_max(target_sequence_length, name='max_target_len')\n",
    "    source_sequence_length = tf.placeholder(tf.int32, (None,), name='source_sequence_length')\n",
    "    \n",
    "    return input_data, targets, lr, target_sequence_length, max_target_sequence_length, source_sequence_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoding_layer(input_data, rnn_size, num_layers,\n",
    "                   source_sequence_length, source_vocab_size, \n",
    "                   encoding_embedding_size):\n",
    "\n",
    "\n",
    "    # Encoder embedding\n",
    "    enc_embed_input = tf.contrib.layers.embed_sequence(input_data, source_vocab_size, encoding_embedding_size)\n",
    "\n",
    "    # RNN cell\n",
    "    def make_cell(rnn_size):\n",
    "        enc_cell = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "        return enc_cell\n",
    "\n",
    "    enc_cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size) for _ in range(num_layers)])\n",
    "    \n",
    "    enc_output, enc_state = tf.nn.dynamic_rnn(enc_cell, enc_embed_input, sequence_length=source_sequence_length, dtype=tf.float32)\n",
    "    \n",
    "    return enc_output, enc_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the input we'll feed to the decoder\n",
    "def process_decoder_input(target_data, vocab_to_int, batch_size):\n",
    "    '''Remove the last word id from each batch and concat the <GO> to the begining of each batch'''\n",
    "    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int[_GO]), ending], 1)\n",
    "\n",
    "    return dec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer(target_letter_to_int, decoding_embedding_size, num_layers, rnn_size,\n",
    "                   target_sequence_length, max_target_sequence_length, enc_state, dec_input):\n",
    "    # 1. Decoder Embedding\n",
    "    target_vocab_size = len(target_letter_to_int)\n",
    "    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "\n",
    "    # 2. Construct the decoder cell\n",
    "    def make_cell(rnn_size):\n",
    "        dec_cell = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "        return dec_cell\n",
    "\n",
    "    dec_cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size) for _ in range(num_layers)])\n",
    "     \n",
    "    # 3. Dense layer to translate the decoder's output at each time \n",
    "    # step into a choice from the target vocabulary\n",
    "    output_layer = Dense(target_vocab_size,\n",
    "                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "\n",
    "\n",
    "    # 4. Set up a training decoder and an inference decoder\n",
    "    # Training Decoder\n",
    "    with tf.variable_scope(\"decode\"):\n",
    "\n",
    "        # Helper for the training process. Used by BasicDecoder to read inputs.\n",
    "        training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input,\n",
    "                                                            sequence_length=target_sequence_length,\n",
    "                                                            time_major=False)\n",
    "        \n",
    "        \n",
    "        # Basic decoder\n",
    "        training_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                           training_helper,\n",
    "                                                           enc_state,\n",
    "                                                           output_layer) \n",
    "        \n",
    "        # Perform dynamic decoding using the decoder\n",
    "        training_decoder_output = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                                                       impute_finished=True,\n",
    "                                                                       maximum_iterations=max_target_sequence_length)[0]\n",
    "    # 5. Inference Decoder\n",
    "    # Reuses the same parameters trained by the training process\n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        start_tokens = tf.tile(tf.constant([target_letter_to_int[_GO]], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "\n",
    "        # Helper for the inference process.\n",
    "        inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embeddings,\n",
    "                                                                start_tokens,\n",
    "                                                                target_letter_to_int[_EOS])\n",
    "\n",
    "        # Basic decoder\n",
    "        inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                        inference_helper,\n",
    "                                                        enc_state,\n",
    "                                                        output_layer)\n",
    "        \n",
    "        # Perform dynamic decoding using the decoder\n",
    "        inference_decoder_output = tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                                            impute_finished=True,\n",
    "                                                            maximum_iterations=max_target_sequence_length)[0]\n",
    "         \n",
    "\n",
    "    \n",
    "    return training_decoder_output, inference_decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, targets, lr, target_sequence_length, \n",
    "                  max_target_sequence_length, source_sequence_length,\n",
    "                  source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size, \n",
    "                  rnn_size, num_layers):\n",
    "    \n",
    "    # Pass the input data through the encoder. We'll ignore the encoder output, but use the state\n",
    "    _, enc_state = encoding_layer(input_data, \n",
    "                                  rnn_size, \n",
    "                                  num_layers, \n",
    "                                  source_sequence_length,\n",
    "                                  source_vocab_size, \n",
    "                                  encoding_embedding_size)\n",
    "    \n",
    "    \n",
    "    # Prepare the target sequences we'll feed to the decoder in training mode\n",
    "    dec_input = process_decoder_input(targets, target_letter_to_int, batch_size)\n",
    "    \n",
    "    # Pass encoder state and decoder inputs to the decoders\n",
    "    training_decoder_output, inference_decoder_output = decoding_layer(target_letter_to_int, \n",
    "                                                                       decoding_embedding_size, \n",
    "                                                                       num_layers, \n",
    "                                                                       rnn_size,\n",
    "                                                                       target_sequence_length,\n",
    "                                                                       max_target_sequence_length,\n",
    "                                                                       enc_state, \n",
    "                                                                       dec_input) \n",
    "    \n",
    "    return training_decoder_output, inference_decoder_output\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "train_graph = tf.Graph()\n",
    "# Set the graph to default to ensure that it is ready for training\n",
    "with train_graph.as_default():\n",
    "    \n",
    "    # Load the model inputs    \n",
    "    input_data, targets, lr, target_sequence_length, max_target_sequence_length, source_sequence_length = get_model_inputs()\n",
    "    \n",
    "    # Create the training and inference logits\n",
    "    training_decoder_output, inference_decoder_output = seq2seq_model(input_data, \n",
    "                                                                      targets, \n",
    "                                                                      lr, \n",
    "                                                                      target_sequence_length, \n",
    "                                                                      max_target_sequence_length, \n",
    "                                                                      source_sequence_length,\n",
    "                                                                      len(source_letter_to_int),\n",
    "                                                                      len(target_letter_to_int),\n",
    "                                                                      encoding_embedding_size, \n",
    "                                                                      decoding_embedding_size, \n",
    "                                                                      rnn_size, \n",
    "                                                                      num_layers)    \n",
    "    \n",
    "    # Create tensors for the training logits and inference logits\n",
    "    training_logits = tf.identity(training_decoder_output.rnn_output, 'logits')\n",
    "    inference_logits = tf.identity(inference_decoder_output.sample_id, name='predictions')\n",
    "    \n",
    "    # Create the weights for sequence_loss\n",
    "    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        \n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(targets, sources, batch_size):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(sources)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "           \n",
    "        yield targets_batch, sources_batch, [51]*len(sources_batch), [51]*len(targets_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100 Batch    1/70 - Loss:  8.617  - Validation loss:  8.291\n",
      "Epoch   1/100 Batch    2/70 - Loss:  8.286  - Validation loss:  8.014\n",
      "Epoch   1/100 Batch    3/70 - Loss:  7.957  - Validation loss:  7.751\n",
      "Epoch   1/100 Batch    4/70 - Loss:  7.734  - Validation loss:  7.502\n",
      "Epoch   1/100 Batch    5/70 - Loss:  7.355  - Validation loss:  7.263\n",
      "Epoch   1/100 Batch    6/70 - Loss:  7.115  - Validation loss:  7.031\n",
      "Epoch   1/100 Batch    7/70 - Loss:  7.115  - Validation loss:  6.805\n",
      "Epoch   1/100 Batch    8/70 - Loss:  6.412  - Validation loss:  6.585\n",
      "Epoch   1/100 Batch    9/70 - Loss:  6.616  - Validation loss:  6.368\n",
      "Epoch   1/100 Batch   10/70 - Loss:  6.052  - Validation loss:  6.154\n",
      "Epoch   1/100 Batch   11/70 - Loss:  5.610  - Validation loss:  5.940\n",
      "Epoch   1/100 Batch   12/70 - Loss:  5.683  - Validation loss:  5.725\n",
      "Epoch   1/100 Batch   13/70 - Loss:  5.546  - Validation loss:  5.512\n",
      "Epoch   1/100 Batch   14/70 - Loss:  5.306  - Validation loss:  5.301\n",
      "Epoch   1/100 Batch   15/70 - Loss:  4.978  - Validation loss:  5.095\n",
      "Epoch   1/100 Batch   16/70 - Loss:  4.892  - Validation loss:  4.896\n",
      "Epoch   1/100 Batch   17/70 - Loss:  4.331  - Validation loss:  4.707\n",
      "Epoch   1/100 Batch   18/70 - Loss:  4.334  - Validation loss:  4.531\n",
      "Epoch   1/100 Batch   19/70 - Loss:  4.372  - Validation loss:  4.369\n",
      "Epoch   1/100 Batch   20/70 - Loss:  4.137  - Validation loss:  4.222\n",
      "Epoch   1/100 Batch   21/70 - Loss:  4.298  - Validation loss:  4.094\n",
      "Epoch   1/100 Batch   22/70 - Loss:  3.515  - Validation loss:  3.983\n",
      "Epoch   1/100 Batch   23/70 - Loss:  3.149  - Validation loss:  3.888\n",
      "Epoch   1/100 Batch   24/70 - Loss:  3.248  - Validation loss:  3.807\n",
      "Epoch   1/100 Batch   25/70 - Loss:  4.012  - Validation loss:  3.738\n",
      "Epoch   1/100 Batch   26/70 - Loss:  3.402  - Validation loss:  3.678\n",
      "Epoch   1/100 Batch   27/70 - Loss:  3.204  - Validation loss:  3.625\n",
      "Epoch   1/100 Batch   28/70 - Loss:  3.530  - Validation loss:  3.578\n",
      "Epoch   1/100 Batch   29/70 - Loss:  3.179  - Validation loss:  3.541\n",
      "Epoch   1/100 Batch   30/70 - Loss:  2.939  - Validation loss:  3.510\n",
      "Epoch   1/100 Batch   31/70 - Loss:  2.973  - Validation loss:  3.484\n",
      "Epoch   1/100 Batch   32/70 - Loss:  2.969  - Validation loss:  3.462\n",
      "Epoch   1/100 Batch   33/70 - Loss:  3.074  - Validation loss:  3.442\n",
      "Epoch   1/100 Batch   34/70 - Loss:  3.207  - Validation loss:  3.422\n",
      "Epoch   1/100 Batch   35/70 - Loss:  3.425  - Validation loss:  3.400\n",
      "Epoch   1/100 Batch   36/70 - Loss:  3.360  - Validation loss:  3.381\n",
      "Epoch   1/100 Batch   37/70 - Loss:  3.095  - Validation loss:  3.366\n",
      "Epoch   1/100 Batch   38/70 - Loss:  2.877  - Validation loss:  3.353\n",
      "Epoch   1/100 Batch   39/70 - Loss:  2.673  - Validation loss:  3.341\n",
      "Epoch   1/100 Batch   40/70 - Loss:  3.541  - Validation loss:  3.328\n",
      "Epoch   1/100 Batch   41/70 - Loss:  3.325  - Validation loss:  3.317\n",
      "Epoch   1/100 Batch   42/70 - Loss:  3.416  - Validation loss:  3.306\n",
      "Epoch   1/100 Batch   43/70 - Loss:  3.569  - Validation loss:  3.295\n",
      "Epoch   1/100 Batch   44/70 - Loss:  3.226  - Validation loss:  3.285\n",
      "Epoch   1/100 Batch   45/70 - Loss:  3.064  - Validation loss:  3.276\n",
      "Epoch   1/100 Batch   46/70 - Loss:  2.956  - Validation loss:  3.266\n",
      "Epoch   1/100 Batch   47/70 - Loss:  2.708  - Validation loss:  3.256\n",
      "Epoch   1/100 Batch   48/70 - Loss:  3.054  - Validation loss:  3.248\n",
      "Epoch   1/100 Batch   49/70 - Loss:  2.963  - Validation loss:  3.241\n",
      "Epoch   1/100 Batch   50/70 - Loss:  2.800  - Validation loss:  3.236\n",
      "Epoch   1/100 Batch   51/70 - Loss:  3.169  - Validation loss:  3.232\n",
      "Epoch   1/100 Batch   52/70 - Loss:  3.494  - Validation loss:  3.224\n",
      "Epoch   1/100 Batch   53/70 - Loss:  3.033  - Validation loss:  3.217\n",
      "Epoch   1/100 Batch   54/70 - Loss:  2.003  - Validation loss:  3.214\n",
      "Epoch   1/100 Batch   55/70 - Loss:  2.410  - Validation loss:  3.222\n",
      "Epoch   1/100 Batch   56/70 - Loss:  2.942  - Validation loss:  3.205\n",
      "Epoch   1/100 Batch   57/70 - Loss:  2.171  - Validation loss:  3.201\n",
      "Epoch   1/100 Batch   58/70 - Loss:  2.356  - Validation loss:  3.198\n",
      "Epoch   1/100 Batch   59/70 - Loss:  3.020  - Validation loss:  3.193\n",
      "Epoch   1/100 Batch   60/70 - Loss:  2.304  - Validation loss:  3.194\n",
      "Epoch   1/100 Batch   61/70 - Loss:  2.311  - Validation loss:  3.189\n",
      "Epoch   1/100 Batch   62/70 - Loss:  3.187  - Validation loss:  3.173\n",
      "Epoch   1/100 Batch   63/70 - Loss:  2.992  - Validation loss:  3.164\n",
      "Epoch   1/100 Batch   64/70 - Loss:  2.896  - Validation loss:  3.153\n",
      "Epoch   1/100 Batch   65/70 - Loss:  2.908  - Validation loss:  3.140\n",
      "Epoch   1/100 Batch   66/70 - Loss:  3.483  - Validation loss:  3.122\n",
      "Epoch   1/100 Batch   67/70 - Loss:  2.952  - Validation loss:  3.097\n",
      "Epoch   1/100 Batch   68/70 - Loss:  3.113  - Validation loss:  3.082\n",
      "Epoch   1/100 Batch   69/70 - Loss:  2.489  - Validation loss:  3.094\n",
      "Epoch   2/100 Batch    1/70 - Loss:  3.197  - Validation loss:  3.068\n",
      "Epoch   2/100 Batch    2/70 - Loss:  2.932  - Validation loss:  3.057\n",
      "Epoch   2/100 Batch    3/70 - Loss:  2.796  - Validation loss:  3.015\n",
      "Epoch   2/100 Batch    4/70 - Loss:  2.912  - Validation loss:  3.044\n",
      "Epoch   2/100 Batch    5/70 - Loss:  2.619  - Validation loss:  3.008\n",
      "Epoch   2/100 Batch    6/70 - Loss:  2.595  - Validation loss:  2.981\n",
      "Epoch   2/100 Batch    7/70 - Loss:  3.134  - Validation loss:  2.973\n",
      "Epoch   2/100 Batch    8/70 - Loss:  2.216  - Validation loss:  2.966\n",
      "Epoch   2/100 Batch    9/70 - Loss:  2.989  - Validation loss:  2.965\n",
      "Epoch   2/100 Batch   10/70 - Loss:  2.406  - Validation loss:  2.959\n",
      "Epoch   2/100 Batch   11/70 - Loss:  2.125  - Validation loss:  2.948\n",
      "Epoch   2/100 Batch   12/70 - Loss:  2.531  - Validation loss:  2.939\n",
      "Epoch   2/100 Batch   13/70 - Loss:  2.671  - Validation loss:  2.933\n",
      "Epoch   2/100 Batch   14/70 - Loss:  2.630  - Validation loss:  2.917\n",
      "Epoch   2/100 Batch   15/70 - Loss:  2.442  - Validation loss:  2.909\n",
      "Epoch   2/100 Batch   16/70 - Loss:  2.599  - Validation loss:  2.896\n",
      "Epoch   2/100 Batch   17/70 - Loss:  2.232  - Validation loss:  2.886\n",
      "Epoch   2/100 Batch   18/70 - Loss:  2.428  - Validation loss:  2.883\n",
      "Epoch   2/100 Batch   19/70 - Loss:  2.669  - Validation loss:  2.874\n",
      "Epoch   2/100 Batch   20/70 - Loss:  2.578  - Validation loss:  2.865\n",
      "Epoch   2/100 Batch   21/70 - Loss:  2.905  - Validation loss:  2.859\n",
      "Epoch   2/100 Batch   22/70 - Loss:  2.222  - Validation loss:  2.856\n",
      "Epoch   2/100 Batch   23/70 - Loss:  1.997  - Validation loss:  2.854\n",
      "Epoch   2/100 Batch   24/70 - Loss:  2.215  - Validation loss:  2.853\n",
      "Epoch   2/100 Batch   25/70 - Loss:  3.005  - Validation loss:  2.844\n",
      "Epoch   2/100 Batch   26/70 - Loss:  2.521  - Validation loss:  2.835\n",
      "Epoch   2/100 Batch   27/70 - Loss:  2.389  - Validation loss:  2.836\n",
      "Epoch   2/100 Batch   28/70 - Loss:  2.689  - Validation loss:  2.832\n",
      "Epoch   2/100 Batch   29/70 - Loss:  2.456  - Validation loss:  2.826\n",
      "Epoch   2/100 Batch   30/70 - Loss:  2.252  - Validation loss:  2.832\n",
      "Epoch   2/100 Batch   31/70 - Loss:  2.308  - Validation loss:  2.820\n",
      "Epoch   2/100 Batch   32/70 - Loss:  2.303  - Validation loss:  2.820\n",
      "Epoch   2/100 Batch   33/70 - Loss:  2.461  - Validation loss:  2.812\n",
      "Epoch   2/100 Batch   34/70 - Loss:  2.594  - Validation loss:  2.819\n",
      "Epoch   2/100 Batch   35/70 - Loss:  2.797  - Validation loss:  2.808\n",
      "Epoch   2/100 Batch   36/70 - Loss:  2.732  - Validation loss:  2.804\n",
      "Epoch   2/100 Batch   37/70 - Loss:  2.512  - Validation loss:  2.805\n",
      "Epoch   2/100 Batch   38/70 - Loss:  2.342  - Validation loss:  2.794\n",
      "Epoch   2/100 Batch   39/70 - Loss:  2.131  - Validation loss:  2.792\n",
      "Epoch   2/100 Batch   40/70 - Loss:  2.948  - Validation loss:  2.792\n",
      "Epoch   2/100 Batch   41/70 - Loss:  2.766  - Validation loss:  2.787\n",
      "Epoch   2/100 Batch   42/70 - Loss:  2.875  - Validation loss:  2.789\n",
      "Epoch   2/100 Batch   43/70 - Loss:  3.011  - Validation loss:  2.789\n",
      "Epoch   2/100 Batch   44/70 - Loss:  2.717  - Validation loss:  2.779\n",
      "Epoch   2/100 Batch   45/70 - Loss:  2.563  - Validation loss:  2.780\n",
      "Epoch   2/100 Batch   46/70 - Loss:  2.463  - Validation loss:  2.775\n",
      "Epoch   2/100 Batch   47/70 - Loss:  2.238  - Validation loss:  2.774\n",
      "Epoch   2/100 Batch   48/70 - Loss:  2.564  - Validation loss:  2.772\n",
      "Epoch   2/100 Batch   49/70 - Loss:  2.473  - Validation loss:  2.769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2/100 Batch   50/70 - Loss:  2.337  - Validation loss:  2.770\n",
      "Epoch   2/100 Batch   51/70 - Loss:  2.686  - Validation loss:  2.769\n",
      "Epoch   2/100 Batch   52/70 - Loss:  2.973  - Validation loss:  2.766\n",
      "Epoch   2/100 Batch   53/70 - Loss:  2.567  - Validation loss:  2.774\n",
      "Epoch   2/100 Batch   54/70 - Loss:  1.622  - Validation loss:  2.767\n",
      "Epoch   2/100 Batch   55/70 - Loss:  2.004  - Validation loss:  2.769\n",
      "Epoch   2/100 Batch   56/70 - Loss:  2.492  - Validation loss:  2.768\n",
      "Epoch   2/100 Batch   57/70 - Loss:  1.807  - Validation loss:  2.771\n",
      "Epoch   2/100 Batch   58/70 - Loss:  1.985  - Validation loss:  2.768\n",
      "Epoch   2/100 Batch   59/70 - Loss:  2.598  - Validation loss:  2.764\n",
      "Epoch   2/100 Batch   60/70 - Loss:  1.938  - Validation loss:  2.774\n",
      "Epoch   2/100 Batch   61/70 - Loss:  1.964  - Validation loss:  2.768\n",
      "Epoch   2/100 Batch   62/70 - Loss:  2.764  - Validation loss:  2.767\n",
      "Epoch   2/100 Batch   63/70 - Loss:  2.597  - Validation loss:  2.773\n",
      "Epoch   2/100 Batch   64/70 - Loss:  2.505  - Validation loss:  2.764\n",
      "Epoch   2/100 Batch   65/70 - Loss:  2.506  - Validation loss:  2.766\n",
      "Epoch   2/100 Batch   66/70 - Loss:  3.067  - Validation loss:  2.764\n",
      "Epoch   2/100 Batch   67/70 - Loss:  2.587  - Validation loss:  2.762\n",
      "Epoch   2/100 Batch   68/70 - Loss:  2.756  - Validation loss:  2.764\n",
      "Epoch   2/100 Batch   69/70 - Loss:  2.203  - Validation loss:  2.765\n",
      "Epoch   3/100 Batch    1/70 - Loss:  2.882  - Validation loss:  2.765\n",
      "Epoch   3/100 Batch    2/70 - Loss:  2.627  - Validation loss:  2.759\n",
      "Epoch   3/100 Batch    3/70 - Loss:  2.505  - Validation loss:  2.757\n",
      "Epoch   3/100 Batch    4/70 - Loss:  2.649  - Validation loss:  2.751\n",
      "Epoch   3/100 Batch    5/70 - Loss:  2.325  - Validation loss:  2.749\n",
      "Epoch   3/100 Batch    6/70 - Loss:  2.342  - Validation loss:  2.751\n",
      "Epoch   3/100 Batch    7/70 - Loss:  2.881  - Validation loss:  2.741\n",
      "Epoch   3/100 Batch    8/70 - Loss:  1.975  - Validation loss:  2.744\n",
      "Epoch   3/100 Batch    9/70 - Loss:  2.742  - Validation loss:  2.739\n",
      "Epoch   3/100 Batch   10/70 - Loss:  2.168  - Validation loss:  2.738\n",
      "Epoch   3/100 Batch   11/70 - Loss:  1.894  - Validation loss:  2.738\n",
      "Epoch   3/100 Batch   12/70 - Loss:  2.313  - Validation loss:  2.738\n",
      "Epoch   3/100 Batch   13/70 - Loss:  2.458  - Validation loss:  2.733\n",
      "Epoch   3/100 Batch   14/70 - Loss:  2.418  - Validation loss:  2.734\n",
      "Epoch   3/100 Batch   15/70 - Loss:  2.254  - Validation loss:  2.736\n",
      "Epoch   3/100 Batch   16/70 - Loss:  2.412  - Validation loss:  2.735\n",
      "Epoch   3/100 Batch   17/70 - Loss:  2.067  - Validation loss:  2.742\n",
      "Epoch   3/100 Batch   18/70 - Loss:  2.284  - Validation loss:  2.734\n",
      "Epoch   3/100 Batch   19/70 - Loss:  2.517  - Validation loss:  2.737\n",
      "Epoch   3/100 Batch   20/70 - Loss:  2.432  - Validation loss:  2.729\n",
      "Epoch   3/100 Batch   21/70 - Loss:  2.752  - Validation loss:  2.727\n",
      "Epoch   3/100 Batch   22/70 - Loss:  2.088  - Validation loss:  2.729\n",
      "Epoch   3/100 Batch   23/70 - Loss:  1.870  - Validation loss:  2.725\n",
      "Epoch   3/100 Batch   24/70 - Loss:  2.083  - Validation loss:  2.723\n",
      "Epoch   3/100 Batch   25/70 - Loss:  2.873  - Validation loss:  2.727\n",
      "Epoch   3/100 Batch   26/70 - Loss:  2.387  - Validation loss:  2.724\n",
      "Epoch   3/100 Batch   27/70 - Loss:  2.268  - Validation loss:  2.723\n",
      "Epoch   3/100 Batch   28/70 - Loss:  2.568  - Validation loss:  2.719\n",
      "Epoch   3/100 Batch   29/70 - Loss:  2.333  - Validation loss:  2.715\n",
      "Epoch   3/100 Batch   30/70 - Loss:  2.136  - Validation loss:  2.715\n",
      "Epoch   3/100 Batch   31/70 - Loss:  2.194  - Validation loss:  2.716\n",
      "Epoch   3/100 Batch   32/70 - Loss:  2.200  - Validation loss:  2.711\n",
      "Epoch   3/100 Batch   33/70 - Loss:  2.356  - Validation loss:  2.720\n",
      "Epoch   3/100 Batch   34/70 - Loss:  2.495  - Validation loss:  2.722\n",
      "Epoch   3/100 Batch   35/70 - Loss:  2.685  - Validation loss:  2.714\n",
      "Epoch   3/100 Batch   36/70 - Loss:  2.627  - Validation loss:  2.715\n",
      "Epoch   3/100 Batch   37/70 - Loss:  2.416  - Validation loss:  2.708\n",
      "Epoch   3/100 Batch   38/70 - Loss:  2.239  - Validation loss:  2.709\n",
      "Epoch   3/100 Batch   39/70 - Loss:  2.041  - Validation loss:  2.702\n",
      "Epoch   3/100 Batch   40/70 - Loss:  2.846  - Validation loss:  2.704\n",
      "Epoch   3/100 Batch   41/70 - Loss:  2.667  - Validation loss:  2.709\n",
      "Epoch   3/100 Batch   42/70 - Loss:  2.782  - Validation loss:  2.702\n",
      "Epoch   3/100 Batch   43/70 - Loss:  2.899  - Validation loss:  2.705\n",
      "Epoch   3/100 Batch   44/70 - Loss:  2.626  - Validation loss:  2.702\n",
      "Epoch   3/100 Batch   45/70 - Loss:  2.481  - Validation loss:  2.698\n",
      "Epoch   3/100 Batch   46/70 - Loss:  2.375  - Validation loss:  2.702\n",
      "Epoch   3/100 Batch   47/70 - Loss:  2.164  - Validation loss:  2.693\n",
      "Epoch   3/100 Batch   48/70 - Loss:  2.478  - Validation loss:  2.709\n",
      "Epoch   3/100 Batch   49/70 - Loss:  2.396  - Validation loss:  2.693\n",
      "Epoch   3/100 Batch   50/70 - Loss:  2.256  - Validation loss:  2.698\n",
      "Epoch   3/100 Batch   51/70 - Loss:  2.608  - Validation loss:  2.690\n",
      "Epoch   3/100 Batch   52/70 - Loss:  2.887  - Validation loss:  2.695\n",
      "Epoch   3/100 Batch   53/70 - Loss:  2.486  - Validation loss:  2.691\n",
      "Epoch   3/100 Batch   54/70 - Loss:  1.543  - Validation loss:  2.691\n",
      "Epoch   3/100 Batch   55/70 - Loss:  1.923  - Validation loss:  2.692\n",
      "Epoch   3/100 Batch   56/70 - Loss:  2.405  - Validation loss:  2.692\n",
      "Epoch   3/100 Batch   57/70 - Loss:  1.733  - Validation loss:  2.694\n",
      "Epoch   3/100 Batch   58/70 - Loss:  1.902  - Validation loss:  2.694\n",
      "Epoch   3/100 Batch   59/70 - Loss:  2.510  - Validation loss:  2.695\n",
      "Epoch   3/100 Batch   60/70 - Loss:  1.870  - Validation loss:  2.692\n",
      "Epoch   3/100 Batch   61/70 - Loss:  1.885  - Validation loss:  2.697\n",
      "Epoch   3/100 Batch   62/70 - Loss:  2.685  - Validation loss:  2.701\n",
      "Epoch   3/100 Batch   63/70 - Loss:  2.530  - Validation loss:  2.694\n",
      "Epoch   3/100 Batch   64/70 - Loss:  2.425  - Validation loss:  2.717\n",
      "Epoch   3/100 Batch   65/70 - Loss:  2.449  - Validation loss:  2.695\n",
      "Epoch   3/100 Batch   66/70 - Loss:  2.978  - Validation loss:  2.714\n",
      "Epoch   3/100 Batch   67/70 - Loss:  2.537  - Validation loss:  2.696\n",
      "Epoch   3/100 Batch   68/70 - Loss:  2.682  - Validation loss:  2.712\n",
      "Epoch   3/100 Batch   69/70 - Loss:  2.149  - Validation loss:  2.698\n",
      "Epoch   4/100 Batch    1/70 - Loss:  2.807  - Validation loss:  2.699\n",
      "Epoch   4/100 Batch    2/70 - Loss:  2.560  - Validation loss:  2.692\n",
      "Epoch   4/100 Batch    3/70 - Loss:  2.436  - Validation loss:  2.697\n",
      "Epoch   4/100 Batch    4/70 - Loss:  2.590  - Validation loss:  2.686\n",
      "Epoch   4/100 Batch    5/70 - Loss:  2.257  - Validation loss:  2.697\n",
      "Epoch   4/100 Batch    6/70 - Loss:  2.286  - Validation loss:  2.682\n",
      "Epoch   4/100 Batch    7/70 - Loss:  2.808  - Validation loss:  2.682\n",
      "Epoch   4/100 Batch    8/70 - Loss:  1.914  - Validation loss:  2.683\n",
      "Epoch   4/100 Batch    9/70 - Loss:  2.671  - Validation loss:  2.678\n",
      "Epoch   4/100 Batch   10/70 - Loss:  2.099  - Validation loss:  2.675\n",
      "Epoch   4/100 Batch   11/70 - Loss:  1.832  - Validation loss:  2.675\n",
      "Epoch   4/100 Batch   12/70 - Loss:  2.247  - Validation loss:  2.674\n",
      "Epoch   4/100 Batch   13/70 - Loss:  2.392  - Validation loss:  2.672\n",
      "Epoch   4/100 Batch   14/70 - Loss:  2.353  - Validation loss:  2.673\n",
      "Epoch   4/100 Batch   15/70 - Loss:  2.193  - Validation loss:  2.673\n",
      "Epoch   4/100 Batch   16/70 - Loss:  2.350  - Validation loss:  2.676\n",
      "Epoch   4/100 Batch   17/70 - Loss:  2.002  - Validation loss:  2.674\n",
      "Epoch   4/100 Batch   18/70 - Loss:  2.208  - Validation loss:  2.678\n",
      "Epoch   4/100 Batch   19/70 - Loss:  2.459  - Validation loss:  2.671\n",
      "Epoch   4/100 Batch   20/70 - Loss:  2.365  - Validation loss:  2.680\n",
      "Epoch   4/100 Batch   21/70 - Loss:  2.695  - Validation loss:  2.671\n",
      "Epoch   4/100 Batch   22/70 - Loss:  2.027  - Validation loss:  2.676\n",
      "Epoch   4/100 Batch   23/70 - Loss:  1.821  - Validation loss:  2.671\n",
      "Epoch   4/100 Batch   24/70 - Loss:  2.024  - Validation loss:  2.687\n",
      "Epoch   4/100 Batch   25/70 - Loss:  2.818  - Validation loss:  2.670\n",
      "Epoch   4/100 Batch   26/70 - Loss:  2.331  - Validation loss:  2.672\n",
      "Epoch   4/100 Batch   27/70 - Loss:  2.215  - Validation loss:  2.674\n",
      "Epoch   4/100 Batch   28/70 - Loss:  2.510  - Validation loss:  2.680\n",
      "Epoch   4/100 Batch   29/70 - Loss:  2.284  - Validation loss:  2.670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4/100 Batch   30/70 - Loss:  2.087  - Validation loss:  2.667\n",
      "Epoch   4/100 Batch   31/70 - Loss:  2.136  - Validation loss:  2.670\n",
      "Epoch   4/100 Batch   32/70 - Loss:  2.145  - Validation loss:  2.667\n",
      "Epoch   4/100 Batch   33/70 - Loss:  2.309  - Validation loss:  2.676\n",
      "Epoch   4/100 Batch   34/70 - Loss:  2.443  - Validation loss:  2.663\n",
      "Epoch   4/100 Batch   35/70 - Loss:  2.625  - Validation loss:  2.694\n",
      "Epoch   4/100 Batch   36/70 - Loss:  2.595  - Validation loss:  2.670\n",
      "Epoch   4/100 Batch   37/70 - Loss:  2.361  - Validation loss:  2.681\n",
      "Epoch   4/100 Batch   38/70 - Loss:  2.210  - Validation loss:  2.667\n",
      "Epoch   4/100 Batch   39/70 - Loss:  1.994  - Validation loss:  2.677\n",
      "Epoch   4/100 Batch   40/70 - Loss:  2.807  - Validation loss:  2.679\n",
      "Epoch   4/100 Batch   41/70 - Loss:  2.633  - Validation loss:  2.660\n",
      "Epoch   4/100 Batch   42/70 - Loss:  2.734  - Validation loss:  2.662\n",
      "Epoch   4/100 Batch   43/70 - Loss:  2.854  - Validation loss:  2.667\n",
      "Epoch   4/100 Batch   44/70 - Loss:  2.576  - Validation loss:  2.674\n",
      "Epoch   4/100 Batch   45/70 - Loss:  2.438  - Validation loss:  2.663\n",
      "Epoch   4/100 Batch   46/70 - Loss:  2.328  - Validation loss:  2.654\n",
      "Epoch   4/100 Batch   47/70 - Loss:  2.106  - Validation loss:  2.654\n",
      "Epoch   4/100 Batch   48/70 - Loss:  2.435  - Validation loss:  2.657\n",
      "Epoch   4/100 Batch   49/70 - Loss:  2.343  - Validation loss:  2.659\n",
      "Epoch   4/100 Batch   50/70 - Loss:  2.218  - Validation loss:  2.653\n",
      "Epoch   4/100 Batch   51/70 - Loss:  2.555  - Validation loss:  2.660\n",
      "Epoch   4/100 Batch   52/70 - Loss:  2.846  - Validation loss:  2.661\n",
      "Epoch   4/100 Batch   53/70 - Loss:  2.441  - Validation loss:  2.667\n",
      "Epoch   4/100 Batch   54/70 - Loss:  1.508  - Validation loss:  2.673\n",
      "Epoch   4/100 Batch   55/70 - Loss:  1.890  - Validation loss:  2.659\n",
      "Epoch   4/100 Batch   56/70 - Loss:  2.361  - Validation loss:  2.663\n",
      "Epoch   4/100 Batch   57/70 - Loss:  1.700  - Validation loss:  2.660\n",
      "Epoch   4/100 Batch   58/70 - Loss:  1.865  - Validation loss:  2.666\n",
      "Epoch   4/100 Batch   59/70 - Loss:  2.476  - Validation loss:  2.660\n",
      "Epoch   4/100 Batch   60/70 - Loss:  1.831  - Validation loss:  2.668\n",
      "Epoch   4/100 Batch   61/70 - Loss:  1.857  - Validation loss:  2.663\n",
      "Epoch   4/100 Batch   62/70 - Loss:  2.642  - Validation loss:  2.672\n",
      "Epoch   4/100 Batch   63/70 - Loss:  2.493  - Validation loss:  2.664\n",
      "Epoch   4/100 Batch   64/70 - Loss:  2.390  - Validation loss:  2.663\n",
      "Epoch   4/100 Batch   65/70 - Loss:  2.399  - Validation loss:  2.668\n",
      "Epoch   4/100 Batch   66/70 - Loss:  2.944  - Validation loss:  2.664\n",
      "Epoch   4/100 Batch   67/70 - Loss:  2.478  - Validation loss:  2.667\n",
      "Epoch   4/100 Batch   68/70 - Loss:  2.653  - Validation loss:  2.660\n",
      "Epoch   4/100 Batch   69/70 - Loss:  2.089  - Validation loss:  2.673\n",
      "Epoch   5/100 Batch    1/70 - Loss:  2.764  - Validation loss:  2.669\n",
      "Epoch   5/100 Batch    2/70 - Loss:  2.520  - Validation loss:  2.662\n",
      "Epoch   5/100 Batch    3/70 - Loss:  2.398  - Validation loss:  2.662\n",
      "Epoch   5/100 Batch    4/70 - Loss:  2.542  - Validation loss:  2.658\n",
      "Epoch   5/100 Batch    5/70 - Loss:  2.221  - Validation loss:  2.652\n",
      "Epoch   5/100 Batch    6/70 - Loss:  2.237  - Validation loss:  2.650\n",
      "Epoch   5/100 Batch    7/70 - Loss:  2.765  - Validation loss:  2.651\n",
      "Epoch   5/100 Batch    8/70 - Loss:  1.878  - Validation loss:  2.649\n",
      "Epoch   5/100 Batch    9/70 - Loss:  2.624  - Validation loss:  2.649\n",
      "Epoch   5/100 Batch   10/70 - Loss:  2.066  - Validation loss:  2.648\n",
      "Epoch   5/100 Batch   11/70 - Loss:  1.797  - Validation loss:  2.649\n",
      "Epoch   5/100 Batch   12/70 - Loss:  2.212  - Validation loss:  2.645\n",
      "Epoch   5/100 Batch   13/70 - Loss:  2.356  - Validation loss:  2.646\n",
      "Epoch   5/100 Batch   14/70 - Loss:  2.320  - Validation loss:  2.645\n",
      "Epoch   5/100 Batch   15/70 - Loss:  2.160  - Validation loss:  2.645\n",
      "Epoch   5/100 Batch   16/70 - Loss:  2.312  - Validation loss:  2.644\n",
      "Epoch   5/100 Batch   17/70 - Loss:  1.967  - Validation loss:  2.645\n",
      "Epoch   5/100 Batch   18/70 - Loss:  2.169  - Validation loss:  2.645\n",
      "Epoch   5/100 Batch   19/70 - Loss:  2.417  - Validation loss:  2.645\n",
      "Epoch   5/100 Batch   20/70 - Loss:  2.332  - Validation loss:  2.645\n",
      "Epoch   5/100 Batch   21/70 - Loss:  2.651  - Validation loss:  2.649\n",
      "Epoch   5/100 Batch   22/70 - Loss:  1.996  - Validation loss:  2.645\n",
      "Epoch   5/100 Batch   23/70 - Loss:  1.781  - Validation loss:  2.648\n",
      "Epoch   5/100 Batch   24/70 - Loss:  2.000  - Validation loss:  2.652\n",
      "Epoch   5/100 Batch   25/70 - Loss:  2.773  - Validation loss:  2.655\n",
      "Epoch   5/100 Batch   26/70 - Loss:  2.306  - Validation loss:  2.650\n",
      "Epoch   5/100 Batch   27/70 - Loss:  2.183  - Validation loss:  2.650\n",
      "Epoch   5/100 Batch   28/70 - Loss:  2.489  - Validation loss:  2.654\n",
      "Epoch   5/100 Batch   29/70 - Loss:  2.250  - Validation loss:  2.662\n",
      "Epoch   5/100 Batch   30/70 - Loss:  2.068  - Validation loss:  2.644\n",
      "Epoch   5/100 Batch   31/70 - Loss:  2.107  - Validation loss:  2.652\n",
      "Epoch   5/100 Batch   32/70 - Loss:  2.131  - Validation loss:  2.645\n",
      "Epoch   5/100 Batch   33/70 - Loss:  2.278  - Validation loss:  2.653\n",
      "Epoch   5/100 Batch   34/70 - Loss:  2.421  - Validation loss:  2.646\n",
      "Epoch   5/100 Batch   35/70 - Loss:  2.606  - Validation loss:  2.644\n",
      "Epoch   5/100 Batch   36/70 - Loss:  2.552  - Validation loss:  2.651\n",
      "Epoch   5/100 Batch   37/70 - Loss:  2.332  - Validation loss:  2.657\n",
      "Epoch   5/100 Batch   38/70 - Loss:  2.179  - Validation loss:  2.643\n",
      "Epoch   5/100 Batch   39/70 - Loss:  1.964  - Validation loss:  2.649\n",
      "Epoch   5/100 Batch   40/70 - Loss:  2.776  - Validation loss:  2.634\n",
      "Epoch   5/100 Batch   41/70 - Loss:  2.577  - Validation loss:  2.649\n",
      "Epoch   5/100 Batch   42/70 - Loss:  2.707  - Validation loss:  2.633\n",
      "Epoch   5/100 Batch   43/70 - Loss:  2.817  - Validation loss:  2.641\n",
      "Epoch   5/100 Batch   44/70 - Loss:  2.552  - Validation loss:  2.632\n",
      "Epoch   5/100 Batch   45/70 - Loss:  2.401  - Validation loss:  2.649\n",
      "Epoch   5/100 Batch   46/70 - Loss:  2.300  - Validation loss:  2.650\n",
      "Epoch   5/100 Batch   47/70 - Loss:  2.087  - Validation loss:  2.640\n",
      "Epoch   5/100 Batch   48/70 - Loss:  2.411  - Validation loss:  2.640\n",
      "Epoch   5/100 Batch   49/70 - Loss:  2.321  - Validation loss:  2.630\n",
      "Epoch   5/100 Batch   50/70 - Loss:  2.184  - Validation loss:  2.642\n",
      "Epoch   5/100 Batch   51/70 - Loss:  2.540  - Validation loss:  2.636\n",
      "Epoch   5/100 Batch   52/70 - Loss:  2.822  - Validation loss:  2.642\n",
      "Epoch   5/100 Batch   53/70 - Loss:  2.423  - Validation loss:  2.636\n",
      "Epoch   5/100 Batch   54/70 - Loss:  1.479  - Validation loss:  2.635\n",
      "Epoch   5/100 Batch   55/70 - Loss:  1.853  - Validation loss:  2.648\n",
      "Epoch   5/100 Batch   56/70 - Loss:  2.338  - Validation loss:  2.643\n",
      "Epoch   5/100 Batch   57/70 - Loss:  1.670  - Validation loss:  2.644\n",
      "Epoch   5/100 Batch   58/70 - Loss:  1.846  - Validation loss:  2.639\n",
      "Epoch   5/100 Batch   59/70 - Loss:  2.441  - Validation loss:  2.642\n",
      "Epoch   5/100 Batch   60/70 - Loss:  1.807  - Validation loss:  2.639\n",
      "Epoch   5/100 Batch   61/70 - Loss:  1.820  - Validation loss:  2.643\n",
      "Epoch   5/100 Batch   62/70 - Loss:  2.622  - Validation loss:  2.638\n",
      "Epoch   5/100 Batch   63/70 - Loss:  2.455  - Validation loss:  2.644\n",
      "Epoch   5/100 Batch   64/70 - Loss:  2.362  - Validation loss:  2.643\n",
      "Epoch   5/100 Batch   65/70 - Loss:  2.370  - Validation loss:  2.645\n",
      "Epoch   5/100 Batch   66/70 - Loss:  2.913  - Validation loss:  2.644\n",
      "Epoch   5/100 Batch   67/70 - Loss:  2.454  - Validation loss:  2.642\n",
      "Epoch   5/100 Batch   68/70 - Loss:  2.617  - Validation loss:  2.639\n",
      "Epoch   5/100 Batch   69/70 - Loss:  2.062  - Validation loss:  2.640\n",
      "Epoch   6/100 Batch    1/70 - Loss:  2.739  - Validation loss:  2.639\n",
      "Epoch   6/100 Batch    2/70 - Loss:  2.490  - Validation loss:  2.637\n",
      "Epoch   6/100 Batch    3/70 - Loss:  2.366  - Validation loss:  2.641\n",
      "Epoch   6/100 Batch    4/70 - Loss:  2.517  - Validation loss:  2.638\n",
      "Epoch   6/100 Batch    5/70 - Loss:  2.198  - Validation loss:  2.645\n",
      "Epoch   6/100 Batch    6/70 - Loss:  2.217  - Validation loss:  2.632\n",
      "Epoch   6/100 Batch    7/70 - Loss:  2.738  - Validation loss:  2.632\n",
      "Epoch   6/100 Batch    8/70 - Loss:  1.855  - Validation loss:  2.630\n",
      "Epoch   6/100 Batch    9/70 - Loss:  2.605  - Validation loss:  2.635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6/100 Batch   10/70 - Loss:  2.049  - Validation loss:  2.627\n",
      "Epoch   6/100 Batch   11/70 - Loss:  1.771  - Validation loss:  2.629\n",
      "Epoch   6/100 Batch   12/70 - Loss:  2.189  - Validation loss:  2.629\n",
      "Epoch   6/100 Batch   13/70 - Loss:  2.334  - Validation loss:  2.630\n",
      "Epoch   6/100 Batch   14/70 - Loss:  2.299  - Validation loss:  2.626\n",
      "Epoch   6/100 Batch   15/70 - Loss:  2.138  - Validation loss:  2.624\n",
      "Epoch   6/100 Batch   16/70 - Loss:  2.287  - Validation loss:  2.625\n",
      "Epoch   6/100 Batch   17/70 - Loss:  1.944  - Validation loss:  2.627\n",
      "Epoch   6/100 Batch   18/70 - Loss:  2.145  - Validation loss:  2.625\n",
      "Epoch   6/100 Batch   19/70 - Loss:  2.394  - Validation loss:  2.625\n",
      "Epoch   6/100 Batch   20/70 - Loss:  2.307  - Validation loss:  2.627\n",
      "Epoch   6/100 Batch   21/70 - Loss:  2.626  - Validation loss:  2.632\n",
      "Epoch   6/100 Batch   22/70 - Loss:  1.968  - Validation loss:  2.632\n",
      "Epoch   6/100 Batch   23/70 - Loss:  1.759  - Validation loss:  2.629\n",
      "Epoch   6/100 Batch   24/70 - Loss:  1.972  - Validation loss:  2.627\n",
      "Epoch   6/100 Batch   25/70 - Loss:  2.747  - Validation loss:  2.635\n",
      "Epoch   6/100 Batch   26/70 - Loss:  2.276  - Validation loss:  2.631\n",
      "Epoch   6/100 Batch   27/70 - Loss:  2.160  - Validation loss:  2.633\n",
      "Epoch   6/100 Batch   28/70 - Loss:  2.465  - Validation loss:  2.631\n",
      "Epoch   6/100 Batch   29/70 - Loss:  2.232  - Validation loss:  2.639\n",
      "Epoch   6/100 Batch   30/70 - Loss:  2.037  - Validation loss:  2.648\n",
      "Epoch   6/100 Batch   31/70 - Loss:  2.099  - Validation loss:  2.626\n",
      "Epoch   6/100 Batch   32/70 - Loss:  2.092  - Validation loss:  2.636\n",
      "Epoch   6/100 Batch   33/70 - Loss:  2.272  - Validation loss:  2.622\n",
      "Epoch   6/100 Batch   34/70 - Loss:  2.372  - Validation loss:  2.633\n",
      "Epoch   6/100 Batch   35/70 - Loss:  2.580  - Validation loss:  2.622\n",
      "Epoch   6/100 Batch   36/70 - Loss:  2.518  - Validation loss:  2.621\n",
      "Epoch   6/100 Batch   37/70 - Loss:  2.303  - Validation loss:  2.619\n",
      "Epoch   6/100 Batch   38/70 - Loss:  2.134  - Validation loss:  2.622\n",
      "Epoch   6/100 Batch   39/70 - Loss:  1.933  - Validation loss:  2.622\n",
      "Epoch   6/100 Batch   40/70 - Loss:  2.736  - Validation loss:  2.619\n",
      "Epoch   6/100 Batch   41/70 - Loss:  2.555  - Validation loss:  2.616\n",
      "Epoch   6/100 Batch   42/70 - Loss:  2.667  - Validation loss:  2.622\n",
      "Epoch   6/100 Batch   43/70 - Loss:  2.794  - Validation loss:  2.617\n",
      "Epoch   6/100 Batch   44/70 - Loss:  2.519  - Validation loss:  2.617\n",
      "Epoch   6/100 Batch   45/70 - Loss:  2.384  - Validation loss:  2.613\n",
      "Epoch   6/100 Batch   46/70 - Loss:  2.268  - Validation loss:  2.624\n",
      "Epoch   6/100 Batch   47/70 - Loss:  2.056  - Validation loss:  2.627\n",
      "Epoch   6/100 Batch   48/70 - Loss:  2.384  - Validation loss:  2.619\n",
      "Epoch   6/100 Batch   49/70 - Loss:  2.289  - Validation loss:  2.618\n",
      "Epoch   6/100 Batch   50/70 - Loss:  2.173  - Validation loss:  2.613\n",
      "Epoch   6/100 Batch   51/70 - Loss:  2.506  - Validation loss:  2.624\n",
      "Epoch   6/100 Batch   52/70 - Loss:  2.802  - Validation loss:  2.615\n",
      "Epoch   6/100 Batch   53/70 - Loss:  2.388  - Validation loss:  2.623\n",
      "Epoch   6/100 Batch   54/70 - Loss:  1.459  - Validation loss:  2.620\n",
      "Epoch   6/100 Batch   55/70 - Loss:  1.838  - Validation loss:  2.623\n",
      "Epoch   6/100 Batch   56/70 - Loss:  2.310  - Validation loss:  2.637\n",
      "Epoch   6/100 Batch   57/70 - Loss:  1.657  - Validation loss:  2.628\n",
      "Epoch   6/100 Batch   58/70 - Loss:  1.818  - Validation loss:  2.633\n",
      "Epoch   6/100 Batch   59/70 - Loss:  2.432  - Validation loss:  2.628\n",
      "Epoch   6/100 Batch   60/70 - Loss:  1.790  - Validation loss:  2.638\n",
      "Epoch   6/100 Batch   61/70 - Loss:  1.806  - Validation loss:  2.632\n",
      "Epoch   6/100 Batch   62/70 - Loss:  2.601  - Validation loss:  2.630\n",
      "Epoch   6/100 Batch   63/70 - Loss:  2.446  - Validation loss:  2.628\n",
      "Epoch   6/100 Batch   64/70 - Loss:  2.349  - Validation loss:  2.630\n",
      "Epoch   6/100 Batch   65/70 - Loss:  2.355  - Validation loss:  2.642\n",
      "Epoch   6/100 Batch   66/70 - Loss:  2.902  - Validation loss:  2.626\n",
      "Epoch   6/100 Batch   67/70 - Loss:  2.429  - Validation loss:  2.634\n",
      "Epoch   6/100 Batch   68/70 - Loss:  2.610  - Validation loss:  2.626\n",
      "Epoch   6/100 Batch   69/70 - Loss:  2.049  - Validation loss:  2.641\n",
      "Epoch   7/100 Batch    1/70 - Loss:  2.726  - Validation loss:  2.624\n",
      "Epoch   7/100 Batch    2/70 - Loss:  2.470  - Validation loss:  2.637\n",
      "Epoch   7/100 Batch    3/70 - Loss:  2.363  - Validation loss:  2.621\n",
      "Epoch   7/100 Batch    4/70 - Loss:  2.492  - Validation loss:  2.629\n",
      "Epoch   7/100 Batch    5/70 - Loss:  2.183  - Validation loss:  2.634\n",
      "Epoch   7/100 Batch    6/70 - Loss:  2.203  - Validation loss:  2.618\n",
      "Epoch   7/100 Batch    7/70 - Loss:  2.720  - Validation loss:  2.624\n",
      "Epoch   7/100 Batch    8/70 - Loss:  1.840  - Validation loss:  2.619\n",
      "Epoch   7/100 Batch    9/70 - Loss:  2.581  - Validation loss:  2.617\n",
      "Epoch   7/100 Batch   10/70 - Loss:  2.020  - Validation loss:  2.624\n",
      "Epoch   7/100 Batch   11/70 - Loss:  1.758  - Validation loss:  2.613\n",
      "Epoch   7/100 Batch   12/70 - Loss:  2.165  - Validation loss:  2.617\n",
      "Epoch   7/100 Batch   13/70 - Loss:  2.317  - Validation loss:  2.613\n",
      "Epoch   7/100 Batch   14/70 - Loss:  2.278  - Validation loss:  2.616\n",
      "Epoch   7/100 Batch   15/70 - Loss:  2.121  - Validation loss:  2.622\n",
      "Epoch   7/100 Batch   16/70 - Loss:  2.275  - Validation loss:  2.611\n",
      "Epoch   7/100 Batch   17/70 - Loss:  1.925  - Validation loss:  2.613\n",
      "Epoch   7/100 Batch   18/70 - Loss:  2.127  - Validation loss:  2.610\n",
      "Epoch   7/100 Batch   19/70 - Loss:  2.374  - Validation loss:  2.614\n",
      "Epoch   7/100 Batch   20/70 - Loss:  2.291  - Validation loss:  2.611\n",
      "Epoch   7/100 Batch   21/70 - Loss:  2.605  - Validation loss:  2.611\n",
      "Epoch   7/100 Batch   22/70 - Loss:  1.946  - Validation loss:  2.613\n",
      "Epoch   7/100 Batch   23/70 - Loss:  1.736  - Validation loss:  2.617\n",
      "Epoch   7/100 Batch   24/70 - Loss:  1.953  - Validation loss:  2.617\n",
      "Epoch   7/100 Batch   25/70 - Loss:  2.724  - Validation loss:  2.614\n",
      "Epoch   7/100 Batch   26/70 - Loss:  2.254  - Validation loss:  2.613\n",
      "Epoch   7/100 Batch   27/70 - Loss:  2.136  - Validation loss:  2.610\n",
      "Epoch   7/100 Batch   28/70 - Loss:  2.438  - Validation loss:  2.611\n",
      "Epoch   7/100 Batch   29/70 - Loss:  2.206  - Validation loss:  2.609\n",
      "Epoch   7/100 Batch   30/70 - Loss:  2.012  - Validation loss:  2.617\n",
      "Epoch   7/100 Batch   31/70 - Loss:  2.064  - Validation loss:  2.615\n",
      "Epoch   7/100 Batch   32/70 - Loss:  2.075  - Validation loss:  2.611\n",
      "Epoch   7/100 Batch   33/70 - Loss:  2.236  - Validation loss:  2.614\n",
      "Epoch   7/100 Batch   34/70 - Loss:  2.357  - Validation loss:  2.608\n",
      "Epoch   7/100 Batch   35/70 - Loss:  2.548  - Validation loss:  2.617\n",
      "Epoch   7/100 Batch   36/70 - Loss:  2.503  - Validation loss:  2.611\n",
      "Epoch   7/100 Batch   37/70 - Loss:  2.282  - Validation loss:  2.606\n",
      "Epoch   7/100 Batch   38/70 - Loss:  2.117  - Validation loss:  2.611\n",
      "Epoch   7/100 Batch   39/70 - Loss:  1.922  - Validation loss:  2.604\n",
      "Epoch   7/100 Batch   40/70 - Loss:  2.713  - Validation loss:  2.615\n",
      "Epoch   7/100 Batch   41/70 - Loss:  2.542  - Validation loss:  2.609\n",
      "Epoch   7/100 Batch   42/70 - Loss:  2.648  - Validation loss:  2.603\n",
      "Epoch   7/100 Batch   43/70 - Loss:  2.774  - Validation loss:  2.603\n",
      "Epoch   7/100 Batch   44/70 - Loss:  2.500  - Validation loss:  2.601\n",
      "Epoch   7/100 Batch   45/70 - Loss:  2.357  - Validation loss:  2.602\n",
      "Epoch   7/100 Batch   46/70 - Loss:  2.246  - Validation loss:  2.598\n",
      "Epoch   7/100 Batch   47/70 - Loss:  2.032  - Validation loss:  2.596\n",
      "Epoch   7/100 Batch   48/70 - Loss:  2.358  - Validation loss:  2.597\n",
      "Epoch   7/100 Batch   49/70 - Loss:  2.265  - Validation loss:  2.600\n",
      "Epoch   7/100 Batch   50/70 - Loss:  2.144  - Validation loss:  2.600\n",
      "Epoch   7/100 Batch   51/70 - Loss:  2.489  - Validation loss:  2.598\n",
      "Epoch   7/100 Batch   52/70 - Loss:  2.773  - Validation loss:  2.597\n",
      "Epoch   7/100 Batch   53/70 - Loss:  2.363  - Validation loss:  2.598\n",
      "Epoch   7/100 Batch   54/70 - Loss:  1.433  - Validation loss:  2.600\n",
      "Epoch   7/100 Batch   55/70 - Loss:  1.809  - Validation loss:  2.601\n",
      "Epoch   7/100 Batch   56/70 - Loss:  2.287  - Validation loss:  2.603\n",
      "Epoch   7/100 Batch   57/70 - Loss:  1.625  - Validation loss:  2.607\n",
      "Epoch   7/100 Batch   58/70 - Loss:  1.796  - Validation loss:  2.608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7/100 Batch   59/70 - Loss:  2.397  - Validation loss:  2.610\n",
      "Epoch   7/100 Batch   60/70 - Loss:  1.768  - Validation loss:  2.609\n",
      "Epoch   7/100 Batch   61/70 - Loss:  1.779  - Validation loss:  2.614\n",
      "Epoch   7/100 Batch   62/70 - Loss:  2.577  - Validation loss:  2.605\n",
      "Epoch   7/100 Batch   63/70 - Loss:  2.413  - Validation loss:  2.612\n",
      "Epoch   7/100 Batch   64/70 - Loss:  2.328  - Validation loss:  2.606\n",
      "Epoch   7/100 Batch   65/70 - Loss:  2.334  - Validation loss:  2.619\n",
      "Epoch   7/100 Batch   66/70 - Loss:  2.873  - Validation loss:  2.617\n",
      "Epoch   7/100 Batch   67/70 - Loss:  2.414  - Validation loss:  2.608\n",
      "Epoch   7/100 Batch   68/70 - Loss:  2.577  - Validation loss:  2.620\n",
      "Epoch   7/100 Batch   69/70 - Loss:  2.044  - Validation loss:  2.608\n",
      "Epoch   8/100 Batch    1/70 - Loss:  2.710  - Validation loss:  2.611\n",
      "Epoch   8/100 Batch    2/70 - Loss:  2.454  - Validation loss:  2.614\n",
      "Epoch   8/100 Batch    3/70 - Loss:  2.333  - Validation loss:  2.631\n",
      "Epoch   8/100 Batch    4/70 - Loss:  2.499  - Validation loss:  2.602\n",
      "Epoch   8/100 Batch    5/70 - Loss:  2.157  - Validation loss:  2.634\n",
      "Epoch   8/100 Batch    6/70 - Loss:  2.198  - Validation loss:  2.623\n",
      "Epoch   8/100 Batch    7/70 - Loss:  2.714  - Validation loss:  2.601\n",
      "Epoch   8/100 Batch    8/70 - Loss:  1.813  - Validation loss:  2.626\n",
      "Epoch   8/100 Batch    9/70 - Loss:  2.580  - Validation loss:  2.610\n",
      "Epoch   8/100 Batch   10/70 - Loss:  2.023  - Validation loss:  2.613\n",
      "Epoch   8/100 Batch   11/70 - Loss:  1.739  - Validation loss:  2.646\n",
      "Epoch   8/100 Batch   12/70 - Loss:  2.187  - Validation loss:  2.601\n",
      "Epoch   8/100 Batch   13/70 - Loss:  2.294  - Validation loss:  2.617\n",
      "Epoch   8/100 Batch   14/70 - Loss:  2.279  - Validation loss:  2.625\n",
      "Epoch   8/100 Batch   15/70 - Loss:  2.139  - Validation loss:  2.597\n",
      "Epoch   8/100 Batch   16/70 - Loss:  2.250  - Validation loss:  2.625\n",
      "Epoch   8/100 Batch   17/70 - Loss:  1.938  - Validation loss:  2.626\n",
      "Epoch   8/100 Batch   18/70 - Loss:  2.135  - Validation loss:  2.596\n",
      "Epoch   8/100 Batch   19/70 - Loss:  2.354  - Validation loss:  2.616\n",
      "Epoch   8/100 Batch   20/70 - Loss:  2.297  - Validation loss:  2.610\n",
      "Epoch   8/100 Batch   21/70 - Loss:  2.601  - Validation loss:  2.596\n",
      "Epoch   8/100 Batch   22/70 - Loss:  1.926  - Validation loss:  2.619\n",
      "Epoch   8/100 Batch   23/70 - Loss:  1.734  - Validation loss:  2.621\n",
      "Epoch   8/100 Batch   24/70 - Loss:  1.950  - Validation loss:  2.596\n",
      "Epoch   8/100 Batch   25/70 - Loss:  2.699  - Validation loss:  2.601\n",
      "Epoch   8/100 Batch   26/70 - Loss:  2.246  - Validation loss:  2.597\n",
      "Epoch   8/100 Batch   27/70 - Loss:  2.121  - Validation loss:  2.592\n",
      "Epoch   8/100 Batch   28/70 - Loss:  2.415  - Validation loss:  2.599\n",
      "Epoch   8/100 Batch   29/70 - Loss:  2.188  - Validation loss:  2.593\n",
      "Epoch   8/100 Batch   30/70 - Loss:  1.992  - Validation loss:  2.588\n",
      "Epoch   8/100 Batch   31/70 - Loss:  2.040  - Validation loss:  2.588\n",
      "Epoch   8/100 Batch   32/70 - Loss:  2.054  - Validation loss:  2.587\n",
      "Epoch   8/100 Batch   33/70 - Loss:  2.210  - Validation loss:  2.589\n",
      "Epoch   8/100 Batch   34/70 - Loss:  2.329  - Validation loss:  2.586\n",
      "Epoch   8/100 Batch   35/70 - Loss:  2.523  - Validation loss:  2.585\n",
      "Epoch   8/100 Batch   36/70 - Loss:  2.473  - Validation loss:  2.584\n",
      "Epoch   8/100 Batch   37/70 - Loss:  2.251  - Validation loss:  2.586\n",
      "Epoch   8/100 Batch   38/70 - Loss:  2.095  - Validation loss:  2.582\n",
      "Epoch   8/100 Batch   39/70 - Loss:  1.890  - Validation loss:  2.582\n",
      "Epoch   8/100 Batch   40/70 - Loss:  2.686  - Validation loss:  2.580\n",
      "Epoch   8/100 Batch   41/70 - Loss:  2.508  - Validation loss:  2.580\n",
      "Epoch   8/100 Batch   42/70 - Loss:  2.615  - Validation loss:  2.584\n",
      "Epoch   8/100 Batch   43/70 - Loss:  2.748  - Validation loss:  2.577\n",
      "Epoch   8/100 Batch   44/70 - Loss:  2.473  - Validation loss:  2.579\n",
      "Epoch   8/100 Batch   45/70 - Loss:  2.335  - Validation loss:  2.576\n",
      "Epoch   8/100 Batch   46/70 - Loss:  2.220  - Validation loss:  2.576\n",
      "Epoch   8/100 Batch   47/70 - Loss:  2.007  - Validation loss:  2.583\n",
      "Epoch   8/100 Batch   48/70 - Loss:  2.333  - Validation loss:  2.576\n",
      "Epoch   8/100 Batch   49/70 - Loss:  2.239  - Validation loss:  2.572\n",
      "Epoch   8/100 Batch   50/70 - Loss:  2.120  - Validation loss:  2.573\n",
      "Epoch   8/100 Batch   51/70 - Loss:  2.464  - Validation loss:  2.572\n",
      "Epoch   8/100 Batch   52/70 - Loss:  2.741  - Validation loss:  2.576\n",
      "Epoch   8/100 Batch   53/70 - Loss:  2.335  - Validation loss:  2.573\n",
      "Epoch   8/100 Batch   54/70 - Loss:  1.409  - Validation loss:  2.573\n",
      "Epoch   8/100 Batch   55/70 - Loss:  1.781  - Validation loss:  2.574\n",
      "Epoch   8/100 Batch   56/70 - Loss:  2.256  - Validation loss:  2.574\n",
      "Epoch   8/100 Batch   57/70 - Loss:  1.600  - Validation loss:  2.578\n",
      "Epoch   8/100 Batch   58/70 - Loss:  1.769  - Validation loss:  2.578\n",
      "Epoch   8/100 Batch   59/70 - Loss:  2.365  - Validation loss:  2.576\n",
      "Epoch   8/100 Batch   60/70 - Loss:  1.740  - Validation loss:  2.577\n",
      "Epoch   8/100 Batch   61/70 - Loss:  1.758  - Validation loss:  2.579\n",
      "Epoch   8/100 Batch   62/70 - Loss:  2.542  - Validation loss:  2.583\n",
      "Epoch   8/100 Batch   63/70 - Loss:  2.386  - Validation loss:  2.574\n",
      "Epoch   8/100 Batch   64/70 - Loss:  2.287  - Validation loss:  2.577\n",
      "Epoch   8/100 Batch   65/70 - Loss:  2.311  - Validation loss:  2.574\n",
      "Epoch   8/100 Batch   66/70 - Loss:  2.834  - Validation loss:  2.586\n",
      "Epoch   8/100 Batch   67/70 - Loss:  2.379  - Validation loss:  2.591\n",
      "Epoch   8/100 Batch   68/70 - Loss:  2.561  - Validation loss:  2.575\n",
      "Epoch   8/100 Batch   69/70 - Loss:  1.995  - Validation loss:  2.592\n",
      "Epoch   9/100 Batch    1/70 - Loss:  2.656  - Validation loss:  2.593\n",
      "Epoch   9/100 Batch    2/70 - Loss:  2.425  - Validation loss:  2.595\n",
      "Epoch   9/100 Batch    3/70 - Loss:  2.327  - Validation loss:  2.570\n",
      "Epoch   9/100 Batch    4/70 - Loss:  2.432  - Validation loss:  2.600\n",
      "Epoch   9/100 Batch    5/70 - Loss:  2.161  - Validation loss:  2.585\n",
      "Epoch   9/100 Batch    6/70 - Loss:  2.173  - Validation loss:  2.573\n",
      "Epoch   9/100 Batch    7/70 - Loss:  2.665  - Validation loss:  2.613\n",
      "Epoch   9/100 Batch    8/70 - Loss:  1.839  - Validation loss:  2.597\n",
      "Epoch   9/100 Batch    9/70 - Loss:  2.555  - Validation loss:  2.565\n",
      "Epoch   9/100 Batch   10/70 - Loss:  1.968  - Validation loss:  2.584\n",
      "Epoch   9/100 Batch   11/70 - Loss:  1.738  - Validation loss:  2.582\n",
      "Epoch   9/100 Batch   12/70 - Loss:  2.138  - Validation loss:  2.564\n",
      "Epoch   9/100 Batch   13/70 - Loss:  2.256  - Validation loss:  2.578\n",
      "Epoch   9/100 Batch   14/70 - Loss:  2.242  - Validation loss:  2.584\n",
      "Epoch   9/100 Batch   15/70 - Loss:  2.088  - Validation loss:  2.567\n",
      "Epoch   9/100 Batch   16/70 - Loss:  2.216  - Validation loss:  2.560\n",
      "Epoch   9/100 Batch   17/70 - Loss:  1.879  - Validation loss:  2.565\n",
      "Epoch   9/100 Batch   18/70 - Loss:  2.078  - Validation loss:  2.558\n",
      "Epoch   9/100 Batch   19/70 - Loss:  2.316  - Validation loss:  2.559\n",
      "Epoch   9/100 Batch   20/70 - Loss:  2.237  - Validation loss:  2.560\n",
      "Epoch   9/100 Batch   21/70 - Loss:  2.542  - Validation loss:  2.555\n",
      "Epoch   9/100 Batch   22/70 - Loss:  1.888  - Validation loss:  2.554\n",
      "Epoch   9/100 Batch   23/70 - Loss:  1.686  - Validation loss:  2.554\n",
      "Epoch   9/100 Batch   24/70 - Loss:  1.900  - Validation loss:  2.556\n",
      "Epoch   9/100 Batch   25/70 - Loss:  2.654  - Validation loss:  2.560\n",
      "Epoch   9/100 Batch   26/70 - Loss:  2.200  - Validation loss:  2.555\n",
      "Epoch   9/100 Batch   27/70 - Loss:  2.080  - Validation loss:  2.553\n",
      "Epoch   9/100 Batch   28/70 - Loss:  2.372  - Validation loss:  2.554\n",
      "Epoch   9/100 Batch   29/70 - Loss:  2.151  - Validation loss:  2.549\n",
      "Epoch   9/100 Batch   30/70 - Loss:  1.953  - Validation loss:  2.558\n",
      "Epoch   9/100 Batch   31/70 - Loss:  2.006  - Validation loss:  2.558\n",
      "Epoch   9/100 Batch   32/70 - Loss:  2.023  - Validation loss:  2.547\n",
      "Epoch   9/100 Batch   33/70 - Loss:  2.169  - Validation loss:  2.550\n",
      "Epoch   9/100 Batch   34/70 - Loss:  2.292  - Validation loss:  2.550\n",
      "Epoch   9/100 Batch   35/70 - Loss:  2.490  - Validation loss:  2.545\n",
      "Epoch   9/100 Batch   36/70 - Loss:  2.426  - Validation loss:  2.554\n",
      "Epoch   9/100 Batch   37/70 - Loss:  2.215  - Validation loss:  2.553\n",
      "Epoch   9/100 Batch   38/70 - Loss:  2.063  - Validation loss:  2.540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9/100 Batch   39/70 - Loss:  1.857  - Validation loss:  2.542\n",
      "Epoch   9/100 Batch   40/70 - Loss:  2.642  - Validation loss:  2.541\n",
      "Epoch   9/100 Batch   41/70 - Loss:  2.468  - Validation loss:  2.535\n",
      "Epoch   9/100 Batch   42/70 - Loss:  2.569  - Validation loss:  2.545\n",
      "Epoch   9/100 Batch   43/70 - Loss:  2.701  - Validation loss:  2.546\n",
      "Epoch   9/100 Batch   44/70 - Loss:  2.442  - Validation loss:  2.533\n",
      "Epoch   9/100 Batch   45/70 - Loss:  2.286  - Validation loss:  2.539\n",
      "Epoch   9/100 Batch   46/70 - Loss:  2.182  - Validation loss:  2.537\n",
      "Epoch   9/100 Batch   47/70 - Loss:  1.980  - Validation loss:  2.532\n",
      "Epoch   9/100 Batch   48/70 - Loss:  2.283  - Validation loss:  2.547\n",
      "Epoch   9/100 Batch   49/70 - Loss:  2.206  - Validation loss:  2.549\n",
      "Epoch   9/100 Batch   50/70 - Loss:  2.093  - Validation loss:  2.532\n",
      "Epoch   9/100 Batch   51/70 - Loss:  2.419  - Validation loss:  2.535\n",
      "Epoch   9/100 Batch   52/70 - Loss:  2.703  - Validation loss:  2.536\n",
      "Epoch   9/100 Batch   53/70 - Loss:  2.297  - Validation loss:  2.530\n",
      "Epoch   9/100 Batch   54/70 - Loss:  1.381  - Validation loss:  2.544\n",
      "Epoch   9/100 Batch   55/70 - Loss:  1.750  - Validation loss:  2.546\n",
      "Epoch   9/100 Batch   56/70 - Loss:  2.217  - Validation loss:  2.533\n",
      "Epoch   9/100 Batch   57/70 - Loss:  1.568  - Validation loss:  2.533\n",
      "Epoch   9/100 Batch   58/70 - Loss:  1.736  - Validation loss:  2.534\n",
      "Epoch   9/100 Batch   59/70 - Loss:  2.322  - Validation loss:  2.532\n",
      "Epoch   9/100 Batch   60/70 - Loss:  1.707  - Validation loss:  2.538\n",
      "Epoch   9/100 Batch   61/70 - Loss:  1.723  - Validation loss:  2.537\n",
      "Epoch   9/100 Batch   62/70 - Loss:  2.498  - Validation loss:  2.532\n",
      "Epoch   9/100 Batch   63/70 - Loss:  2.335  - Validation loss:  2.532\n",
      "Epoch   9/100 Batch   64/70 - Loss:  2.248  - Validation loss:  2.531\n",
      "Epoch   9/100 Batch   65/70 - Loss:  2.267  - Validation loss:  2.531\n",
      "Epoch   9/100 Batch   66/70 - Loss:  2.775  - Validation loss:  2.534\n",
      "Epoch   9/100 Batch   67/70 - Loss:  2.328  - Validation loss:  2.534\n",
      "Epoch   9/100 Batch   68/70 - Loss:  2.497  - Validation loss:  2.530\n",
      "Epoch   9/100 Batch   69/70 - Loss:  1.955  - Validation loss:  2.531\n",
      "Epoch  10/100 Batch    1/70 - Loss:  2.601  - Validation loss:  2.530\n",
      "Epoch  10/100 Batch    2/70 - Loss:  2.360  - Validation loss:  2.537\n",
      "Epoch  10/100 Batch    3/70 - Loss:  2.256  - Validation loss:  2.530\n",
      "Epoch  10/100 Batch    4/70 - Loss:  2.387  - Validation loss:  2.526\n",
      "Epoch  10/100 Batch    5/70 - Loss:  2.085  - Validation loss:  2.530\n",
      "Epoch  10/100 Batch    6/70 - Loss:  2.111  - Validation loss:  2.519\n",
      "Epoch  10/100 Batch    7/70 - Loss:  2.610  - Validation loss:  2.532\n",
      "Epoch  10/100 Batch    8/70 - Loss:  1.752  - Validation loss:  2.536\n",
      "Epoch  10/100 Batch    9/70 - Loss:  2.481  - Validation loss:  2.519\n",
      "Epoch  10/100 Batch   10/70 - Loss:  1.925  - Validation loss:  2.519\n",
      "Epoch  10/100 Batch   11/70 - Loss:  1.672  - Validation loss:  2.524\n",
      "Epoch  10/100 Batch   12/70 - Loss:  2.072  - Validation loss:  2.514\n",
      "Epoch  10/100 Batch   13/70 - Loss:  2.204  - Validation loss:  2.523\n",
      "Epoch  10/100 Batch   14/70 - Loss:  2.182  - Validation loss:  2.527\n",
      "Epoch  10/100 Batch   15/70 - Loss:  2.030  - Validation loss:  2.515\n",
      "Epoch  10/100 Batch   16/70 - Loss:  2.161  - Validation loss:  2.512\n",
      "Epoch  10/100 Batch   17/70 - Loss:  1.838  - Validation loss:  2.513\n",
      "Epoch  10/100 Batch   18/70 - Loss:  2.026  - Validation loss:  2.511\n",
      "Epoch  10/100 Batch   19/70 - Loss:  2.265  - Validation loss:  2.514\n",
      "Epoch  10/100 Batch   20/70 - Loss:  2.189  - Validation loss:  2.512\n",
      "Epoch  10/100 Batch   21/70 - Loss:  2.485  - Validation loss:  2.510\n",
      "Epoch  10/100 Batch   22/70 - Loss:  1.846  - Validation loss:  2.510\n",
      "Epoch  10/100 Batch   23/70 - Loss:  1.646  - Validation loss:  2.511\n",
      "Epoch  10/100 Batch   24/70 - Loss:  1.858  - Validation loss:  2.514\n",
      "Epoch  10/100 Batch   25/70 - Loss:  2.602  - Validation loss:  2.515\n",
      "Epoch  10/100 Batch   26/70 - Loss:  2.151  - Validation loss:  2.512\n",
      "Epoch  10/100 Batch   27/70 - Loss:  2.036  - Validation loss:  2.508\n",
      "Epoch  10/100 Batch   28/70 - Loss:  2.319  - Validation loss:  2.508\n",
      "Epoch  10/100 Batch   29/70 - Loss:  2.105  - Validation loss:  2.505\n",
      "Epoch  10/100 Batch   30/70 - Loss:  1.914  - Validation loss:  2.508\n",
      "Epoch  10/100 Batch   31/70 - Loss:  1.957  - Validation loss:  2.514\n",
      "Epoch  10/100 Batch   32/70 - Loss:  1.979  - Validation loss:  2.508\n",
      "Epoch  10/100 Batch   33/70 - Loss:  2.126  - Validation loss:  2.503\n",
      "Epoch  10/100 Batch   34/70 - Loss:  2.240  - Validation loss:  2.510\n",
      "Epoch  10/100 Batch   35/70 - Loss:  2.440  - Validation loss:  2.505\n",
      "Epoch  10/100 Batch   36/70 - Loss:  2.380  - Validation loss:  2.504\n",
      "Epoch  10/100 Batch   37/70 - Loss:  2.162  - Validation loss:  2.515\n",
      "Epoch  10/100 Batch   38/70 - Loss:  2.021  - Validation loss:  2.512\n",
      "Epoch  10/100 Batch   39/70 - Loss:  1.827  - Validation loss:  2.499\n",
      "Epoch  10/100 Batch   40/70 - Loss:  2.588  - Validation loss:  2.501\n",
      "Epoch  10/100 Batch   41/70 - Loss:  2.419  - Validation loss:  2.503\n",
      "Epoch  10/100 Batch   42/70 - Loss:  2.534  - Validation loss:  2.492\n",
      "Epoch  10/100 Batch   43/70 - Loss:  2.647  - Validation loss:  2.510\n",
      "Epoch  10/100 Batch   44/70 - Loss:  2.399  - Validation loss:  2.509\n",
      "Epoch  10/100 Batch   45/70 - Loss:  2.254  - Validation loss:  2.492\n",
      "Epoch  10/100 Batch   46/70 - Loss:  2.128  - Validation loss:  2.499\n",
      "Epoch  10/100 Batch   47/70 - Loss:  1.941  - Validation loss:  2.500\n",
      "Epoch  10/100 Batch   48/70 - Loss:  2.251  - Validation loss:  2.491\n",
      "Epoch  10/100 Batch   49/70 - Loss:  2.155  - Validation loss:  2.505\n",
      "Epoch  10/100 Batch   50/70 - Loss:  2.048  - Validation loss:  2.516\n",
      "Epoch  10/100 Batch   51/70 - Loss:  2.396  - Validation loss:  2.498\n",
      "Epoch  10/100 Batch   52/70 - Loss:  2.650  - Validation loss:  2.492\n",
      "Epoch  10/100 Batch   53/70 - Loss:  2.243  - Validation loss:  2.502\n",
      "Epoch  10/100 Batch   54/70 - Loss:  1.365  - Validation loss:  2.495\n",
      "Epoch  10/100 Batch   55/70 - Loss:  1.715  - Validation loss:  2.492\n",
      "Epoch  10/100 Batch   56/70 - Loss:  2.165  - Validation loss:  2.510\n",
      "Epoch  10/100 Batch   57/70 - Loss:  1.552  - Validation loss:  2.505\n",
      "Epoch  10/100 Batch   58/70 - Loss:  1.708  - Validation loss:  2.492\n",
      "Epoch  10/100 Batch   59/70 - Loss:  2.270  - Validation loss:  2.502\n",
      "Epoch  10/100 Batch   60/70 - Loss:  1.685  - Validation loss:  2.500\n",
      "Epoch  10/100 Batch   61/70 - Loss:  1.700  - Validation loss:  2.495\n",
      "Epoch  10/100 Batch   62/70 - Loss:  2.452  - Validation loss:  2.509\n",
      "Epoch  10/100 Batch   63/70 - Loss:  2.304  - Validation loss:  2.505\n",
      "Epoch  10/100 Batch   64/70 - Loss:  2.215  - Validation loss:  2.491\n",
      "Epoch  10/100 Batch   65/70 - Loss:  2.226  - Validation loss:  2.496\n",
      "Epoch  10/100 Batch   66/70 - Loss:  2.737  - Validation loss:  2.495\n",
      "Epoch  10/100 Batch   67/70 - Loss:  2.293  - Validation loss:  2.491\n",
      "Epoch  10/100 Batch   68/70 - Loss:  2.451  - Validation loss:  2.504\n",
      "Epoch  10/100 Batch   69/70 - Loss:  1.927  - Validation loss:  2.501\n",
      "Epoch  11/100 Batch    1/70 - Loss:  2.542  - Validation loss:  2.493\n",
      "Epoch  11/100 Batch    2/70 - Loss:  2.321  - Validation loss:  2.492\n",
      "Epoch  11/100 Batch    3/70 - Loss:  2.208  - Validation loss:  2.486\n",
      "Epoch  11/100 Batch    4/70 - Loss:  2.333  - Validation loss:  2.489\n",
      "Epoch  11/100 Batch    5/70 - Loss:  2.043  - Validation loss:  2.488\n",
      "Epoch  11/100 Batch    6/70 - Loss:  2.054  - Validation loss:  2.481\n",
      "Epoch  11/100 Batch    7/70 - Loss:  2.560  - Validation loss:  2.478\n",
      "Epoch  11/100 Batch    8/70 - Loss:  1.707  - Validation loss:  2.477\n",
      "Epoch  11/100 Batch    9/70 - Loss:  2.421  - Validation loss:  2.477\n",
      "Epoch  11/100 Batch   10/70 - Loss:  1.880  - Validation loss:  2.477\n",
      "Epoch  11/100 Batch   11/70 - Loss:  1.626  - Validation loss:  2.477\n",
      "Epoch  11/100 Batch   12/70 - Loss:  2.012  - Validation loss:  2.475\n",
      "Epoch  11/100 Batch   13/70 - Loss:  2.156  - Validation loss:  2.475\n",
      "Epoch  11/100 Batch   14/70 - Loss:  2.131  - Validation loss:  2.474\n",
      "Epoch  11/100 Batch   15/70 - Loss:  1.977  - Validation loss:  2.475\n",
      "Epoch  11/100 Batch   16/70 - Loss:  2.112  - Validation loss:  2.478\n",
      "Epoch  11/100 Batch   17/70 - Loss:  1.801  - Validation loss:  2.475\n",
      "Epoch  11/100 Batch   18/70 - Loss:  1.980  - Validation loss:  2.473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  11/100 Batch   19/70 - Loss:  2.217  - Validation loss:  2.474\n",
      "Epoch  11/100 Batch   20/70 - Loss:  2.143  - Validation loss:  2.472\n",
      "Epoch  11/100 Batch   21/70 - Loss:  2.436  - Validation loss:  2.473\n",
      "Epoch  11/100 Batch   22/70 - Loss:  1.803  - Validation loss:  2.475\n",
      "Epoch  11/100 Batch   23/70 - Loss:  1.610  - Validation loss:  2.475\n",
      "Epoch  11/100 Batch   24/70 - Loss:  1.820  - Validation loss:  2.473\n",
      "Epoch  11/100 Batch   25/70 - Loss:  2.549  - Validation loss:  2.472\n",
      "Epoch  11/100 Batch   26/70 - Loss:  2.106  - Validation loss:  2.471\n",
      "Epoch  11/100 Batch   27/70 - Loss:  1.993  - Validation loss:  2.469\n",
      "Epoch  11/100 Batch   28/70 - Loss:  2.268  - Validation loss:  2.467\n",
      "Epoch  11/100 Batch   29/70 - Loss:  2.060  - Validation loss:  2.465\n",
      "Epoch  11/100 Batch   30/70 - Loss:  1.870  - Validation loss:  2.465\n",
      "Epoch  11/100 Batch   31/70 - Loss:  1.915  - Validation loss:  2.466\n",
      "Epoch  11/100 Batch   32/70 - Loss:  1.931  - Validation loss:  2.467\n",
      "Epoch  11/100 Batch   33/70 - Loss:  2.077  - Validation loss:  2.464\n",
      "Epoch  11/100 Batch   34/70 - Loss:  2.193  - Validation loss:  2.463\n",
      "Epoch  11/100 Batch   35/70 - Loss:  2.380  - Validation loss:  2.466\n",
      "Epoch  11/100 Batch   36/70 - Loss:  2.330  - Validation loss:  2.462\n",
      "Epoch  11/100 Batch   37/70 - Loss:  2.117  - Validation loss:  2.465\n",
      "Epoch  11/100 Batch   38/70 - Loss:  1.970  - Validation loss:  2.475\n",
      "Epoch  11/100 Batch   39/70 - Loss:  1.789  - Validation loss:  2.472\n",
      "Epoch  11/100 Batch   40/70 - Loss:  2.550  - Validation loss:  2.458\n",
      "Epoch  11/100 Batch   41/70 - Loss:  2.369  - Validation loss:  2.462\n",
      "Epoch  11/100 Batch   42/70 - Loss:  2.482  - Validation loss:  2.461\n",
      "Epoch  11/100 Batch   43/70 - Loss:  2.613  - Validation loss:  2.454\n",
      "Epoch  11/100 Batch   44/70 - Loss:  2.343  - Validation loss:  2.468\n",
      "Epoch  11/100 Batch   45/70 - Loss:  2.202  - Validation loss:  2.470\n",
      "Epoch  11/100 Batch   46/70 - Loss:  2.097  - Validation loss:  2.456\n",
      "Epoch  11/100 Batch   47/70 - Loss:  1.893  - Validation loss:  2.455\n",
      "Epoch  11/100 Batch   48/70 - Loss:  2.193  - Validation loss:  2.460\n",
      "Epoch  11/100 Batch   49/70 - Loss:  2.123  - Validation loss:  2.455\n",
      "Epoch  11/100 Batch   50/70 - Loss:  2.009  - Validation loss:  2.459\n",
      "Epoch  11/100 Batch   51/70 - Loss:  2.336  - Validation loss:  2.470\n",
      "Epoch  11/100 Batch   52/70 - Loss:  2.608  - Validation loss:  2.462\n",
      "Epoch  11/100 Batch   53/70 - Loss:  2.200  - Validation loss:  2.452\n",
      "Epoch  11/100 Batch   54/70 - Loss:  1.319  - Validation loss:  2.459\n",
      "Epoch  11/100 Batch   55/70 - Loss:  1.678  - Validation loss:  2.462\n",
      "Epoch  11/100 Batch   56/70 - Loss:  2.133  - Validation loss:  2.454\n",
      "Epoch  11/100 Batch   57/70 - Loss:  1.504  - Validation loss:  2.460\n",
      "Epoch  11/100 Batch   58/70 - Loss:  1.666  - Validation loss:  2.467\n",
      "Epoch  11/100 Batch   59/70 - Loss:  2.238  - Validation loss:  2.459\n",
      "Epoch  11/100 Batch   60/70 - Loss:  1.643  - Validation loss:  2.455\n",
      "Epoch  11/100 Batch   61/70 - Loss:  1.654  - Validation loss:  2.459\n",
      "Epoch  11/100 Batch   62/70 - Loss:  2.416  - Validation loss:  2.456\n",
      "Epoch  11/100 Batch   63/70 - Loss:  2.254  - Validation loss:  2.460\n",
      "Epoch  11/100 Batch   64/70 - Loss:  2.170  - Validation loss:  2.467\n",
      "Epoch  11/100 Batch   65/70 - Loss:  2.195  - Validation loss:  2.460\n",
      "Epoch  11/100 Batch   66/70 - Loss:  2.684  - Validation loss:  2.452\n",
      "Epoch  11/100 Batch   67/70 - Loss:  2.241  - Validation loss:  2.456\n",
      "Epoch  11/100 Batch   68/70 - Loss:  2.419  - Validation loss:  2.454\n",
      "Epoch  11/100 Batch   69/70 - Loss:  1.884  - Validation loss:  2.454\n",
      "Epoch  12/100 Batch    1/70 - Loss:  2.488  - Validation loss:  2.456\n",
      "Epoch  12/100 Batch    2/70 - Loss:  2.270  - Validation loss:  2.452\n",
      "Epoch  12/100 Batch    3/70 - Loss:  2.156  - Validation loss:  2.450\n",
      "Epoch  12/100 Batch    4/70 - Loss:  2.286  - Validation loss:  2.450\n",
      "Epoch  12/100 Batch    5/70 - Loss:  2.001  - Validation loss:  2.447\n",
      "Epoch  12/100 Batch    6/70 - Loss:  2.012  - Validation loss:  2.446\n",
      "Epoch  12/100 Batch    7/70 - Loss:  2.517  - Validation loss:  2.450\n",
      "Epoch  12/100 Batch    8/70 - Loss:  1.675  - Validation loss:  2.448\n",
      "Epoch  12/100 Batch    9/70 - Loss:  2.377  - Validation loss:  2.441\n",
      "Epoch  12/100 Batch   10/70 - Loss:  1.840  - Validation loss:  2.441\n",
      "Epoch  12/100 Batch   11/70 - Loss:  1.593  - Validation loss:  2.441\n",
      "Epoch  12/100 Batch   12/70 - Loss:  1.974  - Validation loss:  2.438\n",
      "Epoch  12/100 Batch   13/70 - Loss:  2.112  - Validation loss:  2.439\n",
      "Epoch  12/100 Batch   14/70 - Loss:  2.087  - Validation loss:  2.442\n",
      "Epoch  12/100 Batch   15/70 - Loss:  1.931  - Validation loss:  2.441\n",
      "Epoch  12/100 Batch   16/70 - Loss:  2.067  - Validation loss:  2.439\n",
      "Epoch  12/100 Batch   17/70 - Loss:  1.763  - Validation loss:  2.439\n",
      "Epoch  12/100 Batch   18/70 - Loss:  1.937  - Validation loss:  2.439\n",
      "Epoch  12/100 Batch   19/70 - Loss:  2.173  - Validation loss:  2.438\n",
      "Epoch  12/100 Batch   20/70 - Loss:  2.096  - Validation loss:  2.438\n",
      "Epoch  12/100 Batch   21/70 - Loss:  2.386  - Validation loss:  2.438\n",
      "Epoch  12/100 Batch   22/70 - Loss:  1.762  - Validation loss:  2.437\n",
      "Epoch  12/100 Batch   23/70 - Loss:  1.571  - Validation loss:  2.437\n",
      "Epoch  12/100 Batch   24/70 - Loss:  1.787  - Validation loss:  2.436\n",
      "Epoch  12/100 Batch   25/70 - Loss:  2.498  - Validation loss:  2.437\n",
      "Epoch  12/100 Batch   26/70 - Loss:  2.063  - Validation loss:  2.437\n",
      "Epoch  12/100 Batch   27/70 - Loss:  1.954  - Validation loss:  2.435\n",
      "Epoch  12/100 Batch   28/70 - Loss:  2.218  - Validation loss:  2.433\n",
      "Epoch  12/100 Batch   29/70 - Loss:  2.024  - Validation loss:  2.432\n",
      "Epoch  12/100 Batch   30/70 - Loss:  1.832  - Validation loss:  2.430\n",
      "Epoch  12/100 Batch   31/70 - Loss:  1.876  - Validation loss:  2.431\n",
      "Epoch  12/100 Batch   32/70 - Loss:  1.890  - Validation loss:  2.433\n",
      "Epoch  12/100 Batch   33/70 - Loss:  2.032  - Validation loss:  2.431\n",
      "Epoch  12/100 Batch   34/70 - Loss:  2.150  - Validation loss:  2.428\n",
      "Epoch  12/100 Batch   35/70 - Loss:  2.334  - Validation loss:  2.430\n",
      "Epoch  12/100 Batch   36/70 - Loss:  2.283  - Validation loss:  2.429\n",
      "Epoch  12/100 Batch   37/70 - Loss:  2.075  - Validation loss:  2.428\n",
      "Epoch  12/100 Batch   38/70 - Loss:  1.929  - Validation loss:  2.436\n",
      "Epoch  12/100 Batch   39/70 - Loss:  1.751  - Validation loss:  2.441\n",
      "Epoch  12/100 Batch   40/70 - Loss:  2.508  - Validation loss:  2.431\n",
      "Epoch  12/100 Batch   41/70 - Loss:  2.334  - Validation loss:  2.424\n",
      "Epoch  12/100 Batch   42/70 - Loss:  2.434  - Validation loss:  2.428\n",
      "Epoch  12/100 Batch   43/70 - Loss:  2.570  - Validation loss:  2.424\n",
      "Epoch  12/100 Batch   44/70 - Loss:  2.312  - Validation loss:  2.423\n",
      "Epoch  12/100 Batch   45/70 - Loss:  2.153  - Validation loss:  2.434\n",
      "Epoch  12/100 Batch   46/70 - Loss:  2.052  - Validation loss:  2.434\n",
      "Epoch  12/100 Batch   47/70 - Loss:  1.868  - Validation loss:  2.422\n",
      "Epoch  12/100 Batch   48/70 - Loss:  2.145  - Validation loss:  2.422\n",
      "Epoch  12/100 Batch   49/70 - Loss:  2.073  - Validation loss:  2.428\n",
      "Epoch  12/100 Batch   50/70 - Loss:  1.980  - Validation loss:  2.424\n",
      "Epoch  12/100 Batch   51/70 - Loss:  2.302  - Validation loss:  2.428\n",
      "Epoch  12/100 Batch   52/70 - Loss:  2.556  - Validation loss:  2.434\n",
      "Epoch  12/100 Batch   53/70 - Loss:  2.154  - Validation loss:  2.430\n",
      "Epoch  12/100 Batch   54/70 - Loss:  1.293  - Validation loss:  2.421\n",
      "Epoch  12/100 Batch   55/70 - Loss:  1.637  - Validation loss:  2.423\n",
      "Epoch  12/100 Batch   56/70 - Loss:  2.087  - Validation loss:  2.426\n",
      "Epoch  12/100 Batch   57/70 - Loss:  1.478  - Validation loss:  2.422\n",
      "Epoch  12/100 Batch   58/70 - Loss:  1.631  - Validation loss:  2.426\n",
      "Epoch  12/100 Batch   59/70 - Loss:  2.192  - Validation loss:  2.433\n",
      "Epoch  12/100 Batch   60/70 - Loss:  1.617  - Validation loss:  2.428\n",
      "Epoch  12/100 Batch   61/70 - Loss:  1.624  - Validation loss:  2.423\n",
      "Epoch  12/100 Batch   62/70 - Loss:  2.364  - Validation loss:  2.426\n",
      "Epoch  12/100 Batch   63/70 - Loss:  2.221  - Validation loss:  2.425\n",
      "Epoch  12/100 Batch   64/70 - Loss:  2.140  - Validation loss:  2.425\n",
      "Epoch  12/100 Batch   65/70 - Loss:  2.149  - Validation loss:  2.431\n",
      "Epoch  12/100 Batch   66/70 - Loss:  2.643  - Validation loss:  2.430\n",
      "Epoch  12/100 Batch   67/70 - Loss:  2.206  - Validation loss:  2.423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  12/100 Batch   68/70 - Loss:  2.379  - Validation loss:  2.423\n",
      "Epoch  12/100 Batch   69/70 - Loss:  1.853  - Validation loss:  2.426\n",
      "Epoch  13/100 Batch    1/70 - Loss:  2.439  - Validation loss:  2.423\n",
      "Epoch  13/100 Batch    2/70 - Loss:  2.227  - Validation loss:  2.430\n",
      "Epoch  13/100 Batch    3/70 - Loss:  2.124  - Validation loss:  2.423\n",
      "Epoch  13/100 Batch    4/70 - Loss:  2.244  - Validation loss:  2.418\n",
      "Epoch  13/100 Batch    5/70 - Loss:  1.961  - Validation loss:  2.421\n",
      "Epoch  13/100 Batch    6/70 - Loss:  1.980  - Validation loss:  2.417\n",
      "Epoch  13/100 Batch    7/70 - Loss:  2.482  - Validation loss:  2.414\n",
      "Epoch  13/100 Batch    8/70 - Loss:  1.640  - Validation loss:  2.418\n",
      "Epoch  13/100 Batch    9/70 - Loss:  2.338  - Validation loss:  2.420\n",
      "Epoch  13/100 Batch   10/70 - Loss:  1.811  - Validation loss:  2.412\n",
      "Epoch  13/100 Batch   11/70 - Loss:  1.561  - Validation loss:  2.410\n",
      "Epoch  13/100 Batch   12/70 - Loss:  1.932  - Validation loss:  2.412\n",
      "Epoch  13/100 Batch   13/70 - Loss:  2.075  - Validation loss:  2.410\n",
      "Epoch  13/100 Batch   14/70 - Loss:  2.051  - Validation loss:  2.409\n",
      "Epoch  13/100 Batch   15/70 - Loss:  1.891  - Validation loss:  2.416\n",
      "Epoch  13/100 Batch   16/70 - Loss:  2.031  - Validation loss:  2.418\n",
      "Epoch  13/100 Batch   17/70 - Loss:  1.735  - Validation loss:  2.412\n",
      "Epoch  13/100 Batch   18/70 - Loss:  1.901  - Validation loss:  2.411\n",
      "Epoch  13/100 Batch   19/70 - Loss:  2.132  - Validation loss:  2.413\n",
      "Epoch  13/100 Batch   20/70 - Loss:  2.062  - Validation loss:  2.410\n",
      "Epoch  13/100 Batch   21/70 - Loss:  2.343  - Validation loss:  2.409\n",
      "Epoch  13/100 Batch   22/70 - Loss:  1.724  - Validation loss:  2.413\n",
      "Epoch  13/100 Batch   23/70 - Loss:  1.539  - Validation loss:  2.414\n",
      "Epoch  13/100 Batch   24/70 - Loss:  1.756  - Validation loss:  2.410\n",
      "Epoch  13/100 Batch   25/70 - Loss:  2.455  - Validation loss:  2.407\n",
      "Epoch  13/100 Batch   26/70 - Loss:  2.025  - Validation loss:  2.407\n",
      "Epoch  13/100 Batch   27/70 - Loss:  1.919  - Validation loss:  2.405\n",
      "Epoch  13/100 Batch   28/70 - Loss:  2.174  - Validation loss:  2.404\n",
      "Epoch  13/100 Batch   29/70 - Loss:  1.990  - Validation loss:  2.404\n",
      "Epoch  13/100 Batch   30/70 - Loss:  1.798  - Validation loss:  2.405\n",
      "Epoch  13/100 Batch   31/70 - Loss:  1.841  - Validation loss:  2.404\n",
      "Epoch  13/100 Batch   32/70 - Loss:  1.856  - Validation loss:  2.403\n",
      "Epoch  13/100 Batch   33/70 - Loss:  1.991  - Validation loss:  2.402\n",
      "Epoch  13/100 Batch   34/70 - Loss:  2.109  - Validation loss:  2.400\n",
      "Epoch  13/100 Batch   35/70 - Loss:  2.291  - Validation loss:  2.400\n",
      "Epoch  13/100 Batch   36/70 - Loss:  2.242  - Validation loss:  2.400\n",
      "Epoch  13/100 Batch   37/70 - Loss:  2.033  - Validation loss:  2.400\n",
      "Epoch  13/100 Batch   38/70 - Loss:  1.892  - Validation loss:  2.402\n",
      "Epoch  13/100 Batch   39/70 - Loss:  1.718  - Validation loss:  2.405\n",
      "Epoch  13/100 Batch   40/70 - Loss:  2.464  - Validation loss:  2.402\n",
      "Epoch  13/100 Batch   41/70 - Loss:  2.297  - Validation loss:  2.397\n",
      "Epoch  13/100 Batch   42/70 - Loss:  2.397  - Validation loss:  2.396\n",
      "Epoch  13/100 Batch   43/70 - Loss:  2.528  - Validation loss:  2.397\n",
      "Epoch  13/100 Batch   44/70 - Loss:  2.277  - Validation loss:  2.393\n",
      "Epoch  13/100 Batch   45/70 - Loss:  2.118  - Validation loss:  2.397\n",
      "Epoch  13/100 Batch   46/70 - Loss:  2.010  - Validation loss:  2.403\n",
      "Epoch  13/100 Batch   47/70 - Loss:  1.832  - Validation loss:  2.398\n",
      "Epoch  13/100 Batch   48/70 - Loss:  2.109  - Validation loss:  2.393\n",
      "Epoch  13/100 Batch   49/70 - Loss:  2.033  - Validation loss:  2.396\n",
      "Epoch  13/100 Batch   50/70 - Loss:  1.941  - Validation loss:  2.398\n",
      "Epoch  13/100 Batch   51/70 - Loss:  2.270  - Validation loss:  2.398\n",
      "Epoch  13/100 Batch   52/70 - Loss:  2.515  - Validation loss:  2.401\n",
      "Epoch  13/100 Batch   53/70 - Loss:  2.107  - Validation loss:  2.404\n",
      "Epoch  13/100 Batch   54/70 - Loss:  1.261  - Validation loss:  2.401\n",
      "Epoch  13/100 Batch   55/70 - Loss:  1.610  - Validation loss:  2.395\n",
      "Epoch  13/100 Batch   56/70 - Loss:  2.050  - Validation loss:  2.396\n",
      "Epoch  13/100 Batch   57/70 - Loss:  1.443  - Validation loss:  2.397\n",
      "Epoch  13/100 Batch   58/70 - Loss:  1.606  - Validation loss:  2.396\n",
      "Epoch  13/100 Batch   59/70 - Loss:  2.155  - Validation loss:  2.401\n",
      "Epoch  13/100 Batch   60/70 - Loss:  1.584  - Validation loss:  2.403\n",
      "Epoch  13/100 Batch   61/70 - Loss:  1.595  - Validation loss:  2.400\n",
      "Epoch  13/100 Batch   62/70 - Loss:  2.328  - Validation loss:  2.396\n",
      "Epoch  13/100 Batch   63/70 - Loss:  2.185  - Validation loss:  2.397\n",
      "Epoch  13/100 Batch   64/70 - Loss:  2.109  - Validation loss:  2.397\n",
      "Epoch  13/100 Batch   65/70 - Loss:  2.114  - Validation loss:  2.398\n",
      "Epoch  13/100 Batch   66/70 - Loss:  2.600  - Validation loss:  2.402\n",
      "Epoch  13/100 Batch   67/70 - Loss:  2.170  - Validation loss:  2.402\n",
      "Epoch  13/100 Batch   68/70 - Loss:  2.349  - Validation loss:  2.397\n",
      "Epoch  13/100 Batch   69/70 - Loss:  1.824  - Validation loss:  2.397\n",
      "Epoch  14/100 Batch    1/70 - Loss:  2.400  - Validation loss:  2.394\n",
      "Epoch  14/100 Batch    2/70 - Loss:  2.190  - Validation loss:  2.397\n",
      "Epoch  14/100 Batch    3/70 - Loss:  2.080  - Validation loss:  2.399\n",
      "Epoch  14/100 Batch    4/70 - Loss:  2.205  - Validation loss:  2.394\n",
      "Epoch  14/100 Batch    5/70 - Loss:  1.927  - Validation loss:  2.391\n",
      "Epoch  14/100 Batch    6/70 - Loss:  1.938  - Validation loss:  2.391\n",
      "Epoch  14/100 Batch    7/70 - Loss:  2.443  - Validation loss:  2.389\n",
      "Epoch  14/100 Batch    8/70 - Loss:  1.615  - Validation loss:  2.388\n",
      "Epoch  14/100 Batch    9/70 - Loss:  2.297  - Validation loss:  2.391\n",
      "Epoch  14/100 Batch   10/70 - Loss:  1.773  - Validation loss:  2.391\n",
      "Epoch  14/100 Batch   11/70 - Loss:  1.535  - Validation loss:  2.386\n",
      "Epoch  14/100 Batch   12/70 - Loss:  1.896  - Validation loss:  2.384\n",
      "Epoch  14/100 Batch   13/70 - Loss:  2.034  - Validation loss:  2.387\n",
      "Epoch  14/100 Batch   14/70 - Loss:  2.018  - Validation loss:  2.385\n",
      "Epoch  14/100 Batch   15/70 - Loss:  1.857  - Validation loss:  2.386\n",
      "Epoch  14/100 Batch   16/70 - Loss:  1.993  - Validation loss:  2.394\n",
      "Epoch  14/100 Batch   17/70 - Loss:  1.705  - Validation loss:  2.394\n",
      "Epoch  14/100 Batch   18/70 - Loss:  1.871  - Validation loss:  2.387\n",
      "Epoch  14/100 Batch   19/70 - Loss:  2.097  - Validation loss:  2.388\n",
      "Epoch  14/100 Batch   20/70 - Loss:  2.022  - Validation loss:  2.390\n",
      "Epoch  14/100 Batch   21/70 - Loss:  2.308  - Validation loss:  2.384\n",
      "Epoch  14/100 Batch   22/70 - Loss:  1.693  - Validation loss:  2.387\n",
      "Epoch  14/100 Batch   23/70 - Loss:  1.507  - Validation loss:  2.396\n",
      "Epoch  14/100 Batch   24/70 - Loss:  1.728  - Validation loss:  2.396\n",
      "Epoch  14/100 Batch   25/70 - Loss:  2.422  - Validation loss:  2.386\n",
      "Epoch  14/100 Batch   26/70 - Loss:  1.991  - Validation loss:  2.383\n",
      "Epoch  14/100 Batch   27/70 - Loss:  1.887  - Validation loss:  2.385\n",
      "Epoch  14/100 Batch   28/70 - Loss:  2.138  - Validation loss:  2.382\n",
      "Epoch  14/100 Batch   29/70 - Loss:  1.964  - Validation loss:  2.379\n",
      "Epoch  14/100 Batch   30/70 - Loss:  1.768  - Validation loss:  2.386\n",
      "Epoch  14/100 Batch   31/70 - Loss:  1.810  - Validation loss:  2.390\n",
      "Epoch  14/100 Batch   32/70 - Loss:  1.828  - Validation loss:  2.384\n",
      "Epoch  14/100 Batch   33/70 - Loss:  1.958  - Validation loss:  2.378\n",
      "Epoch  14/100 Batch   34/70 - Loss:  2.074  - Validation loss:  2.379\n",
      "Epoch  14/100 Batch   35/70 - Loss:  2.256  - Validation loss:  2.380\n",
      "Epoch  14/100 Batch   36/70 - Loss:  2.209  - Validation loss:  2.376\n",
      "Epoch  14/100 Batch   37/70 - Loss:  1.998  - Validation loss:  2.378\n",
      "Epoch  14/100 Batch   38/70 - Loss:  1.858  - Validation loss:  2.384\n",
      "Epoch  14/100 Batch   39/70 - Loss:  1.690  - Validation loss:  2.384\n",
      "Epoch  14/100 Batch   40/70 - Loss:  2.430  - Validation loss:  2.377\n",
      "Epoch  14/100 Batch   41/70 - Loss:  2.264  - Validation loss:  2.372\n",
      "Epoch  14/100 Batch   42/70 - Loss:  2.363  - Validation loss:  2.374\n",
      "Epoch  14/100 Batch   43/70 - Loss:  2.494  - Validation loss:  2.372\n",
      "Epoch  14/100 Batch   44/70 - Loss:  2.245  - Validation loss:  2.370\n",
      "Epoch  14/100 Batch   45/70 - Loss:  2.083  - Validation loss:  2.374\n",
      "Epoch  14/100 Batch   46/70 - Loss:  1.978  - Validation loss:  2.378\n",
      "Epoch  14/100 Batch   47/70 - Loss:  1.800  - Validation loss:  2.374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  14/100 Batch   48/70 - Loss:  2.071  - Validation loss:  2.371\n",
      "Epoch  14/100 Batch   49/70 - Loss:  1.999  - Validation loss:  2.373\n",
      "Epoch  14/100 Batch   50/70 - Loss:  1.909  - Validation loss:  2.375\n",
      "Epoch  14/100 Batch   51/70 - Loss:  2.236  - Validation loss:  2.374\n",
      "Epoch  14/100 Batch   52/70 - Loss:  2.478  - Validation loss:  2.374\n",
      "Epoch  14/100 Batch   53/70 - Loss:  2.069  - Validation loss:  2.376\n",
      "Epoch  14/100 Batch   54/70 - Loss:  1.235  - Validation loss:  2.375\n",
      "Epoch  14/100 Batch   55/70 - Loss:  1.581  - Validation loss:  2.372\n",
      "Epoch  14/100 Batch   56/70 - Loss:  2.018  - Validation loss:  2.373\n",
      "Epoch  14/100 Batch   57/70 - Loss:  1.415  - Validation loss:  2.374\n",
      "Epoch  14/100 Batch   58/70 - Loss:  1.579  - Validation loss:  2.374\n",
      "Epoch  14/100 Batch   59/70 - Loss:  2.122  - Validation loss:  2.376\n",
      "Epoch  14/100 Batch   60/70 - Loss:  1.555  - Validation loss:  2.377\n",
      "Epoch  14/100 Batch   61/70 - Loss:  1.565  - Validation loss:  2.376\n",
      "Epoch  14/100 Batch   62/70 - Loss:  2.293  - Validation loss:  2.373\n",
      "Epoch  14/100 Batch   63/70 - Loss:  2.156  - Validation loss:  2.372\n",
      "Epoch  14/100 Batch   64/70 - Loss:  2.080  - Validation loss:  2.372\n",
      "Epoch  14/100 Batch   65/70 - Loss:  2.081  - Validation loss:  2.372\n",
      "Epoch  14/100 Batch   66/70 - Loss:  2.563  - Validation loss:  2.375\n",
      "Epoch  14/100 Batch   67/70 - Loss:  2.136  - Validation loss:  2.379\n",
      "Epoch  14/100 Batch   68/70 - Loss:  2.316  - Validation loss:  2.376\n",
      "Epoch  14/100 Batch   69/70 - Loss:  1.799  - Validation loss:  2.374\n",
      "Epoch  15/100 Batch    1/70 - Loss:  2.359  - Validation loss:  2.372\n",
      "Epoch  15/100 Batch    2/70 - Loss:  2.157  - Validation loss:  2.371\n",
      "Epoch  15/100 Batch    3/70 - Loss:  2.045  - Validation loss:  2.373\n",
      "Epoch  15/100 Batch    4/70 - Loss:  2.168  - Validation loss:  2.373\n",
      "Epoch  15/100 Batch    5/70 - Loss:  1.898  - Validation loss:  2.370\n",
      "Epoch  15/100 Batch    6/70 - Loss:  1.907  - Validation loss:  2.367\n",
      "Epoch  15/100 Batch    7/70 - Loss:  2.407  - Validation loss:  2.367\n",
      "Epoch  15/100 Batch    8/70 - Loss:  1.588  - Validation loss:  2.364\n",
      "Epoch  15/100 Batch    9/70 - Loss:  2.263  - Validation loss:  2.364\n",
      "Epoch  15/100 Batch   10/70 - Loss:  1.742  - Validation loss:  2.368\n",
      "Epoch  15/100 Batch   11/70 - Loss:  1.507  - Validation loss:  2.368\n",
      "Epoch  15/100 Batch   12/70 - Loss:  1.866  - Validation loss:  2.363\n",
      "Epoch  15/100 Batch   13/70 - Loss:  2.000  - Validation loss:  2.364\n",
      "Epoch  15/100 Batch   14/70 - Loss:  1.983  - Validation loss:  2.365\n",
      "Epoch  15/100 Batch   15/70 - Loss:  1.826  - Validation loss:  2.364\n",
      "Epoch  15/100 Batch   16/70 - Loss:  1.962  - Validation loss:  2.371\n",
      "Epoch  15/100 Batch   17/70 - Loss:  1.677  - Validation loss:  2.377\n",
      "Epoch  15/100 Batch   18/70 - Loss:  1.843  - Validation loss:  2.370\n",
      "Epoch  15/100 Batch   19/70 - Loss:  2.068  - Validation loss:  2.363\n",
      "Epoch  15/100 Batch   20/70 - Loss:  1.985  - Validation loss:  2.368\n",
      "Epoch  15/100 Batch   21/70 - Loss:  2.273  - Validation loss:  2.366\n",
      "Epoch  15/100 Batch   22/70 - Loss:  1.667  - Validation loss:  2.363\n",
      "Epoch  15/100 Batch   23/70 - Loss:  1.479  - Validation loss:  2.375\n",
      "Epoch  15/100 Batch   24/70 - Loss:  1.699  - Validation loss:  2.383\n",
      "Epoch  15/100 Batch   25/70 - Loss:  2.392  - Validation loss:  2.372\n",
      "Epoch  15/100 Batch   26/70 - Loss:  1.964  - Validation loss:  2.361\n",
      "Epoch  15/100 Batch   27/70 - Loss:  1.858  - Validation loss:  2.365\n",
      "Epoch  15/100 Batch   28/70 - Loss:  2.103  - Validation loss:  2.366\n",
      "Epoch  15/100 Batch   29/70 - Loss:  1.943  - Validation loss:  2.357\n",
      "Epoch  15/100 Batch   30/70 - Loss:  1.743  - Validation loss:  2.364\n",
      "Epoch  15/100 Batch   31/70 - Loss:  1.780  - Validation loss:  2.375\n",
      "Epoch  15/100 Batch   32/70 - Loss:  1.803  - Validation loss:  2.370\n",
      "Epoch  15/100 Batch   33/70 - Loss:  1.929  - Validation loss:  2.359\n",
      "Epoch  15/100 Batch   34/70 - Loss:  2.042  - Validation loss:  2.361\n",
      "Epoch  15/100 Batch   35/70 - Loss:  2.225  - Validation loss:  2.365\n",
      "Epoch  15/100 Batch   36/70 - Loss:  2.181  - Validation loss:  2.357\n",
      "Epoch  15/100 Batch   37/70 - Loss:  1.971  - Validation loss:  2.357\n",
      "Epoch  15/100 Batch   38/70 - Loss:  1.828  - Validation loss:  2.367\n",
      "Epoch  15/100 Batch   39/70 - Loss:  1.664  - Validation loss:  2.370\n",
      "Epoch  15/100 Batch   40/70 - Loss:  2.400  - Validation loss:  2.358\n",
      "Epoch  15/100 Batch   41/70 - Loss:  2.235  - Validation loss:  2.351\n",
      "Epoch  15/100 Batch   42/70 - Loss:  2.333  - Validation loss:  2.355\n",
      "Epoch  15/100 Batch   43/70 - Loss:  2.465  - Validation loss:  2.353\n",
      "Epoch  15/100 Batch   44/70 - Loss:  2.220  - Validation loss:  2.350\n",
      "Epoch  15/100 Batch   45/70 - Loss:  2.050  - Validation loss:  2.357\n",
      "Epoch  15/100 Batch   46/70 - Loss:  1.950  - Validation loss:  2.362\n",
      "Epoch  15/100 Batch   47/70 - Loss:  1.776  - Validation loss:  2.356\n",
      "Epoch  15/100 Batch   48/70 - Loss:  2.039  - Validation loss:  2.351\n",
      "Epoch  15/100 Batch   49/70 - Loss:  1.969  - Validation loss:  2.354\n",
      "Epoch  15/100 Batch   50/70 - Loss:  1.882  - Validation loss:  2.356\n",
      "Epoch  15/100 Batch   51/70 - Loss:  2.204  - Validation loss:  2.354\n",
      "Epoch  15/100 Batch   52/70 - Loss:  2.444  - Validation loss:  2.354\n",
      "Epoch  15/100 Batch   53/70 - Loss:  2.036  - Validation loss:  2.357\n",
      "Epoch  15/100 Batch   54/70 - Loss:  1.215  - Validation loss:  2.356\n",
      "Epoch  15/100 Batch   55/70 - Loss:  1.557  - Validation loss:  2.351\n",
      "Epoch  15/100 Batch   56/70 - Loss:  1.991  - Validation loss:  2.352\n",
      "Epoch  15/100 Batch   57/70 - Loss:  1.392  - Validation loss:  2.354\n",
      "Epoch  15/100 Batch   58/70 - Loss:  1.555  - Validation loss:  2.353\n",
      "Epoch  15/100 Batch   59/70 - Loss:  2.092  - Validation loss:  2.355\n",
      "Epoch  15/100 Batch   60/70 - Loss:  1.531  - Validation loss:  2.357\n",
      "Epoch  15/100 Batch   61/70 - Loss:  1.543  - Validation loss:  2.356\n",
      "Epoch  15/100 Batch   62/70 - Loss:  2.263  - Validation loss:  2.352\n",
      "Epoch  15/100 Batch   63/70 - Loss:  2.128  - Validation loss:  2.350\n",
      "Epoch  15/100 Batch   64/70 - Loss:  2.055  - Validation loss:  2.351\n",
      "Epoch  15/100 Batch   65/70 - Loss:  2.053  - Validation loss:  2.351\n",
      "Epoch  15/100 Batch   66/70 - Loss:  2.531  - Validation loss:  2.354\n",
      "Epoch  15/100 Batch   67/70 - Loss:  2.106  - Validation loss:  2.359\n",
      "Epoch  15/100 Batch   68/70 - Loss:  2.286  - Validation loss:  2.357\n",
      "Epoch  15/100 Batch   69/70 - Loss:  1.776  - Validation loss:  2.353\n",
      "Epoch  16/100 Batch    1/70 - Loss:  2.323  - Validation loss:  2.352\n",
      "Epoch  16/100 Batch    2/70 - Loss:  2.127  - Validation loss:  2.350\n",
      "Epoch  16/100 Batch    3/70 - Loss:  2.016  - Validation loss:  2.352\n",
      "Epoch  16/100 Batch    4/70 - Loss:  2.136  - Validation loss:  2.355\n",
      "Epoch  16/100 Batch    5/70 - Loss:  1.872  - Validation loss:  2.352\n",
      "Epoch  16/100 Batch    6/70 - Loss:  1.881  - Validation loss:  2.347\n",
      "Epoch  16/100 Batch    7/70 - Loss:  2.375  - Validation loss:  2.346\n",
      "Epoch  16/100 Batch    8/70 - Loss:  1.563  - Validation loss:  2.345\n",
      "Epoch  16/100 Batch    9/70 - Loss:  2.235  - Validation loss:  2.343\n",
      "Epoch  16/100 Batch   10/70 - Loss:  1.717  - Validation loss:  2.347\n",
      "Epoch  16/100 Batch   11/70 - Loss:  1.482  - Validation loss:  2.352\n",
      "Epoch  16/100 Batch   12/70 - Loss:  1.838  - Validation loss:  2.347\n",
      "Epoch  16/100 Batch   13/70 - Loss:  1.970  - Validation loss:  2.344\n",
      "Epoch  16/100 Batch   14/70 - Loss:  1.952  - Validation loss:  2.348\n",
      "Epoch  16/100 Batch   15/70 - Loss:  1.797  - Validation loss:  2.346\n",
      "Epoch  16/100 Batch   16/70 - Loss:  1.935  - Validation loss:  2.348\n",
      "Epoch  16/100 Batch   17/70 - Loss:  1.650  - Validation loss:  2.358\n",
      "Epoch  16/100 Batch   18/70 - Loss:  1.814  - Validation loss:  2.357\n",
      "Epoch  16/100 Batch   19/70 - Loss:  2.041  - Validation loss:  2.346\n",
      "Epoch  16/100 Batch   20/70 - Loss:  1.954  - Validation loss:  2.348\n",
      "Epoch  16/100 Batch   21/70 - Loss:  2.239  - Validation loss:  2.353\n",
      "Epoch  16/100 Batch   22/70 - Loss:  1.646  - Validation loss:  2.344\n",
      "Epoch  16/100 Batch   23/70 - Loss:  1.458  - Validation loss:  2.353\n",
      "Epoch  16/100 Batch   24/70 - Loss:  1.672  - Validation loss:  2.369\n",
      "Epoch  16/100 Batch   25/70 - Loss:  2.363  - Validation loss:  2.362\n",
      "Epoch  16/100 Batch   26/70 - Loss:  1.942  - Validation loss:  2.345\n",
      "Epoch  16/100 Batch   27/70 - Loss:  1.835  - Validation loss:  2.344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  16/100 Batch   28/70 - Loss:  2.069  - Validation loss:  2.356\n",
      "Epoch  16/100 Batch   29/70 - Loss:  1.924  - Validation loss:  2.343\n",
      "Epoch  16/100 Batch   30/70 - Loss:  1.724  - Validation loss:  2.342\n",
      "Epoch  16/100 Batch   31/70 - Loss:  1.751  - Validation loss:  2.361\n",
      "Epoch  16/100 Batch   32/70 - Loss:  1.779  - Validation loss:  2.366\n",
      "Epoch  16/100 Batch   33/70 - Loss:  1.909  - Validation loss:  2.349\n",
      "Epoch  16/100 Batch   34/70 - Loss:  2.019  - Validation loss:  2.342\n",
      "Epoch  16/100 Batch   35/70 - Loss:  2.192  - Validation loss:  2.356\n",
      "Epoch  16/100 Batch   36/70 - Loss:  2.158  - Validation loss:  2.351\n",
      "Epoch  16/100 Batch   37/70 - Loss:  1.959  - Validation loss:  2.336\n",
      "Epoch  16/100 Batch   38/70 - Loss:  1.803  - Validation loss:  2.350\n",
      "Epoch  16/100 Batch   39/70 - Loss:  1.639  - Validation loss:  2.367\n",
      "Epoch  16/100 Batch   40/70 - Loss:  2.382  - Validation loss:  2.356\n",
      "Epoch  16/100 Batch   41/70 - Loss:  2.218  - Validation loss:  2.336\n",
      "Epoch  16/100 Batch   42/70 - Loss:  2.306  - Validation loss:  2.339\n",
      "Epoch  16/100 Batch   43/70 - Loss:  2.438  - Validation loss:  2.353\n",
      "Epoch  16/100 Batch   44/70 - Loss:  2.210  - Validation loss:  2.336\n",
      "Epoch  16/100 Batch   45/70 - Loss:  2.027  - Validation loss:  2.337\n",
      "Epoch  16/100 Batch   46/70 - Loss:  1.923  - Validation loss:  2.358\n",
      "Epoch  16/100 Batch   47/70 - Loss:  1.763  - Validation loss:  2.360\n",
      "Epoch  16/100 Batch   48/70 - Loss:  2.026  - Validation loss:  2.343\n",
      "Epoch  16/100 Batch   49/70 - Loss:  1.948  - Validation loss:  2.335\n",
      "Epoch  16/100 Batch   50/70 - Loss:  1.855  - Validation loss:  2.345\n",
      "Epoch  16/100 Batch   51/70 - Loss:  2.184  - Validation loss:  2.344\n",
      "Epoch  16/100 Batch   52/70 - Loss:  2.424  - Validation loss:  2.332\n",
      "Epoch  16/100 Batch   53/70 - Loss:  2.010  - Validation loss:  2.336\n",
      "Epoch  16/100 Batch   54/70 - Loss:  1.197  - Validation loss:  2.350\n",
      "Epoch  16/100 Batch   55/70 - Loss:  1.547  - Validation loss:  2.348\n",
      "Epoch  16/100 Batch   56/70 - Loss:  1.975  - Validation loss:  2.336\n",
      "Epoch  16/100 Batch   57/70 - Loss:  1.373  - Validation loss:  2.335\n",
      "Epoch  16/100 Batch   58/70 - Loss:  1.535  - Validation loss:  2.341\n",
      "Epoch  16/100 Batch   59/70 - Loss:  2.075  - Validation loss:  2.335\n",
      "Epoch  16/100 Batch   60/70 - Loss:  1.514  - Validation loss:  2.334\n",
      "Epoch  16/100 Batch   61/70 - Loss:  1.522  - Validation loss:  2.346\n",
      "Epoch  16/100 Batch   62/70 - Loss:  2.242  - Validation loss:  2.349\n",
      "Epoch  16/100 Batch   63/70 - Loss:  2.116  - Validation loss:  2.338\n",
      "Epoch  16/100 Batch   64/70 - Loss:  2.037  - Validation loss:  2.335\n",
      "Epoch  16/100 Batch   65/70 - Loss:  2.032  - Validation loss:  2.342\n",
      "Epoch  16/100 Batch   66/70 - Loss:  2.513  - Validation loss:  2.337\n",
      "Epoch  16/100 Batch   67/70 - Loss:  2.085  - Validation loss:  2.341\n",
      "Epoch  16/100 Batch   68/70 - Loss:  2.261  - Validation loss:  2.351\n",
      "Epoch  16/100 Batch   69/70 - Loss:  1.761  - Validation loss:  2.351\n",
      "Epoch  17/100 Batch    1/70 - Loss:  2.294  - Validation loss:  2.333\n",
      "Epoch  17/100 Batch    2/70 - Loss:  2.099  - Validation loss:  2.340\n",
      "Epoch  17/100 Batch    3/70 - Loss:  2.004  - Validation loss:  2.336\n",
      "Epoch  17/100 Batch    4/70 - Loss:  2.117  - Validation loss:  2.334\n",
      "Epoch  17/100 Batch    5/70 - Loss:  1.848  - Validation loss:  2.344\n",
      "Epoch  17/100 Batch    6/70 - Loss:  1.862  - Validation loss:  2.346\n",
      "Epoch  17/100 Batch    7/70 - Loss:  2.358  - Validation loss:  2.334\n",
      "Epoch  17/100 Batch    8/70 - Loss:  1.543  - Validation loss:  2.327\n",
      "Epoch  17/100 Batch    9/70 - Loss:  2.206  - Validation loss:  2.331\n",
      "Epoch  17/100 Batch   10/70 - Loss:  1.704  - Validation loss:  2.329\n",
      "Epoch  17/100 Batch   11/70 - Loss:  1.469  - Validation loss:  2.328\n",
      "Epoch  17/100 Batch   12/70 - Loss:  1.806  - Validation loss:  2.337\n",
      "Epoch  17/100 Batch   13/70 - Loss:  1.949  - Validation loss:  2.339\n",
      "Epoch  17/100 Batch   14/70 - Loss:  1.936  - Validation loss:  2.331\n",
      "Epoch  17/100 Batch   15/70 - Loss:  1.766  - Validation loss:  2.331\n",
      "Epoch  17/100 Batch   16/70 - Loss:  1.909  - Validation loss:  2.333\n",
      "Epoch  17/100 Batch   17/70 - Loss:  1.640  - Validation loss:  2.329\n",
      "Epoch  17/100 Batch   18/70 - Loss:  1.785  - Validation loss:  2.333\n",
      "Epoch  17/100 Batch   19/70 - Loss:  2.008  - Validation loss:  2.340\n",
      "Epoch  17/100 Batch   20/70 - Loss:  1.936  - Validation loss:  2.333\n",
      "Epoch  17/100 Batch   21/70 - Loss:  2.214  - Validation loss:  2.327\n",
      "Epoch  17/100 Batch   22/70 - Loss:  1.612  - Validation loss:  2.332\n",
      "Epoch  17/100 Batch   23/70 - Loss:  1.445  - Validation loss:  2.332\n",
      "Epoch  17/100 Batch   24/70 - Loss:  1.659  - Validation loss:  2.330\n",
      "Epoch  17/100 Batch   25/70 - Loss:  2.325  - Validation loss:  2.342\n",
      "Epoch  17/100 Batch   26/70 - Loss:  1.914  - Validation loss:  2.350\n",
      "Epoch  17/100 Batch   27/70 - Loss:  1.829  - Validation loss:  2.338\n",
      "Epoch  17/100 Batch   28/70 - Loss:  2.051  - Validation loss:  2.324\n",
      "Epoch  17/100 Batch   29/70 - Loss:  1.887  - Validation loss:  2.331\n",
      "Epoch  17/100 Batch   30/70 - Loss:  1.706  - Validation loss:  2.334\n",
      "Epoch  17/100 Batch   31/70 - Loss:  1.749  - Validation loss:  2.322\n",
      "Epoch  17/100 Batch   32/70 - Loss:  1.747  - Validation loss:  2.336\n",
      "Epoch  17/100 Batch   33/70 - Loss:  1.870  - Validation loss:  2.355\n",
      "Epoch  17/100 Batch   34/70 - Loss:  2.013  - Validation loss:  2.347\n",
      "Epoch  17/100 Batch   35/70 - Loss:  2.187  - Validation loss:  2.326\n",
      "Epoch  17/100 Batch   36/70 - Loss:  2.124  - Validation loss:  2.330\n",
      "Epoch  17/100 Batch   37/70 - Loss:  1.929  - Validation loss:  2.344\n",
      "Epoch  17/100 Batch   38/70 - Loss:  1.811  - Validation loss:  2.326\n",
      "Epoch  17/100 Batch   39/70 - Loss:  1.622  - Validation loss:  2.329\n",
      "Epoch  17/100 Batch   40/70 - Loss:  2.347  - Validation loss:  2.339\n",
      "Epoch  17/100 Batch   41/70 - Loss:  2.195  - Validation loss:  2.344\n",
      "Epoch  17/100 Batch   42/70 - Loss:  2.306  - Validation loss:  2.332\n",
      "Epoch  17/100 Batch   43/70 - Loss:  2.423  - Validation loss:  2.319\n",
      "Epoch  17/100 Batch   44/70 - Loss:  2.170  - Validation loss:  2.331\n",
      "Epoch  17/100 Batch   45/70 - Loss:  2.011  - Validation loss:  2.334\n",
      "Epoch  17/100 Batch   46/70 - Loss:  1.924  - Validation loss:  2.319\n",
      "Epoch  17/100 Batch   47/70 - Loss:  1.735  - Validation loss:  2.322\n",
      "Epoch  17/100 Batch   48/70 - Loss:  1.987  - Validation loss:  2.341\n",
      "Epoch  17/100 Batch   49/70 - Loss:  1.935  - Validation loss:  2.347\n",
      "Epoch  17/100 Batch   50/70 - Loss:  1.857  - Validation loss:  2.336\n",
      "Epoch  17/100 Batch   51/70 - Loss:  2.167  - Validation loss:  2.326\n",
      "Epoch  17/100 Batch   52/70 - Loss:  2.391  - Validation loss:  2.331\n",
      "Epoch  17/100 Batch   53/70 - Loss:  2.000  - Validation loss:  2.331\n",
      "Epoch  17/100 Batch   54/70 - Loss:  1.197  - Validation loss:  2.319\n",
      "Epoch  17/100 Batch   55/70 - Loss:  1.527  - Validation loss:  2.317\n",
      "Epoch  17/100 Batch   56/70 - Loss:  1.946  - Validation loss:  2.328\n",
      "Epoch  17/100 Batch   57/70 - Loss:  1.368  - Validation loss:  2.334\n",
      "Epoch  17/100 Batch   58/70 - Loss:  1.531  - Validation loss:  2.330\n",
      "Epoch  17/100 Batch   59/70 - Loss:  2.051  - Validation loss:  2.326\n",
      "Epoch  17/100 Batch   60/70 - Loss:  1.498  - Validation loss:  2.328\n",
      "Epoch  17/100 Batch   61/70 - Loss:  1.520  - Validation loss:  2.323\n",
      "Epoch  17/100 Batch   62/70 - Loss:  2.226  - Validation loss:  2.317\n",
      "Epoch  17/100 Batch   63/70 - Loss:  2.083  - Validation loss:  2.327\n",
      "Epoch  17/100 Batch   64/70 - Loss:  2.019  - Validation loss:  2.333\n",
      "Epoch  17/100 Batch   65/70 - Loss:  2.021  - Validation loss:  2.327\n",
      "Epoch  17/100 Batch   66/70 - Loss:  2.484  - Validation loss:  2.318\n",
      "Epoch  17/100 Batch   67/70 - Loss:  2.057  - Validation loss:  2.320\n",
      "Epoch  17/100 Batch   68/70 - Loss:  2.241  - Validation loss:  2.326\n",
      "Epoch  17/100 Batch   69/70 - Loss:  1.743  - Validation loss:  2.325\n",
      "Epoch  18/100 Batch    1/70 - Loss:  2.263  - Validation loss:  2.323\n",
      "Epoch  18/100 Batch    2/70 - Loss:  2.076  - Validation loss:  2.322\n",
      "Epoch  18/100 Batch    3/70 - Loss:  1.973  - Validation loss:  2.318\n",
      "Epoch  18/100 Batch    4/70 - Loss:  2.086  - Validation loss:  2.315\n",
      "Epoch  18/100 Batch    5/70 - Loss:  1.828  - Validation loss:  2.314\n",
      "Epoch  18/100 Batch    6/70 - Loss:  1.837  - Validation loss:  2.313\n",
      "Epoch  18/100 Batch    7/70 - Loss:  2.329  - Validation loss:  2.314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  18/100 Batch    8/70 - Loss:  1.521  - Validation loss:  2.317\n",
      "Epoch  18/100 Batch    9/70 - Loss:  2.184  - Validation loss:  2.316\n",
      "Epoch  18/100 Batch   10/70 - Loss:  1.676  - Validation loss:  2.312\n",
      "Epoch  18/100 Batch   11/70 - Loss:  1.444  - Validation loss:  2.310\n",
      "Epoch  18/100 Batch   12/70 - Loss:  1.782  - Validation loss:  2.310\n",
      "Epoch  18/100 Batch   13/70 - Loss:  1.921  - Validation loss:  2.310\n",
      "Epoch  18/100 Batch   14/70 - Loss:  1.904  - Validation loss:  2.311\n",
      "Epoch  18/100 Batch   15/70 - Loss:  1.740  - Validation loss:  2.313\n",
      "Epoch  18/100 Batch   16/70 - Loss:  1.880  - Validation loss:  2.315\n",
      "Epoch  18/100 Batch   17/70 - Loss:  1.611  - Validation loss:  2.315\n",
      "Epoch  18/100 Batch   18/70 - Loss:  1.761  - Validation loss:  2.314\n",
      "Epoch  18/100 Batch   19/70 - Loss:  1.982  - Validation loss:  2.312\n",
      "Epoch  18/100 Batch   20/70 - Loss:  1.899  - Validation loss:  2.310\n",
      "Epoch  18/100 Batch   21/70 - Loss:  2.182  - Validation loss:  2.309\n",
      "Epoch  18/100 Batch   22/70 - Loss:  1.590  - Validation loss:  2.309\n",
      "Epoch  18/100 Batch   23/70 - Loss:  1.418  - Validation loss:  2.309\n",
      "Epoch  18/100 Batch   24/70 - Loss:  1.628  - Validation loss:  2.310\n",
      "Epoch  18/100 Batch   25/70 - Loss:  2.297  - Validation loss:  2.313\n",
      "Epoch  18/100 Batch   26/70 - Loss:  1.887  - Validation loss:  2.316\n",
      "Epoch  18/100 Batch   27/70 - Loss:  1.794  - Validation loss:  2.315\n",
      "Epoch  18/100 Batch   28/70 - Loss:  2.014  - Validation loss:  2.310\n",
      "Epoch  18/100 Batch   29/70 - Loss:  1.865  - Validation loss:  2.307\n",
      "Epoch  18/100 Batch   30/70 - Loss:  1.674  - Validation loss:  2.308\n",
      "Epoch  18/100 Batch   31/70 - Loss:  1.710  - Validation loss:  2.305\n",
      "Epoch  18/100 Batch   32/70 - Loss:  1.726  - Validation loss:  2.306\n",
      "Epoch  18/100 Batch   33/70 - Loss:  1.841  - Validation loss:  2.313\n",
      "Epoch  18/100 Batch   34/70 - Loss:  1.969  - Validation loss:  2.318\n",
      "Epoch  18/100 Batch   35/70 - Loss:  2.143  - Validation loss:  2.312\n",
      "Epoch  18/100 Batch   36/70 - Loss:  2.099  - Validation loss:  2.306\n",
      "Epoch  18/100 Batch   37/70 - Loss:  1.898  - Validation loss:  2.311\n",
      "Epoch  18/100 Batch   38/70 - Loss:  1.764  - Validation loss:  2.310\n",
      "Epoch  18/100 Batch   39/70 - Loss:  1.602  - Validation loss:  2.302\n",
      "Epoch  18/100 Batch   40/70 - Loss:  2.319  - Validation loss:  2.308\n",
      "Epoch  18/100 Batch   41/70 - Loss:  2.159  - Validation loss:  2.322\n",
      "Epoch  18/100 Batch   42/70 - Loss:  2.270  - Validation loss:  2.318\n",
      "Epoch  18/100 Batch   43/70 - Loss:  2.397  - Validation loss:  2.304\n",
      "Epoch  18/100 Batch   44/70 - Loss:  2.147  - Validation loss:  2.305\n",
      "Epoch  18/100 Batch   45/70 - Loss:  1.969  - Validation loss:  2.317\n",
      "Epoch  18/100 Batch   46/70 - Loss:  1.894  - Validation loss:  2.307\n",
      "Epoch  18/100 Batch   47/70 - Loss:  1.717  - Validation loss:  2.301\n",
      "Epoch  18/100 Batch   48/70 - Loss:  1.959  - Validation loss:  2.315\n",
      "Epoch  18/100 Batch   49/70 - Loss:  1.907  - Validation loss:  2.326\n",
      "Epoch  18/100 Batch   50/70 - Loss:  1.833  - Validation loss:  2.320\n",
      "Epoch  18/100 Batch   51/70 - Loss:  2.141  - Validation loss:  2.307\n",
      "Epoch  18/100 Batch   52/70 - Loss:  2.357  - Validation loss:  2.308\n",
      "Epoch  18/100 Batch   53/70 - Loss:  1.966  - Validation loss:  2.317\n",
      "Epoch  18/100 Batch   54/70 - Loss:  1.177  - Validation loss:  2.311\n",
      "Epoch  18/100 Batch   55/70 - Loss:  1.515  - Validation loss:  2.301\n",
      "Epoch  18/100 Batch   56/70 - Loss:  1.924  - Validation loss:  2.308\n",
      "Epoch  18/100 Batch   57/70 - Loss:  1.345  - Validation loss:  2.317\n",
      "Epoch  18/100 Batch   58/70 - Loss:  1.510  - Validation loss:  2.316\n",
      "Epoch  18/100 Batch   59/70 - Loss:  2.032  - Validation loss:  2.308\n",
      "Epoch  18/100 Batch   60/70 - Loss:  1.479  - Validation loss:  2.305\n",
      "Epoch  18/100 Batch   61/70 - Loss:  1.493  - Validation loss:  2.307\n",
      "Epoch  18/100 Batch   62/70 - Loss:  2.203  - Validation loss:  2.302\n",
      "Epoch  18/100 Batch   63/70 - Loss:  2.066  - Validation loss:  2.302\n",
      "Epoch  18/100 Batch   64/70 - Loss:  1.991  - Validation loss:  2.310\n",
      "Epoch  18/100 Batch   65/70 - Loss:  1.990  - Validation loss:  2.315\n",
      "Epoch  18/100 Batch   66/70 - Loss:  2.459  - Validation loss:  2.310\n",
      "Epoch  18/100 Batch   67/70 - Loss:  2.038  - Validation loss:  2.303\n",
      "Epoch  18/100 Batch   68/70 - Loss:  2.214  - Validation loss:  2.304\n",
      "Epoch  18/100 Batch   69/70 - Loss:  1.717  - Validation loss:  2.308\n",
      "Epoch  19/100 Batch    1/70 - Loss:  2.236  - Validation loss:  2.303\n",
      "Epoch  19/100 Batch    2/70 - Loss:  2.048  - Validation loss:  2.303\n",
      "Epoch  19/100 Batch    3/70 - Loss:  1.946  - Validation loss:  2.303\n",
      "Epoch  19/100 Batch    4/70 - Loss:  2.063  - Validation loss:  2.301\n",
      "Epoch  19/100 Batch    5/70 - Loss:  1.806  - Validation loss:  2.297\n",
      "Epoch  19/100 Batch    6/70 - Loss:  1.811  - Validation loss:  2.295\n",
      "Epoch  19/100 Batch    7/70 - Loss:  2.302  - Validation loss:  2.295\n",
      "Epoch  19/100 Batch    8/70 - Loss:  1.504  - Validation loss:  2.295\n",
      "Epoch  19/100 Batch    9/70 - Loss:  2.159  - Validation loss:  2.296\n",
      "Epoch  19/100 Batch   10/70 - Loss:  1.654  - Validation loss:  2.297\n",
      "Epoch  19/100 Batch   11/70 - Loss:  1.426  - Validation loss:  2.298\n",
      "Epoch  19/100 Batch   12/70 - Loss:  1.759  - Validation loss:  2.296\n",
      "Epoch  19/100 Batch   13/70 - Loss:  1.897  - Validation loss:  2.295\n",
      "Epoch  19/100 Batch   14/70 - Loss:  1.879  - Validation loss:  2.294\n",
      "Epoch  19/100 Batch   15/70 - Loss:  1.717  - Validation loss:  2.295\n",
      "Epoch  19/100 Batch   16/70 - Loss:  1.858  - Validation loss:  2.296\n",
      "Epoch  19/100 Batch   17/70 - Loss:  1.592  - Validation loss:  2.298\n",
      "Epoch  19/100 Batch   18/70 - Loss:  1.740  - Validation loss:  2.300\n",
      "Epoch  19/100 Batch   19/70 - Loss:  1.959  - Validation loss:  2.299\n",
      "Epoch  19/100 Batch   20/70 - Loss:  1.875  - Validation loss:  2.296\n",
      "Epoch  19/100 Batch   21/70 - Loss:  2.158  - Validation loss:  2.294\n",
      "Epoch  19/100 Batch   22/70 - Loss:  1.571  - Validation loss:  2.294\n",
      "Epoch  19/100 Batch   23/70 - Loss:  1.401  - Validation loss:  2.293\n",
      "Epoch  19/100 Batch   24/70 - Loss:  1.611  - Validation loss:  2.294\n",
      "Epoch  19/100 Batch   25/70 - Loss:  2.273  - Validation loss:  2.299\n",
      "Epoch  19/100 Batch   26/70 - Loss:  1.869  - Validation loss:  2.303\n",
      "Epoch  19/100 Batch   27/70 - Loss:  1.777  - Validation loss:  2.300\n",
      "Epoch  19/100 Batch   28/70 - Loss:  1.990  - Validation loss:  2.293\n",
      "Epoch  19/100 Batch   29/70 - Loss:  1.844  - Validation loss:  2.291\n",
      "Epoch  19/100 Batch   30/70 - Loss:  1.656  - Validation loss:  2.293\n",
      "Epoch  19/100 Batch   31/70 - Loss:  1.690  - Validation loss:  2.290\n",
      "Epoch  19/100 Batch   32/70 - Loss:  1.705  - Validation loss:  2.290\n",
      "Epoch  19/100 Batch   33/70 - Loss:  1.815  - Validation loss:  2.298\n",
      "Epoch  19/100 Batch   34/70 - Loss:  1.946  - Validation loss:  2.302\n",
      "Epoch  19/100 Batch   35/70 - Loss:  2.117  - Validation loss:  2.296\n",
      "Epoch  19/100 Batch   36/70 - Loss:  2.076  - Validation loss:  2.288\n",
      "Epoch  19/100 Batch   37/70 - Loss:  1.878  - Validation loss:  2.291\n",
      "Epoch  19/100 Batch   38/70 - Loss:  1.740  - Validation loss:  2.295\n",
      "Epoch  19/100 Batch   39/70 - Loss:  1.581  - Validation loss:  2.289\n",
      "Epoch  19/100 Batch   40/70 - Loss:  2.299  - Validation loss:  2.290\n",
      "Epoch  19/100 Batch   41/70 - Loss:  2.136  - Validation loss:  2.304\n",
      "Epoch  19/100 Batch   42/70 - Loss:  2.238  - Validation loss:  2.305\n",
      "Epoch  19/100 Batch   43/70 - Loss:  2.372  - Validation loss:  2.293\n",
      "Epoch  19/100 Batch   44/70 - Loss:  2.128  - Validation loss:  2.287\n",
      "Epoch  19/100 Batch   45/70 - Loss:  1.940  - Validation loss:  2.296\n",
      "Epoch  19/100 Batch   46/70 - Loss:  1.864  - Validation loss:  2.297\n",
      "Epoch  19/100 Batch   47/70 - Loss:  1.703  - Validation loss:  2.286\n",
      "Epoch  19/100 Batch   48/70 - Loss:  1.938  - Validation loss:  2.293\n",
      "Epoch  19/100 Batch   49/70 - Loss:  1.882  - Validation loss:  2.307\n",
      "Epoch  19/100 Batch   50/70 - Loss:  1.808  - Validation loss:  2.309\n",
      "Epoch  19/100 Batch   51/70 - Loss:  2.120  - Validation loss:  2.296\n",
      "Epoch  19/100 Batch   52/70 - Loss:  2.332  - Validation loss:  2.289\n",
      "Epoch  19/100 Batch   53/70 - Loss:  1.939  - Validation loss:  2.295\n",
      "Epoch  19/100 Batch   54/70 - Loss:  1.154  - Validation loss:  2.299\n",
      "Epoch  19/100 Batch   55/70 - Loss:  1.500  - Validation loss:  2.289\n",
      "Epoch  19/100 Batch   56/70 - Loss:  1.907  - Validation loss:  2.287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  19/100 Batch   57/70 - Loss:  1.325  - Validation loss:  2.297\n",
      "Epoch  19/100 Batch   58/70 - Loss:  1.485  - Validation loss:  2.304\n",
      "Epoch  19/100 Batch   59/70 - Loss:  2.010  - Validation loss:  2.300\n",
      "Epoch  19/100 Batch   60/70 - Loss:  1.464  - Validation loss:  2.292\n",
      "Epoch  19/100 Batch   61/70 - Loss:  1.475  - Validation loss:  2.291\n",
      "Epoch  19/100 Batch   62/70 - Loss:  2.177  - Validation loss:  2.289\n",
      "Epoch  19/100 Batch   63/70 - Loss:  2.046  - Validation loss:  2.286\n",
      "Epoch  19/100 Batch   64/70 - Loss:  1.974  - Validation loss:  2.289\n",
      "Epoch  19/100 Batch   65/70 - Loss:  1.967  - Validation loss:  2.296\n",
      "Epoch  19/100 Batch   66/70 - Loss:  2.431  - Validation loss:  2.297\n",
      "Epoch  19/100 Batch   67/70 - Loss:  2.015  - Validation loss:  2.292\n",
      "Epoch  19/100 Batch   68/70 - Loss:  2.193  - Validation loss:  2.288\n",
      "Epoch  19/100 Batch   69/70 - Loss:  1.698  - Validation loss:  2.291\n",
      "Epoch  20/100 Batch    1/70 - Loss:  2.210  - Validation loss:  2.289\n",
      "Epoch  20/100 Batch    2/70 - Loss:  2.028  - Validation loss:  2.287\n",
      "Epoch  20/100 Batch    3/70 - Loss:  1.924  - Validation loss:  2.288\n",
      "Epoch  20/100 Batch    4/70 - Loss:  2.039  - Validation loss:  2.289\n",
      "Epoch  20/100 Batch    5/70 - Loss:  1.787  - Validation loss:  2.286\n",
      "Epoch  20/100 Batch    6/70 - Loss:  1.792  - Validation loss:  2.281\n",
      "Epoch  20/100 Batch    7/70 - Loss:  2.280  - Validation loss:  2.279\n",
      "Epoch  20/100 Batch    8/70 - Loss:  1.488  - Validation loss:  2.280\n",
      "Epoch  20/100 Batch    9/70 - Loss:  2.139  - Validation loss:  2.280\n",
      "Epoch  20/100 Batch   10/70 - Loss:  1.637  - Validation loss:  2.281\n",
      "Epoch  20/100 Batch   11/70 - Loss:  1.410  - Validation loss:  2.284\n",
      "Epoch  20/100 Batch   12/70 - Loss:  1.738  - Validation loss:  2.286\n",
      "Epoch  20/100 Batch   13/70 - Loss:  1.878  - Validation loss:  2.283\n",
      "Epoch  20/100 Batch   14/70 - Loss:  1.857  - Validation loss:  2.280\n",
      "Epoch  20/100 Batch   15/70 - Loss:  1.694  - Validation loss:  2.280\n",
      "Epoch  20/100 Batch   16/70 - Loss:  1.838  - Validation loss:  2.281\n",
      "Epoch  20/100 Batch   17/70 - Loss:  1.577  - Validation loss:  2.281\n",
      "Epoch  20/100 Batch   18/70 - Loss:  1.721  - Validation loss:  2.284\n",
      "Epoch  20/100 Batch   19/70 - Loss:  1.936  - Validation loss:  2.286\n",
      "Epoch  20/100 Batch   20/70 - Loss:  1.852  - Validation loss:  2.284\n",
      "Epoch  20/100 Batch   21/70 - Loss:  2.138  - Validation loss:  2.280\n",
      "Epoch  20/100 Batch   22/70 - Loss:  1.552  - Validation loss:  2.280\n",
      "Epoch  20/100 Batch   23/70 - Loss:  1.385  - Validation loss:  2.281\n",
      "Epoch  20/100 Batch   24/70 - Loss:  1.595  - Validation loss:  2.279\n",
      "Epoch  20/100 Batch   25/70 - Loss:  2.251  - Validation loss:  2.283\n",
      "Epoch  20/100 Batch   26/70 - Loss:  1.850  - Validation loss:  2.290\n",
      "Epoch  20/100 Batch   27/70 - Loss:  1.760  - Validation loss:  2.291\n",
      "Epoch  20/100 Batch   28/70 - Loss:  1.971  - Validation loss:  2.283\n",
      "Epoch  20/100 Batch   29/70 - Loss:  1.829  - Validation loss:  2.276\n",
      "Epoch  20/100 Batch   30/70 - Loss:  1.637  - Validation loss:  2.279\n",
      "Epoch  20/100 Batch   31/70 - Loss:  1.672  - Validation loss:  2.279\n",
      "Epoch  20/100 Batch   32/70 - Loss:  1.690  - Validation loss:  2.276\n",
      "Epoch  20/100 Batch   33/70 - Loss:  1.794  - Validation loss:  2.282\n",
      "Epoch  20/100 Batch   34/70 - Loss:  1.925  - Validation loss:  2.291\n",
      "Epoch  20/100 Batch   35/70 - Loss:  2.094  - Validation loss:  2.289\n",
      "Epoch  20/100 Batch   36/70 - Loss:  2.059  - Validation loss:  2.278\n",
      "Epoch  20/100 Batch   37/70 - Loss:  1.863  - Validation loss:  2.275\n",
      "Epoch  20/100 Batch   38/70 - Loss:  1.721  - Validation loss:  2.282\n",
      "Epoch  20/100 Batch   39/70 - Loss:  1.565  - Validation loss:  2.279\n",
      "Epoch  20/100 Batch   40/70 - Loss:  2.285  - Validation loss:  2.274\n",
      "Epoch  20/100 Batch   41/70 - Loss:  2.116  - Validation loss:  2.288\n",
      "Epoch  20/100 Batch   42/70 - Loss:  2.212  - Validation loss:  2.297\n",
      "Epoch  20/100 Batch   43/70 - Loss:  2.352  - Validation loss:  2.289\n",
      "Epoch  20/100 Batch   44/70 - Loss:  2.116  - Validation loss:  2.276\n",
      "Epoch  20/100 Batch   45/70 - Loss:  1.917  - Validation loss:  2.279\n",
      "Epoch  20/100 Batch   46/70 - Loss:  1.839  - Validation loss:  2.289\n",
      "Epoch  20/100 Batch   47/70 - Loss:  1.690  - Validation loss:  2.277\n",
      "Epoch  20/100 Batch   48/70 - Loss:  1.923  - Validation loss:  2.274\n",
      "Epoch  20/100 Batch   49/70 - Loss:  1.861  - Validation loss:  2.288\n",
      "Epoch  20/100 Batch   50/70 - Loss:  1.785  - Validation loss:  2.299\n",
      "Epoch  20/100 Batch   51/70 - Loss:  2.100  - Validation loss:  2.290\n",
      "Epoch  20/100 Batch   52/70 - Loss:  2.312  - Validation loss:  2.277\n",
      "Epoch  20/100 Batch   53/70 - Loss:  1.919  - Validation loss:  2.277\n",
      "Epoch  20/100 Batch   54/70 - Loss:  1.135  - Validation loss:  2.287\n",
      "Epoch  20/100 Batch   55/70 - Loss:  1.483  - Validation loss:  2.285\n",
      "Epoch  20/100 Batch   56/70 - Loss:  1.896  - Validation loss:  2.274\n",
      "Epoch  20/100 Batch   57/70 - Loss:  1.314  - Validation loss:  2.278\n",
      "Epoch  20/100 Batch   58/70 - Loss:  1.465  - Validation loss:  2.291\n",
      "Epoch  20/100 Batch   59/70 - Loss:  1.988  - Validation loss:  2.296\n",
      "Epoch  20/100 Batch   60/70 - Loss:  1.454  - Validation loss:  2.288\n",
      "Epoch  20/100 Batch   61/70 - Loss:  1.465  - Validation loss:  2.279\n",
      "Epoch  20/100 Batch   62/70 - Loss:  2.156  - Validation loss:  2.278\n",
      "Epoch  20/100 Batch   63/70 - Loss:  2.027  - Validation loss:  2.277\n",
      "Epoch  20/100 Batch   64/70 - Loss:  1.964  - Validation loss:  2.274\n",
      "Epoch  20/100 Batch   65/70 - Loss:  1.951  - Validation loss:  2.278\n",
      "Epoch  20/100 Batch   66/70 - Loss:  2.408  - Validation loss:  2.286\n",
      "Epoch  20/100 Batch   67/70 - Loss:  1.996  - Validation loss:  2.287\n",
      "Epoch  20/100 Batch   68/70 - Loss:  2.179  - Validation loss:  2.280\n",
      "Epoch  20/100 Batch   69/70 - Loss:  1.686  - Validation loss:  2.277\n",
      "Epoch  21/100 Batch    1/70 - Loss:  2.188  - Validation loss:  2.283\n",
      "Epoch  21/100 Batch    2/70 - Loss:  2.014  - Validation loss:  2.276\n",
      "Epoch  21/100 Batch    3/70 - Loss:  1.907  - Validation loss:  2.273\n",
      "Epoch  21/100 Batch    4/70 - Loss:  2.019  - Validation loss:  2.278\n",
      "Epoch  21/100 Batch    5/70 - Loss:  1.769  - Validation loss:  2.282\n",
      "Epoch  21/100 Batch    6/70 - Loss:  1.778  - Validation loss:  2.277\n",
      "Epoch  21/100 Batch    7/70 - Loss:  2.264  - Validation loss:  2.268\n",
      "Epoch  21/100 Batch    8/70 - Loss:  1.474  - Validation loss:  2.267\n",
      "Epoch  21/100 Batch    9/70 - Loss:  2.120  - Validation loss:  2.269\n",
      "Epoch  21/100 Batch   10/70 - Loss:  1.623  - Validation loss:  2.269\n",
      "Epoch  21/100 Batch   11/70 - Loss:  1.400  - Validation loss:  2.270\n",
      "Epoch  21/100 Batch   12/70 - Loss:  1.719  - Validation loss:  2.275\n",
      "Epoch  21/100 Batch   13/70 - Loss:  1.860  - Validation loss:  2.277\n",
      "Epoch  21/100 Batch   14/70 - Loss:  1.841  - Validation loss:  2.272\n",
      "Epoch  21/100 Batch   15/70 - Loss:  1.676  - Validation loss:  2.267\n",
      "Epoch  21/100 Batch   16/70 - Loss:  1.818  - Validation loss:  2.268\n",
      "Epoch  21/100 Batch   17/70 - Loss:  1.563  - Validation loss:  2.269\n",
      "Epoch  21/100 Batch   18/70 - Loss:  1.708  - Validation loss:  2.268\n",
      "Epoch  21/100 Batch   19/70 - Loss:  1.916  - Validation loss:  2.272\n",
      "Epoch  21/100 Batch   20/70 - Loss:  1.828  - Validation loss:  2.276\n",
      "Epoch  21/100 Batch   21/70 - Loss:  2.121  - Validation loss:  2.273\n",
      "Epoch  21/100 Batch   22/70 - Loss:  1.540  - Validation loss:  2.268\n",
      "Epoch  21/100 Batch   23/70 - Loss:  1.368  - Validation loss:  2.269\n",
      "Epoch  21/100 Batch   24/70 - Loss:  1.577  - Validation loss:  2.269\n",
      "Epoch  21/100 Batch   25/70 - Loss:  2.235  - Validation loss:  2.267\n",
      "Epoch  21/100 Batch   26/70 - Loss:  1.834  - Validation loss:  2.271\n",
      "Epoch  21/100 Batch   27/70 - Loss:  1.741  - Validation loss:  2.278\n",
      "Epoch  21/100 Batch   28/70 - Loss:  1.949  - Validation loss:  2.278\n",
      "Epoch  21/100 Batch   29/70 - Loss:  1.817  - Validation loss:  2.267\n",
      "Epoch  21/100 Batch   30/70 - Loss:  1.622  - Validation loss:  2.263\n",
      "Epoch  21/100 Batch   31/70 - Loss:  1.651  - Validation loss:  2.267\n",
      "Epoch  21/100 Batch   32/70 - Loss:  1.673  - Validation loss:  2.266\n",
      "Epoch  21/100 Batch   33/70 - Loss:  1.780  - Validation loss:  2.264\n",
      "Epoch  21/100 Batch   34/70 - Loss:  1.905  - Validation loss:  2.273\n",
      "Epoch  21/100 Batch   35/70 - Loss:  2.069  - Validation loss:  2.283\n",
      "Epoch  21/100 Batch   36/70 - Loss:  2.043  - Validation loss:  2.277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  21/100 Batch   37/70 - Loss:  1.853  - Validation loss:  2.265\n",
      "Epoch  21/100 Batch   38/70 - Loss:  1.705  - Validation loss:  2.265\n",
      "Epoch  21/100 Batch   39/70 - Loss:  1.544  - Validation loss:  2.272\n",
      "Epoch  21/100 Batch   40/70 - Loss:  2.271  - Validation loss:  2.264\n",
      "Epoch  21/100 Batch   41/70 - Loss:  2.106  - Validation loss:  2.265\n",
      "Epoch  21/100 Batch   42/70 - Loss:  2.186  - Validation loss:  2.280\n",
      "Epoch  21/100 Batch   43/70 - Loss:  2.327  - Validation loss:  2.288\n",
      "Epoch  21/100 Batch   44/70 - Loss:  2.106  - Validation loss:  2.277\n",
      "Epoch  21/100 Batch   45/70 - Loss:  1.905  - Validation loss:  2.264\n",
      "Epoch  21/100 Batch   46/70 - Loss:  1.817  - Validation loss:  2.268\n",
      "Epoch  21/100 Batch   47/70 - Loss:  1.663  - Validation loss:  2.274\n",
      "Epoch  21/100 Batch   48/70 - Loss:  1.915  - Validation loss:  2.263\n",
      "Epoch  21/100 Batch   49/70 - Loss:  1.852  - Validation loss:  2.262\n",
      "Epoch  21/100 Batch   50/70 - Loss:  1.763  - Validation loss:  2.277\n",
      "Epoch  21/100 Batch   51/70 - Loss:  2.071  - Validation loss:  2.285\n",
      "Epoch  21/100 Batch   52/70 - Loss:  2.293  - Validation loss:  2.278\n",
      "Epoch  21/100 Batch   53/70 - Loss:  1.909  - Validation loss:  2.266\n",
      "Epoch  21/100 Batch   54/70 - Loss:  1.124  - Validation loss:  2.266\n",
      "Epoch  21/100 Batch   55/70 - Loss:  1.458  - Validation loss:  2.275\n",
      "Epoch  21/100 Batch   56/70 - Loss:  1.878  - Validation loss:  2.274\n",
      "Epoch  21/100 Batch   57/70 - Loss:  1.315  - Validation loss:  2.263\n",
      "Epoch  21/100 Batch   58/70 - Loss:  1.457  - Validation loss:  2.268\n",
      "Epoch  21/100 Batch   59/70 - Loss:  1.964  - Validation loss:  2.286\n",
      "Epoch  21/100 Batch   60/70 - Loss:  1.442  - Validation loss:  2.293\n",
      "Epoch  21/100 Batch   61/70 - Loss:  1.464  - Validation loss:  2.282\n",
      "Epoch  21/100 Batch   62/70 - Loss:  2.148  - Validation loss:  2.267\n",
      "Epoch  21/100 Batch   63/70 - Loss:  2.007  - Validation loss:  2.270\n",
      "Epoch  21/100 Batch   64/70 - Loss:  1.951  - Validation loss:  2.272\n",
      "Epoch  21/100 Batch   65/70 - Loss:  1.948  - Validation loss:  2.266\n",
      "Epoch  21/100 Batch   66/70 - Loss:  2.393  - Validation loss:  2.267\n",
      "Epoch  21/100 Batch   67/70 - Loss:  1.973  - Validation loss:  2.278\n",
      "Epoch  21/100 Batch   68/70 - Loss:  2.162  - Validation loss:  2.285\n",
      "Epoch  21/100 Batch   69/70 - Loss:  1.683  - Validation loss:  2.277\n",
      "Epoch  22/100 Batch    1/70 - Loss:  2.163  - Validation loss:  2.270\n",
      "Epoch  22/100 Batch    2/70 - Loss:  1.991  - Validation loss:  2.277\n",
      "Epoch  22/100 Batch    3/70 - Loss:  1.902  - Validation loss:  2.270\n",
      "Epoch  22/100 Batch    4/70 - Loss:  2.013  - Validation loss:  2.260\n",
      "Epoch  22/100 Batch    5/70 - Loss:  1.752  - Validation loss:  2.266\n",
      "Epoch  22/100 Batch    6/70 - Loss:  1.757  - Validation loss:  2.276\n",
      "Epoch  22/100 Batch    7/70 - Loss:  2.251  - Validation loss:  2.274\n",
      "Epoch  22/100 Batch    8/70 - Loss:  1.471  - Validation loss:  2.264\n",
      "Epoch  22/100 Batch    9/70 - Loss:  2.106  - Validation loss:  2.256\n",
      "Epoch  22/100 Batch   10/70 - Loss:  1.605  - Validation loss:  2.259\n",
      "Epoch  22/100 Batch   11/70 - Loss:  1.388  - Validation loss:  2.263\n",
      "Epoch  22/100 Batch   12/70 - Loss:  1.710  - Validation loss:  2.260\n",
      "Epoch  22/100 Batch   13/70 - Loss:  1.843  - Validation loss:  2.261\n",
      "Epoch  22/100 Batch   14/70 - Loss:  1.820  - Validation loss:  2.266\n",
      "Epoch  22/100 Batch   15/70 - Loss:  1.660  - Validation loss:  2.267\n",
      "Epoch  22/100 Batch   16/70 - Loss:  1.807  - Validation loss:  2.263\n",
      "Epoch  22/100 Batch   17/70 - Loss:  1.550  - Validation loss:  2.258\n",
      "Epoch  22/100 Batch   18/70 - Loss:  1.688  - Validation loss:  2.259\n",
      "Epoch  22/100 Batch   19/70 - Loss:  1.902  - Validation loss:  2.260\n",
      "Epoch  22/100 Batch   20/70 - Loss:  1.814  - Validation loss:  2.257\n",
      "Epoch  22/100 Batch   21/70 - Loss:  2.099  - Validation loss:  2.258\n",
      "Epoch  22/100 Batch   22/70 - Loss:  1.520  - Validation loss:  2.263\n",
      "Epoch  22/100 Batch   23/70 - Loss:  1.357  - Validation loss:  2.264\n",
      "Epoch  22/100 Batch   24/70 - Loss:  1.562  - Validation loss:  2.261\n",
      "Epoch  22/100 Batch   25/70 - Loss:  2.210  - Validation loss:  2.258\n",
      "Epoch  22/100 Batch   26/70 - Loss:  1.818  - Validation loss:  2.256\n",
      "Epoch  22/100 Batch   27/70 - Loss:  1.728  - Validation loss:  2.255\n",
      "Epoch  22/100 Batch   28/70 - Loss:  1.926  - Validation loss:  2.254\n",
      "Epoch  22/100 Batch   29/70 - Loss:  1.793  - Validation loss:  2.253\n",
      "Epoch  22/100 Batch   30/70 - Loss:  1.605  - Validation loss:  2.253\n",
      "Epoch  22/100 Batch   31/70 - Loss:  1.636  - Validation loss:  2.251\n",
      "Epoch  22/100 Batch   32/70 - Loss:  1.649  - Validation loss:  2.251\n",
      "Epoch  22/100 Batch   33/70 - Loss:  1.751  - Validation loss:  2.251\n",
      "Epoch  22/100 Batch   34/70 - Loss:  1.888  - Validation loss:  2.251\n",
      "Epoch  22/100 Batch   35/70 - Loss:  2.047  - Validation loss:  2.254\n",
      "Epoch  22/100 Batch   36/70 - Loss:  2.014  - Validation loss:  2.257\n",
      "Epoch  22/100 Batch   37/70 - Loss:  1.829  - Validation loss:  2.256\n",
      "Epoch  22/100 Batch   38/70 - Loss:  1.689  - Validation loss:  2.252\n",
      "Epoch  22/100 Batch   39/70 - Loss:  1.526  - Validation loss:  2.248\n",
      "Epoch  22/100 Batch   40/70 - Loss:  2.234  - Validation loss:  2.248\n",
      "Epoch  22/100 Batch   41/70 - Loss:  2.081  - Validation loss:  2.250\n",
      "Epoch  22/100 Batch   42/70 - Loss:  2.170  - Validation loss:  2.253\n",
      "Epoch  22/100 Batch   43/70 - Loss:  2.302  - Validation loss:  2.260\n",
      "Epoch  22/100 Batch   44/70 - Loss:  2.075  - Validation loss:  2.263\n",
      "Epoch  22/100 Batch   45/70 - Loss:  1.882  - Validation loss:  2.257\n",
      "Epoch  22/100 Batch   46/70 - Loss:  1.801  - Validation loss:  2.251\n",
      "Epoch  22/100 Batch   47/70 - Loss:  1.640  - Validation loss:  2.252\n",
      "Epoch  22/100 Batch   48/70 - Loss:  1.882  - Validation loss:  2.250\n",
      "Epoch  22/100 Batch   49/70 - Loss:  1.837  - Validation loss:  2.245\n",
      "Epoch  22/100 Batch   50/70 - Loss:  1.750  - Validation loss:  2.250\n",
      "Epoch  22/100 Batch   51/70 - Loss:  2.044  - Validation loss:  2.260\n",
      "Epoch  22/100 Batch   52/70 - Loss:  2.259  - Validation loss:  2.263\n",
      "Epoch  22/100 Batch   53/70 - Loss:  1.886  - Validation loss:  2.258\n",
      "Epoch  22/100 Batch   54/70 - Loss:  1.112  - Validation loss:  2.256\n",
      "Epoch  22/100 Batch   55/70 - Loss:  1.442  - Validation loss:  2.261\n",
      "Epoch  22/100 Batch   56/70 - Loss:  1.855  - Validation loss:  2.259\n",
      "Epoch  22/100 Batch   57/70 - Loss:  1.296  - Validation loss:  2.253\n",
      "Epoch  22/100 Batch   58/70 - Loss:  1.445  - Validation loss:  2.253\n",
      "Epoch  22/100 Batch   59/70 - Loss:  1.951  - Validation loss:  2.265\n",
      "Epoch  22/100 Batch   60/70 - Loss:  1.424  - Validation loss:  2.274\n",
      "Epoch  22/100 Batch   61/70 - Loss:  1.444  - Validation loss:  2.271\n",
      "Epoch  22/100 Batch   62/70 - Loss:  2.131  - Validation loss:  2.260\n",
      "Epoch  22/100 Batch   63/70 - Loss:  1.993  - Validation loss:  2.257\n",
      "Epoch  22/100 Batch   64/70 - Loss:  1.930  - Validation loss:  2.259\n",
      "Epoch  22/100 Batch   65/70 - Loss:  1.927  - Validation loss:  2.257\n",
      "Epoch  22/100 Batch   66/70 - Loss:  2.375  - Validation loss:  2.255\n",
      "Epoch  22/100 Batch   67/70 - Loss:  1.958  - Validation loss:  2.259\n",
      "Epoch  22/100 Batch   68/70 - Loss:  2.141  - Validation loss:  2.268\n",
      "Epoch  22/100 Batch   69/70 - Loss:  1.662  - Validation loss:  2.272\n",
      "Epoch  23/100 Batch    1/70 - Loss:  2.147  - Validation loss:  2.256\n",
      "Epoch  23/100 Batch    2/70 - Loss:  1.967  - Validation loss:  2.260\n",
      "Epoch  23/100 Batch    3/70 - Loss:  1.874  - Validation loss:  2.263\n",
      "Epoch  23/100 Batch    4/70 - Loss:  1.997  - Validation loss:  2.255\n",
      "Epoch  23/100 Batch    5/70 - Loss:  1.745  - Validation loss:  2.251\n",
      "Epoch  23/100 Batch    6/70 - Loss:  1.741  - Validation loss:  2.255\n",
      "Epoch  23/100 Batch    7/70 - Loss:  2.224  - Validation loss:  2.264\n",
      "Epoch  23/100 Batch    8/70 - Loss:  1.456  - Validation loss:  2.264\n",
      "Epoch  23/100 Batch    9/70 - Loss:  2.094  - Validation loss:  2.253\n",
      "Epoch  23/100 Batch   10/70 - Loss:  1.595  - Validation loss:  2.245\n",
      "Epoch  23/100 Batch   11/70 - Loss:  1.369  - Validation loss:  2.249\n",
      "Epoch  23/100 Batch   12/70 - Loss:  1.690  - Validation loss:  2.252\n",
      "Epoch  23/100 Batch   13/70 - Loss:  1.834  - Validation loss:  2.248\n",
      "Epoch  23/100 Batch   14/70 - Loss:  1.805  - Validation loss:  2.248\n",
      "Epoch  23/100 Batch   15/70 - Loss:  1.639  - Validation loss:  2.255\n",
      "Epoch  23/100 Batch   16/70 - Loss:  1.787  - Validation loss:  2.260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  23/100 Batch   17/70 - Loss:  1.542  - Validation loss:  2.254\n",
      "Epoch  23/100 Batch   18/70 - Loss:  1.675  - Validation loss:  2.248\n",
      "Epoch  23/100 Batch   19/70 - Loss:  1.880  - Validation loss:  2.248\n",
      "Epoch  23/100 Batch   20/70 - Loss:  1.791  - Validation loss:  2.248\n",
      "Epoch  23/100 Batch   21/70 - Loss:  2.085  - Validation loss:  2.246\n",
      "Epoch  23/100 Batch   22/70 - Loss:  1.506  - Validation loss:  2.246\n",
      "Epoch  23/100 Batch   23/70 - Loss:  1.341  - Validation loss:  2.252\n",
      "Epoch  23/100 Batch   24/70 - Loss:  1.546  - Validation loss:  2.258\n",
      "Epoch  23/100 Batch   25/70 - Loss:  2.193  - Validation loss:  2.256\n",
      "Epoch  23/100 Batch   26/70 - Loss:  1.806  - Validation loss:  2.250\n",
      "Epoch  23/100 Batch   27/70 - Loss:  1.713  - Validation loss:  2.245\n",
      "Epoch  23/100 Batch   28/70 - Loss:  1.907  - Validation loss:  2.243\n",
      "Epoch  23/100 Batch   29/70 - Loss:  1.780  - Validation loss:  2.241\n",
      "Epoch  23/100 Batch   30/70 - Loss:  1.590  - Validation loss:  2.239\n",
      "Epoch  23/100 Batch   31/70 - Loss:  1.620  - Validation loss:  2.241\n",
      "Epoch  23/100 Batch   32/70 - Loss:  1.633  - Validation loss:  2.243\n",
      "Epoch  23/100 Batch   33/70 - Loss:  1.732  - Validation loss:  2.244\n",
      "Epoch  23/100 Batch   34/70 - Loss:  1.870  - Validation loss:  2.243\n",
      "Epoch  23/100 Batch   35/70 - Loss:  2.028  - Validation loss:  2.242\n",
      "Epoch  23/100 Batch   36/70 - Loss:  1.996  - Validation loss:  2.239\n",
      "Epoch  23/100 Batch   37/70 - Loss:  1.812  - Validation loss:  2.238\n",
      "Epoch  23/100 Batch   38/70 - Loss:  1.672  - Validation loss:  2.238\n",
      "Epoch  23/100 Batch   39/70 - Loss:  1.509  - Validation loss:  2.238\n",
      "Epoch  23/100 Batch   40/70 - Loss:  2.214  - Validation loss:  2.236\n",
      "Epoch  23/100 Batch   41/70 - Loss:  2.061  - Validation loss:  2.238\n",
      "Epoch  23/100 Batch   42/70 - Loss:  2.144  - Validation loss:  2.241\n",
      "Epoch  23/100 Batch   43/70 - Loss:  2.284  - Validation loss:  2.243\n",
      "Epoch  23/100 Batch   44/70 - Loss:  2.054  - Validation loss:  2.242\n",
      "Epoch  23/100 Batch   45/70 - Loss:  1.858  - Validation loss:  2.240\n",
      "Epoch  23/100 Batch   46/70 - Loss:  1.779  - Validation loss:  2.238\n",
      "Epoch  23/100 Batch   47/70 - Loss:  1.626  - Validation loss:  2.239\n",
      "Epoch  23/100 Batch   48/70 - Loss:  1.859  - Validation loss:  2.239\n",
      "Epoch  23/100 Batch   49/70 - Loss:  1.816  - Validation loss:  2.236\n",
      "Epoch  23/100 Batch   50/70 - Loss:  1.734  - Validation loss:  2.236\n",
      "Epoch  23/100 Batch   51/70 - Loss:  2.025  - Validation loss:  2.241\n",
      "Epoch  23/100 Batch   52/70 - Loss:  2.234  - Validation loss:  2.243\n",
      "Epoch  23/100 Batch   53/70 - Loss:  1.863  - Validation loss:  2.240\n",
      "Epoch  23/100 Batch   54/70 - Loss:  1.097  - Validation loss:  2.240\n",
      "Epoch  23/100 Batch   55/70 - Loss:  1.427  - Validation loss:  2.248\n",
      "Epoch  23/100 Batch   56/70 - Loss:  1.836  - Validation loss:  2.250\n",
      "Epoch  23/100 Batch   57/70 - Loss:  1.281  - Validation loss:  2.243\n",
      "Epoch  23/100 Batch   58/70 - Loss:  1.429  - Validation loss:  2.240\n",
      "Epoch  23/100 Batch   59/70 - Loss:  1.929  - Validation loss:  2.248\n",
      "Epoch  23/100 Batch   60/70 - Loss:  1.408  - Validation loss:  2.257\n",
      "Epoch  23/100 Batch   61/70 - Loss:  1.429  - Validation loss:  2.255\n",
      "Epoch  23/100 Batch   62/70 - Loss:  2.114  - Validation loss:  2.247\n",
      "Epoch  23/100 Batch   63/70 - Loss:  1.976  - Validation loss:  2.243\n",
      "Epoch  23/100 Batch   64/70 - Loss:  1.910  - Validation loss:  2.246\n",
      "Epoch  23/100 Batch   65/70 - Loss:  1.911  - Validation loss:  2.247\n",
      "Epoch  23/100 Batch   66/70 - Loss:  2.356  - Validation loss:  2.242\n",
      "Epoch  23/100 Batch   67/70 - Loss:  1.938  - Validation loss:  2.245\n",
      "Epoch  23/100 Batch   68/70 - Loss:  2.122  - Validation loss:  2.255\n",
      "Epoch  23/100 Batch   69/70 - Loss:  1.649  - Validation loss:  2.259\n",
      "Epoch  24/100 Batch    1/70 - Loss:  2.125  - Validation loss:  2.246\n",
      "Epoch  24/100 Batch    2/70 - Loss:  1.948  - Validation loss:  2.249\n",
      "Epoch  24/100 Batch    3/70 - Loss:  1.856  - Validation loss:  2.254\n",
      "Epoch  24/100 Batch    4/70 - Loss:  1.980  - Validation loss:  2.245\n",
      "Epoch  24/100 Batch    5/70 - Loss:  1.727  - Validation loss:  2.238\n",
      "Epoch  24/100 Batch    6/70 - Loss:  1.725  - Validation loss:  2.243\n",
      "Epoch  24/100 Batch    7/70 - Loss:  2.209  - Validation loss:  2.253\n",
      "Epoch  24/100 Batch    8/70 - Loss:  1.444  - Validation loss:  2.255\n",
      "Epoch  24/100 Batch    9/70 - Loss:  2.075  - Validation loss:  2.248\n",
      "Epoch  24/100 Batch   10/70 - Loss:  1.582  - Validation loss:  2.239\n",
      "Epoch  24/100 Batch   11/70 - Loss:  1.358  - Validation loss:  2.239\n",
      "Epoch  24/100 Batch   12/70 - Loss:  1.673  - Validation loss:  2.242\n",
      "Epoch  24/100 Batch   13/70 - Loss:  1.816  - Validation loss:  2.239\n",
      "Epoch  24/100 Batch   14/70 - Loss:  1.791  - Validation loss:  2.237\n",
      "Epoch  24/100 Batch   15/70 - Loss:  1.625  - Validation loss:  2.242\n",
      "Epoch  24/100 Batch   16/70 - Loss:  1.770  - Validation loss:  2.247\n",
      "Epoch  24/100 Batch   17/70 - Loss:  1.526  - Validation loss:  2.246\n",
      "Epoch  24/100 Batch   18/70 - Loss:  1.662  - Validation loss:  2.242\n",
      "Epoch  24/100 Batch   19/70 - Loss:  1.865  - Validation loss:  2.241\n",
      "Epoch  24/100 Batch   20/70 - Loss:  1.773  - Validation loss:  2.241\n",
      "Epoch  24/100 Batch   21/70 - Loss:  2.067  - Validation loss:  2.239\n",
      "Epoch  24/100 Batch   22/70 - Loss:  1.495  - Validation loss:  2.235\n",
      "Epoch  24/100 Batch   23/70 - Loss:  1.330  - Validation loss:  2.239\n",
      "Epoch  24/100 Batch   24/70 - Loss:  1.534  - Validation loss:  2.247\n",
      "Epoch  24/100 Batch   25/70 - Loss:  2.173  - Validation loss:  2.250\n",
      "Epoch  24/100 Batch   26/70 - Loss:  1.793  - Validation loss:  2.246\n",
      "Epoch  24/100 Batch   27/70 - Loss:  1.702  - Validation loss:  2.240\n",
      "Epoch  24/100 Batch   28/70 - Loss:  1.890  - Validation loss:  2.236\n",
      "Epoch  24/100 Batch   29/70 - Loss:  1.768  - Validation loss:  2.233\n",
      "Epoch  24/100 Batch   30/70 - Loss:  1.578  - Validation loss:  2.231\n",
      "Epoch  24/100 Batch   31/70 - Loss:  1.607  - Validation loss:  2.232\n",
      "Epoch  24/100 Batch   32/70 - Loss:  1.621  - Validation loss:  2.235\n",
      "Epoch  24/100 Batch   33/70 - Loss:  1.715  - Validation loss:  2.237\n",
      "Epoch  24/100 Batch   34/70 - Loss:  1.855  - Validation loss:  2.238\n",
      "Epoch  24/100 Batch   35/70 - Loss:  2.010  - Validation loss:  2.237\n",
      "Epoch  24/100 Batch   36/70 - Loss:  1.980  - Validation loss:  2.232\n",
      "Epoch  24/100 Batch   37/70 - Loss:  1.796  - Validation loss:  2.229\n",
      "Epoch  24/100 Batch   38/70 - Loss:  1.659  - Validation loss:  2.227\n",
      "Epoch  24/100 Batch   39/70 - Loss:  1.496  - Validation loss:  2.226\n",
      "Epoch  24/100 Batch   40/70 - Loss:  2.195  - Validation loss:  2.227\n",
      "Epoch  24/100 Batch   41/70 - Loss:  2.043  - Validation loss:  2.230\n",
      "Epoch  24/100 Batch   42/70 - Loss:  2.126  - Validation loss:  2.232\n",
      "Epoch  24/100 Batch   43/70 - Loss:  2.265  - Validation loss:  2.232\n",
      "Epoch  24/100 Batch   44/70 - Loss:  2.036  - Validation loss:  2.230\n",
      "Epoch  24/100 Batch   45/70 - Loss:  1.839  - Validation loss:  2.228\n",
      "Epoch  24/100 Batch   46/70 - Loss:  1.764  - Validation loss:  2.227\n",
      "Epoch  24/100 Batch   47/70 - Loss:  1.612  - Validation loss:  2.226\n",
      "Epoch  24/100 Batch   48/70 - Loss:  1.840  - Validation loss:  2.227\n",
      "Epoch  24/100 Batch   49/70 - Loss:  1.798  - Validation loss:  2.226\n",
      "Epoch  24/100 Batch   50/70 - Loss:  1.720  - Validation loss:  2.227\n",
      "Epoch  24/100 Batch   51/70 - Loss:  2.011  - Validation loss:  2.230\n",
      "Epoch  24/100 Batch   52/70 - Loss:  2.211  - Validation loss:  2.231\n",
      "Epoch  24/100 Batch   53/70 - Loss:  1.842  - Validation loss:  2.230\n",
      "Epoch  24/100 Batch   54/70 - Loss:  1.086  - Validation loss:  2.228\n",
      "Epoch  24/100 Batch   55/70 - Loss:  1.415  - Validation loss:  2.231\n",
      "Epoch  24/100 Batch   56/70 - Loss:  1.816  - Validation loss:  2.236\n",
      "Epoch  24/100 Batch   57/70 - Loss:  1.268  - Validation loss:  2.237\n",
      "Epoch  24/100 Batch   58/70 - Loss:  1.417  - Validation loss:  2.232\n",
      "Epoch  24/100 Batch   59/70 - Loss:  1.917  - Validation loss:  2.236\n",
      "Epoch  24/100 Batch   60/70 - Loss:  1.394  - Validation loss:  2.245\n",
      "Epoch  24/100 Batch   61/70 - Loss:  1.413  - Validation loss:  2.246\n",
      "Epoch  24/100 Batch   62/70 - Loss:  2.098  - Validation loss:  2.240\n",
      "Epoch  24/100 Batch   63/70 - Loss:  1.962  - Validation loss:  2.232\n",
      "Epoch  24/100 Batch   64/70 - Loss:  1.894  - Validation loss:  2.234\n",
      "Epoch  24/100 Batch   65/70 - Loss:  1.893  - Validation loss:  2.238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  24/100 Batch   66/70 - Loss:  2.337  - Validation loss:  2.234\n",
      "Epoch  24/100 Batch   67/70 - Loss:  1.924  - Validation loss:  2.234\n",
      "Epoch  24/100 Batch   68/70 - Loss:  2.106  - Validation loss:  2.245\n",
      "Epoch  24/100 Batch   69/70 - Loss:  1.634  - Validation loss:  2.254\n",
      "Epoch  25/100 Batch    1/70 - Loss:  2.111  - Validation loss:  2.239\n",
      "Epoch  25/100 Batch    2/70 - Loss:  1.932  - Validation loss:  2.236\n",
      "Epoch  25/100 Batch    3/70 - Loss:  1.835  - Validation loss:  2.246\n",
      "Epoch  25/100 Batch    4/70 - Loss:  1.963  - Validation loss:  2.243\n",
      "Epoch  25/100 Batch    5/70 - Loss:  1.716  - Validation loss:  2.232\n",
      "Epoch  25/100 Batch    6/70 - Loss:  1.713  - Validation loss:  2.231\n",
      "Epoch  25/100 Batch    7/70 - Loss:  2.191  - Validation loss:  2.245\n",
      "Epoch  25/100 Batch    8/70 - Loss:  1.432  - Validation loss:  2.253\n",
      "Epoch  25/100 Batch    9/70 - Loss:  2.064  - Validation loss:  2.247\n",
      "Epoch  25/100 Batch   10/70 - Loss:  1.573  - Validation loss:  2.234\n",
      "Epoch  25/100 Batch   11/70 - Loss:  1.346  - Validation loss:  2.232\n",
      "Epoch  25/100 Batch   12/70 - Loss:  1.658  - Validation loss:  2.237\n",
      "Epoch  25/100 Batch   13/70 - Loss:  1.803  - Validation loss:  2.236\n",
      "Epoch  25/100 Batch   14/70 - Loss:  1.783  - Validation loss:  2.230\n",
      "Epoch  25/100 Batch   15/70 - Loss:  1.613  - Validation loss:  2.233\n",
      "Epoch  25/100 Batch   16/70 - Loss:  1.755  - Validation loss:  2.243\n",
      "Epoch  25/100 Batch   17/70 - Loss:  1.516  - Validation loss:  2.245\n",
      "Epoch  25/100 Batch   18/70 - Loss:  1.655  - Validation loss:  2.237\n",
      "Epoch  25/100 Batch   19/70 - Loss:  1.851  - Validation loss:  2.232\n",
      "Epoch  25/100 Batch   20/70 - Loss:  1.754  - Validation loss:  2.237\n",
      "Epoch  25/100 Batch   21/70 - Loss:  2.052  - Validation loss:  2.241\n",
      "Epoch  25/100 Batch   22/70 - Loss:  1.489  - Validation loss:  2.232\n",
      "Epoch  25/100 Batch   23/70 - Loss:  1.322  - Validation loss:  2.229\n",
      "Epoch  25/100 Batch   24/70 - Loss:  1.520  - Validation loss:  2.239\n",
      "Epoch  25/100 Batch   25/70 - Loss:  2.154  - Validation loss:  2.248\n",
      "Epoch  25/100 Batch   26/70 - Loss:  1.783  - Validation loss:  2.247\n",
      "Epoch  25/100 Batch   27/70 - Loss:  1.696  - Validation loss:  2.235\n",
      "Epoch  25/100 Batch   28/70 - Loss:  1.876  - Validation loss:  2.226\n",
      "Epoch  25/100 Batch   29/70 - Loss:  1.751  - Validation loss:  2.228\n",
      "Epoch  25/100 Batch   30/70 - Loss:  1.566  - Validation loss:  2.229\n",
      "Epoch  25/100 Batch   31/70 - Loss:  1.602  - Validation loss:  2.222\n",
      "Epoch  25/100 Batch   32/70 - Loss:  1.608  - Validation loss:  2.224\n",
      "Epoch  25/100 Batch   33/70 - Loss:  1.695  - Validation loss:  2.234\n",
      "Epoch  25/100 Batch   34/70 - Loss:  1.844  - Validation loss:  2.240\n",
      "Epoch  25/100 Batch   35/70 - Loss:  1.998  - Validation loss:  2.235\n",
      "Epoch  25/100 Batch   36/70 - Loss:  1.969  - Validation loss:  2.227\n",
      "Epoch  25/100 Batch   37/70 - Loss:  1.783  - Validation loss:  2.229\n",
      "Epoch  25/100 Batch   38/70 - Loss:  1.649  - Validation loss:  2.230\n",
      "Epoch  25/100 Batch   39/70 - Loss:  1.491  - Validation loss:  2.223\n",
      "Epoch  25/100 Batch   40/70 - Loss:  2.184  - Validation loss:  2.220\n",
      "Epoch  25/100 Batch   41/70 - Loss:  2.028  - Validation loss:  2.227\n",
      "Epoch  25/100 Batch   42/70 - Loss:  2.112  - Validation loss:  2.233\n",
      "Epoch  25/100 Batch   43/70 - Loss:  2.258  - Validation loss:  2.232\n",
      "Epoch  25/100 Batch   44/70 - Loss:  2.026  - Validation loss:  2.226\n",
      "Epoch  25/100 Batch   45/70 - Loss:  1.825  - Validation loss:  2.223\n",
      "Epoch  25/100 Batch   46/70 - Loss:  1.751  - Validation loss:  2.224\n",
      "Epoch  25/100 Batch   47/70 - Loss:  1.602  - Validation loss:  2.225\n",
      "Epoch  25/100 Batch   48/70 - Loss:  1.828  - Validation loss:  2.223\n",
      "Epoch  25/100 Batch   49/70 - Loss:  1.785  - Validation loss:  2.221\n",
      "Epoch  25/100 Batch   50/70 - Loss:  1.709  - Validation loss:  2.222\n",
      "Epoch  25/100 Batch   51/70 - Loss:  1.996  - Validation loss:  2.223\n",
      "Epoch  25/100 Batch   52/70 - Loss:  2.194  - Validation loss:  2.223\n",
      "Epoch  25/100 Batch   53/70 - Loss:  1.827  - Validation loss:  2.222\n",
      "Epoch  25/100 Batch   54/70 - Loss:  1.075  - Validation loss:  2.223\n",
      "Epoch  25/100 Batch   55/70 - Loss:  1.404  - Validation loss:  2.226\n",
      "Epoch  25/100 Batch   56/70 - Loss:  1.802  - Validation loss:  2.230\n",
      "Epoch  25/100 Batch   57/70 - Loss:  1.257  - Validation loss:  2.231\n",
      "Epoch  25/100 Batch   58/70 - Loss:  1.404  - Validation loss:  2.228\n",
      "Epoch  25/100 Batch   59/70 - Loss:  1.904  - Validation loss:  2.226\n",
      "Epoch  25/100 Batch   60/70 - Loss:  1.384  - Validation loss:  2.231\n",
      "Epoch  25/100 Batch   61/70 - Loss:  1.398  - Validation loss:  2.235\n",
      "Epoch  25/100 Batch   62/70 - Loss:  2.082  - Validation loss:  2.234\n",
      "Epoch  25/100 Batch   63/70 - Loss:  1.950  - Validation loss:  2.228\n",
      "Epoch  25/100 Batch   64/70 - Loss:  1.884  - Validation loss:  2.225\n",
      "Epoch  25/100 Batch   65/70 - Loss:  1.879  - Validation loss:  2.230\n",
      "Epoch  25/100 Batch   66/70 - Loss:  2.318  - Validation loss:  2.230\n",
      "Epoch  25/100 Batch   67/70 - Loss:  1.911  - Validation loss:  2.225\n",
      "Epoch  25/100 Batch   68/70 - Loss:  2.096  - Validation loss:  2.234\n",
      "Epoch  25/100 Batch   69/70 - Loss:  1.621  - Validation loss:  2.249\n",
      "Epoch  26/100 Batch    1/70 - Loss:  2.098  - Validation loss:  2.240\n",
      "Epoch  26/100 Batch    2/70 - Loss:  1.923  - Validation loss:  2.228\n",
      "Epoch  26/100 Batch    3/70 - Loss:  1.821  - Validation loss:  2.235\n",
      "Epoch  26/100 Batch    4/70 - Loss:  1.943  - Validation loss:  2.247\n",
      "Epoch  26/100 Batch    5/70 - Loss:  1.708  - Validation loss:  2.238\n",
      "Epoch  26/100 Batch    6/70 - Loss:  1.713  - Validation loss:  2.223\n",
      "Epoch  26/100 Batch    7/70 - Loss:  2.179  - Validation loss:  2.235\n",
      "Epoch  26/100 Batch    8/70 - Loss:  1.419  - Validation loss:  2.254\n",
      "Epoch  26/100 Batch    9/70 - Loss:  2.055  - Validation loss:  2.257\n",
      "Epoch  26/100 Batch   10/70 - Loss:  1.574  - Validation loss:  2.240\n",
      "Epoch  26/100 Batch   11/70 - Loss:  1.344  - Validation loss:  2.226\n",
      "Epoch  26/100 Batch   12/70 - Loss:  1.642  - Validation loss:  2.231\n",
      "Epoch  26/100 Batch   13/70 - Loss:  1.785  - Validation loss:  2.244\n",
      "Epoch  26/100 Batch   14/70 - Loss:  1.781  - Validation loss:  2.237\n",
      "Epoch  26/100 Batch   15/70 - Loss:  1.620  - Validation loss:  2.226\n",
      "Epoch  26/100 Batch   16/70 - Loss:  1.744  - Validation loss:  2.232\n",
      "Epoch  26/100 Batch   17/70 - Loss:  1.501  - Validation loss:  2.244\n",
      "Epoch  26/100 Batch   18/70 - Loss:  1.645  - Validation loss:  2.248\n",
      "Epoch  26/100 Batch   19/70 - Loss:  1.851  - Validation loss:  2.240\n",
      "Epoch  26/100 Batch   20/70 - Loss:  1.755  - Validation loss:  2.230\n",
      "Epoch  26/100 Batch   21/70 - Loss:  2.037  - Validation loss:  2.235\n",
      "Epoch  26/100 Batch   22/70 - Loss:  1.474  - Validation loss:  2.249\n",
      "Epoch  26/100 Batch   23/70 - Loss:  1.325  - Validation loss:  2.248\n",
      "Epoch  26/100 Batch   24/70 - Loss:  1.537  - Validation loss:  2.231\n",
      "Epoch  26/100 Batch   25/70 - Loss:  2.146  - Validation loss:  2.234\n",
      "Epoch  26/100 Batch   26/70 - Loss:  1.767  - Validation loss:  2.255\n",
      "Epoch  26/100 Batch   27/70 - Loss:  1.696  - Validation loss:  2.263\n",
      "Epoch  26/100 Batch   28/70 - Loss:  1.889  - Validation loss:  2.251\n",
      "Epoch  26/100 Batch   29/70 - Loss:  1.769  - Validation loss:  2.229\n",
      "Epoch  26/100 Batch   30/70 - Loss:  1.563  - Validation loss:  2.223\n",
      "Epoch  26/100 Batch   31/70 - Loss:  1.589  - Validation loss:  2.239\n",
      "Epoch  26/100 Batch   32/70 - Loss:  1.620  - Validation loss:  2.239\n",
      "Epoch  26/100 Batch   33/70 - Loss:  1.713  - Validation loss:  2.224\n",
      "Epoch  26/100 Batch   34/70 - Loss:  1.831  - Validation loss:  2.230\n",
      "Epoch  26/100 Batch   35/70 - Loss:  1.980  - Validation loss:  2.249\n",
      "Epoch  26/100 Batch   36/70 - Loss:  1.974  - Validation loss:  2.253\n",
      "Epoch  26/100 Batch   37/70 - Loss:  1.807  - Validation loss:  2.239\n",
      "Epoch  26/100 Batch   38/70 - Loss:  1.663  - Validation loss:  2.223\n",
      "Epoch  26/100 Batch   39/70 - Loss:  1.477  - Validation loss:  2.227\n",
      "Epoch  26/100 Batch   40/70 - Loss:  2.176  - Validation loss:  2.237\n",
      "Epoch  26/100 Batch   41/70 - Loss:  2.041  - Validation loss:  2.229\n",
      "Epoch  26/100 Batch   42/70 - Loss:  2.116  - Validation loss:  2.220\n",
      "Epoch  26/100 Batch   43/70 - Loss:  2.243  - Validation loss:  2.229\n",
      "Epoch  26/100 Batch   44/70 - Loss:  2.013  - Validation loss:  2.242\n",
      "Epoch  26/100 Batch   45/70 - Loss:  1.828  - Validation loss:  2.245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  26/100 Batch   46/70 - Loss:  1.759  - Validation loss:  2.236\n",
      "Epoch  26/100 Batch   47/70 - Loss:  1.611  - Validation loss:  2.222\n",
      "Epoch  26/100 Batch   48/70 - Loss:  1.820  - Validation loss:  2.220\n",
      "Epoch  26/100 Batch   49/70 - Loss:  1.778  - Validation loss:  2.230\n",
      "Epoch  26/100 Batch   50/70 - Loss:  1.714  - Validation loss:  2.234\n",
      "Epoch  26/100 Batch   51/70 - Loss:  2.005  - Validation loss:  2.223\n",
      "Epoch  26/100 Batch   52/70 - Loss:  2.189  - Validation loss:  2.218\n",
      "Epoch  26/100 Batch   53/70 - Loss:  1.817  - Validation loss:  2.226\n",
      "Epoch  26/100 Batch   54/70 - Loss:  1.079  - Validation loss:  2.233\n",
      "Epoch  26/100 Batch   55/70 - Loss:  1.417  - Validation loss:  2.229\n",
      "Epoch  26/100 Batch   56/70 - Loss:  1.804  - Validation loss:  2.223\n",
      "Epoch  26/100 Batch   57/70 - Loss:  1.255  - Validation loss:  2.224\n",
      "Epoch  26/100 Batch   58/70 - Loss:  1.394  - Validation loss:  2.235\n",
      "Epoch  26/100 Batch   59/70 - Loss:  1.901  - Validation loss:  2.238\n",
      "Epoch  26/100 Batch   60/70 - Loss:  1.393  - Validation loss:  2.231\n",
      "Epoch  26/100 Batch   61/70 - Loss:  1.396  - Validation loss:  2.231\n",
      "Epoch  26/100 Batch   62/70 - Loss:  2.074  - Validation loss:  2.236\n",
      "Epoch  26/100 Batch   63/70 - Loss:  1.943  - Validation loss:  2.238\n",
      "Epoch  26/100 Batch   64/70 - Loss:  1.887  - Validation loss:  2.232\n",
      "Epoch  26/100 Batch   65/70 - Loss:  1.882  - Validation loss:  2.226\n",
      "Epoch  26/100 Batch   66/70 - Loss:  2.306  - Validation loss:  2.229\n",
      "Epoch  26/100 Batch   67/70 - Loss:  1.899  - Validation loss:  2.235\n",
      "Epoch  26/100 Batch   68/70 - Loss:  2.098  - Validation loss:  2.230\n",
      "Epoch  26/100 Batch   69/70 - Loss:  1.621  - Validation loss:  2.229\n",
      "Epoch  27/100 Batch    1/70 - Loss:  2.076  - Validation loss:  2.244\n",
      "Epoch  27/100 Batch    2/70 - Loss:  1.919  - Validation loss:  2.242\n",
      "Epoch  27/100 Batch    3/70 - Loss:  1.830  - Validation loss:  2.230\n",
      "Epoch  27/100 Batch    4/70 - Loss:  1.940  - Validation loss:  2.226\n",
      "Epoch  27/100 Batch    5/70 - Loss:  1.691  - Validation loss:  2.239\n",
      "Epoch  27/100 Batch    6/70 - Loss:  1.703  - Validation loss:  2.243\n",
      "Epoch  27/100 Batch    7/70 - Loss:  2.193  - Validation loss:  2.226\n",
      "Epoch  27/100 Batch    8/70 - Loss:  1.412  - Validation loss:  2.221\n",
      "Epoch  27/100 Batch    9/70 - Loss:  2.028  - Validation loss:  2.233\n",
      "Epoch  27/100 Batch   10/70 - Loss:  1.549  - Validation loss:  2.245\n",
      "Epoch  27/100 Batch   11/70 - Loss:  1.343  - Validation loss:  2.245\n",
      "Epoch  27/100 Batch   12/70 - Loss:  1.655  - Validation loss:  2.232\n",
      "Epoch  27/100 Batch   13/70 - Loss:  1.785  - Validation loss:  2.220\n",
      "Epoch  27/100 Batch   14/70 - Loss:  1.754  - Validation loss:  2.220\n",
      "Epoch  27/100 Batch   15/70 - Loss:  1.591  - Validation loss:  2.230\n",
      "Epoch  27/100 Batch   16/70 - Loss:  1.747  - Validation loss:  2.231\n",
      "Epoch  27/100 Batch   17/70 - Loss:  1.511  - Validation loss:  2.225\n",
      "Epoch  27/100 Batch   18/70 - Loss:  1.630  - Validation loss:  2.225\n",
      "Epoch  27/100 Batch   19/70 - Loss:  1.822  - Validation loss:  2.229\n",
      "Epoch  27/100 Batch   20/70 - Loss:  1.736  - Validation loss:  2.231\n",
      "Epoch  27/100 Batch   21/70 - Loss:  2.030  - Validation loss:  2.230\n",
      "Epoch  27/100 Batch   22/70 - Loss:  1.477  - Validation loss:  2.225\n",
      "Epoch  27/100 Batch   23/70 - Loss:  1.311  - Validation loss:  2.223\n",
      "Epoch  27/100 Batch   24/70 - Loss:  1.512  - Validation loss:  2.228\n",
      "Epoch  27/100 Batch   25/70 - Loss:  2.141  - Validation loss:  2.229\n",
      "Epoch  27/100 Batch   26/70 - Loss:  1.772  - Validation loss:  2.230\n",
      "Epoch  27/100 Batch   27/70 - Loss:  1.676  - Validation loss:  2.237\n",
      "Epoch  27/100 Batch   28/70 - Loss:  1.860  - Validation loss:  2.241\n",
      "Epoch  27/100 Batch   29/70 - Loss:  1.752  - Validation loss:  2.236\n",
      "Epoch  27/100 Batch   30/70 - Loss:  1.552  - Validation loss:  2.226\n",
      "Epoch  27/100 Batch   31/70 - Loss:  1.584  - Validation loss:  2.216\n",
      "Epoch  27/100 Batch   32/70 - Loss:  1.592  - Validation loss:  2.217\n",
      "Epoch  27/100 Batch   33/70 - Loss:  1.675  - Validation loss:  2.223\n",
      "Epoch  27/100 Batch   34/70 - Loss:  1.830  - Validation loss:  2.222\n",
      "Epoch  27/100 Batch   35/70 - Loss:  1.985  - Validation loss:  2.215\n",
      "Epoch  27/100 Batch   36/70 - Loss:  1.936  - Validation loss:  2.224\n",
      "Epoch  27/100 Batch   37/70 - Loss:  1.762  - Validation loss:  2.234\n",
      "Epoch  27/100 Batch   38/70 - Loss:  1.639  - Validation loss:  2.234\n",
      "Epoch  27/100 Batch   39/70 - Loss:  1.478  - Validation loss:  2.223\n",
      "Epoch  27/100 Batch   40/70 - Loss:  2.160  - Validation loss:  2.214\n",
      "Epoch  27/100 Batch   41/70 - Loss:  2.004  - Validation loss:  2.218\n",
      "Epoch  27/100 Batch   42/70 - Loss:  2.092  - Validation loss:  2.217\n",
      "Epoch  27/100 Batch   43/70 - Loss:  2.242  - Validation loss:  2.210\n",
      "Epoch  27/100 Batch   44/70 - Loss:  1.995  - Validation loss:  2.214\n",
      "Epoch  27/100 Batch   45/70 - Loss:  1.800  - Validation loss:  2.225\n",
      "Epoch  27/100 Batch   46/70 - Loss:  1.737  - Validation loss:  2.230\n",
      "Epoch  27/100 Batch   47/70 - Loss:  1.592  - Validation loss:  2.225\n",
      "Epoch  27/100 Batch   48/70 - Loss:  1.809  - Validation loss:  2.215\n",
      "Epoch  27/100 Batch   49/70 - Loss:  1.765  - Validation loss:  2.210\n",
      "Epoch  27/100 Batch   50/70 - Loss:  1.694  - Validation loss:  2.212\n",
      "Epoch  27/100 Batch   51/70 - Loss:  1.979  - Validation loss:  2.213\n",
      "Epoch  27/100 Batch   52/70 - Loss:  2.170  - Validation loss:  2.210\n",
      "Epoch  27/100 Batch   53/70 - Loss:  1.804  - Validation loss:  2.210\n",
      "Epoch  27/100 Batch   54/70 - Loss:  1.060  - Validation loss:  2.216\n",
      "Epoch  27/100 Batch   55/70 - Loss:  1.389  - Validation loss:  2.222\n",
      "Epoch  27/100 Batch   56/70 - Loss:  1.783  - Validation loss:  2.222\n",
      "Epoch  27/100 Batch   57/70 - Loss:  1.249  - Validation loss:  2.216\n",
      "Epoch  27/100 Batch   58/70 - Loss:  1.386  - Validation loss:  2.214\n",
      "Epoch  27/100 Batch   59/70 - Loss:  1.877  - Validation loss:  2.218\n",
      "Epoch  27/100 Batch   60/70 - Loss:  1.372  - Validation loss:  2.221\n",
      "Epoch  27/100 Batch   61/70 - Loss:  1.389  - Validation loss:  2.217\n",
      "Epoch  27/100 Batch   62/70 - Loss:  2.059  - Validation loss:  2.215\n",
      "Epoch  27/100 Batch   63/70 - Loss:  1.919  - Validation loss:  2.221\n",
      "Epoch  27/100 Batch   64/70 - Loss:  1.863  - Validation loss:  2.226\n",
      "Epoch  27/100 Batch   65/70 - Loss:  1.867  - Validation loss:  2.224\n",
      "Epoch  27/100 Batch   66/70 - Loss:  2.293  - Validation loss:  2.218\n",
      "Epoch  27/100 Batch   67/70 - Loss:  1.881  - Validation loss:  2.214\n",
      "Epoch  27/100 Batch   68/70 - Loss:  2.067  - Validation loss:  2.218\n",
      "Epoch  27/100 Batch   69/70 - Loss:  1.605  - Validation loss:  2.220\n",
      "Epoch  28/100 Batch    1/70 - Loss:  2.054  - Validation loss:  2.219\n",
      "Epoch  28/100 Batch    2/70 - Loss:  1.887  - Validation loss:  2.225\n",
      "Epoch  28/100 Batch    3/70 - Loss:  1.799  - Validation loss:  2.226\n",
      "Epoch  28/100 Batch    4/70 - Loss:  1.923  - Validation loss:  2.218\n",
      "Epoch  28/100 Batch    5/70 - Loss:  1.678  - Validation loss:  2.211\n",
      "Epoch  28/100 Batch    6/70 - Loss:  1.673  - Validation loss:  2.212\n",
      "Epoch  28/100 Batch    7/70 - Loss:  2.152  - Validation loss:  2.216\n",
      "Epoch  28/100 Batch    8/70 - Loss:  1.401  - Validation loss:  2.213\n",
      "Epoch  28/100 Batch    9/70 - Loss:  2.017  - Validation loss:  2.211\n",
      "Epoch  28/100 Batch   10/70 - Loss:  1.532  - Validation loss:  2.217\n",
      "Epoch  28/100 Batch   11/70 - Loss:  1.313  - Validation loss:  2.225\n",
      "Epoch  28/100 Batch   12/70 - Loss:  1.624  - Validation loss:  2.222\n",
      "Epoch  28/100 Batch   13/70 - Loss:  1.761  - Validation loss:  2.212\n",
      "Epoch  28/100 Batch   14/70 - Loss:  1.737  - Validation loss:  2.207\n",
      "Epoch  28/100 Batch   15/70 - Loss:  1.570  - Validation loss:  2.210\n",
      "Epoch  28/100 Batch   16/70 - Loss:  1.721  - Validation loss:  2.213\n",
      "Epoch  28/100 Batch   17/70 - Loss:  1.486  - Validation loss:  2.210\n",
      "Epoch  28/100 Batch   18/70 - Loss:  1.611  - Validation loss:  2.211\n",
      "Epoch  28/100 Batch   19/70 - Loss:  1.801  - Validation loss:  2.220\n",
      "Epoch  28/100 Batch   20/70 - Loss:  1.717  - Validation loss:  2.224\n",
      "Epoch  28/100 Batch   21/70 - Loss:  2.009  - Validation loss:  2.219\n",
      "Epoch  28/100 Batch   22/70 - Loss:  1.453  - Validation loss:  2.210\n",
      "Epoch  28/100 Batch   23/70 - Loss:  1.290  - Validation loss:  2.209\n",
      "Epoch  28/100 Batch   24/70 - Loss:  1.492  - Validation loss:  2.215\n",
      "Epoch  28/100 Batch   25/70 - Loss:  2.114  - Validation loss:  2.215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  28/100 Batch   26/70 - Loss:  1.754  - Validation loss:  2.211\n",
      "Epoch  28/100 Batch   27/70 - Loss:  1.656  - Validation loss:  2.215\n",
      "Epoch  28/100 Batch   28/70 - Loss:  1.834  - Validation loss:  2.223\n",
      "Epoch  28/100 Batch   29/70 - Loss:  1.727  - Validation loss:  2.223\n",
      "Epoch  28/100 Batch   30/70 - Loss:  1.531  - Validation loss:  2.216\n",
      "Epoch  28/100 Batch   31/70 - Loss:  1.564  - Validation loss:  2.208\n",
      "Epoch  28/100 Batch   32/70 - Loss:  1.573  - Validation loss:  2.206\n",
      "Epoch  28/100 Batch   33/70 - Loss:  1.653  - Validation loss:  2.209\n",
      "Epoch  28/100 Batch   34/70 - Loss:  1.805  - Validation loss:  2.210\n",
      "Epoch  28/100 Batch   35/70 - Loss:  1.958  - Validation loss:  2.208\n",
      "Epoch  28/100 Batch   36/70 - Loss:  1.921  - Validation loss:  2.210\n",
      "Epoch  28/100 Batch   37/70 - Loss:  1.746  - Validation loss:  2.217\n",
      "Epoch  28/100 Batch   38/70 - Loss:  1.616  - Validation loss:  2.220\n",
      "Epoch  28/100 Batch   39/70 - Loss:  1.459  - Validation loss:  2.216\n",
      "Epoch  28/100 Batch   40/70 - Loss:  2.142  - Validation loss:  2.209\n",
      "Epoch  28/100 Batch   41/70 - Loss:  1.988  - Validation loss:  2.209\n",
      "Epoch  28/100 Batch   42/70 - Loss:  2.071  - Validation loss:  2.209\n",
      "Epoch  28/100 Batch   43/70 - Loss:  2.220  - Validation loss:  2.204\n",
      "Epoch  28/100 Batch   44/70 - Loss:  1.979  - Validation loss:  2.203\n",
      "Epoch  28/100 Batch   45/70 - Loss:  1.784  - Validation loss:  2.211\n",
      "Epoch  28/100 Batch   46/70 - Loss:  1.720  - Validation loss:  2.219\n",
      "Epoch  28/100 Batch   47/70 - Loss:  1.575  - Validation loss:  2.220\n",
      "Epoch  28/100 Batch   48/70 - Loss:  1.790  - Validation loss:  2.213\n",
      "Epoch  28/100 Batch   49/70 - Loss:  1.750  - Validation loss:  2.206\n",
      "Epoch  28/100 Batch   50/70 - Loss:  1.679  - Validation loss:  2.204\n",
      "Epoch  28/100 Batch   51/70 - Loss:  1.962  - Validation loss:  2.205\n",
      "Epoch  28/100 Batch   52/70 - Loss:  2.148  - Validation loss:  2.204\n",
      "Epoch  28/100 Batch   53/70 - Loss:  1.791  - Validation loss:  2.203\n",
      "Epoch  28/100 Batch   54/70 - Loss:  1.051  - Validation loss:  2.208\n",
      "Epoch  28/100 Batch   55/70 - Loss:  1.375  - Validation loss:  2.216\n",
      "Epoch  28/100 Batch   56/70 - Loss:  1.767  - Validation loss:  2.218\n",
      "Epoch  28/100 Batch   57/70 - Loss:  1.236  - Validation loss:  2.214\n",
      "Epoch  28/100 Batch   58/70 - Loss:  1.375  - Validation loss:  2.210\n",
      "Epoch  28/100 Batch   59/70 - Loss:  1.863  - Validation loss:  2.212\n",
      "Epoch  28/100 Batch   60/70 - Loss:  1.359  - Validation loss:  2.214\n",
      "Epoch  28/100 Batch   61/70 - Loss:  1.374  - Validation loss:  2.212\n",
      "Epoch  28/100 Batch   62/70 - Loss:  2.046  - Validation loss:  2.209\n",
      "Epoch  28/100 Batch   63/70 - Loss:  1.906  - Validation loss:  2.212\n",
      "Epoch  28/100 Batch   64/70 - Loss:  1.849  - Validation loss:  2.216\n",
      "Epoch  28/100 Batch   65/70 - Loss:  1.850  - Validation loss:  2.216\n",
      "Epoch  28/100 Batch   66/70 - Loss:  2.273  - Validation loss:  2.212\n",
      "Epoch  28/100 Batch   67/70 - Loss:  1.866  - Validation loss:  2.209\n",
      "Epoch  28/100 Batch   68/70 - Loss:  2.053  - Validation loss:  2.210\n",
      "Epoch  28/100 Batch   69/70 - Loss:  1.590  - Validation loss:  2.212\n",
      "Epoch  29/100 Batch    1/70 - Loss:  2.036  - Validation loss:  2.212\n",
      "Epoch  29/100 Batch    2/70 - Loss:  1.872  - Validation loss:  2.217\n",
      "Epoch  29/100 Batch    3/70 - Loss:  1.781  - Validation loss:  2.220\n",
      "Epoch  29/100 Batch    4/70 - Loss:  1.904  - Validation loss:  2.214\n",
      "Epoch  29/100 Batch    5/70 - Loss:  1.663  - Validation loss:  2.207\n",
      "Epoch  29/100 Batch    6/70 - Loss:  1.660  - Validation loss:  2.204\n",
      "Epoch  29/100 Batch    7/70 - Loss:  2.135  - Validation loss:  2.206\n",
      "Epoch  29/100 Batch    8/70 - Loss:  1.385  - Validation loss:  2.205\n",
      "Epoch  29/100 Batch    9/70 - Loss:  2.002  - Validation loss:  2.203\n",
      "Epoch  29/100 Batch   10/70 - Loss:  1.520  - Validation loss:  2.208\n",
      "Epoch  29/100 Batch   11/70 - Loss:  1.300  - Validation loss:  2.215\n",
      "Epoch  29/100 Batch   12/70 - Loss:  1.607  - Validation loss:  2.215\n",
      "Epoch  29/100 Batch   13/70 - Loss:  1.743  - Validation loss:  2.207\n",
      "Epoch  29/100 Batch   14/70 - Loss:  1.721  - Validation loss:  2.202\n",
      "Epoch  29/100 Batch   15/70 - Loss:  1.557  - Validation loss:  2.203\n",
      "Epoch  29/100 Batch   16/70 - Loss:  1.704  - Validation loss:  2.205\n",
      "Epoch  29/100 Batch   17/70 - Loss:  1.469  - Validation loss:  2.203\n",
      "Epoch  29/100 Batch   18/70 - Loss:  1.597  - Validation loss:  2.204\n",
      "Epoch  29/100 Batch   19/70 - Loss:  1.787  - Validation loss:  2.211\n",
      "Epoch  29/100 Batch   20/70 - Loss:  1.699  - Validation loss:  2.216\n",
      "Epoch  29/100 Batch   21/70 - Loss:  1.991  - Validation loss:  2.213\n",
      "Epoch  29/100 Batch   22/70 - Loss:  1.439  - Validation loss:  2.205\n",
      "Epoch  29/100 Batch   23/70 - Loss:  1.277  - Validation loss:  2.204\n",
      "Epoch  29/100 Batch   24/70 - Loss:  1.479  - Validation loss:  2.208\n",
      "Epoch  29/100 Batch   25/70 - Loss:  2.093  - Validation loss:  2.207\n",
      "Epoch  29/100 Batch   26/70 - Loss:  1.738  - Validation loss:  2.204\n",
      "Epoch  29/100 Batch   27/70 - Loss:  1.644  - Validation loss:  2.205\n",
      "Epoch  29/100 Batch   28/70 - Loss:  1.819  - Validation loss:  2.210\n",
      "Epoch  29/100 Batch   29/70 - Loss:  1.709  - Validation loss:  2.212\n",
      "Epoch  29/100 Batch   30/70 - Loss:  1.515  - Validation loss:  2.208\n",
      "Epoch  29/100 Batch   31/70 - Loss:  1.548  - Validation loss:  2.203\n",
      "Epoch  29/100 Batch   32/70 - Loss:  1.560  - Validation loss:  2.201\n",
      "Epoch  29/100 Batch   33/70 - Loss:  1.637  - Validation loss:  2.203\n",
      "Epoch  29/100 Batch   34/70 - Loss:  1.788  - Validation loss:  2.203\n",
      "Epoch  29/100 Batch   35/70 - Loss:  1.938  - Validation loss:  2.201\n",
      "Epoch  29/100 Batch   36/70 - Loss:  1.906  - Validation loss:  2.202\n",
      "Epoch  29/100 Batch   37/70 - Loss:  1.733  - Validation loss:  2.209\n",
      "Epoch  29/100 Batch   38/70 - Loss:  1.602  - Validation loss:  2.212\n",
      "Epoch  29/100 Batch   39/70 - Loss:  1.446  - Validation loss:  2.208\n",
      "Epoch  29/100 Batch   40/70 - Loss:  2.126  - Validation loss:  2.202\n",
      "Epoch  29/100 Batch   41/70 - Loss:  1.973  - Validation loss:  2.201\n",
      "Epoch  29/100 Batch   42/70 - Loss:  2.054  - Validation loss:  2.203\n",
      "Epoch  29/100 Batch   43/70 - Loss:  2.204  - Validation loss:  2.200\n",
      "Epoch  29/100 Batch   44/70 - Loss:  1.964  - Validation loss:  2.196\n",
      "Epoch  29/100 Batch   45/70 - Loss:  1.770  - Validation loss:  2.202\n",
      "Epoch  29/100 Batch   46/70 - Loss:  1.705  - Validation loss:  2.212\n",
      "Epoch  29/100 Batch   47/70 - Loss:  1.562  - Validation loss:  2.217\n",
      "Epoch  29/100 Batch   48/70 - Loss:  1.774  - Validation loss:  2.211\n",
      "Epoch  29/100 Batch   49/70 - Loss:  1.737  - Validation loss:  2.202\n",
      "Epoch  29/100 Batch   50/70 - Loss:  1.667  - Validation loss:  2.199\n",
      "Epoch  29/100 Batch   51/70 - Loss:  1.948  - Validation loss:  2.200\n",
      "Epoch  29/100 Batch   52/70 - Loss:  2.131  - Validation loss:  2.199\n",
      "Epoch  29/100 Batch   53/70 - Loss:  1.778  - Validation loss:  2.198\n",
      "Epoch  29/100 Batch   54/70 - Loss:  1.042  - Validation loss:  2.201\n",
      "Epoch  29/100 Batch   55/70 - Loss:  1.365  - Validation loss:  2.210\n",
      "Epoch  29/100 Batch   56/70 - Loss:  1.754  - Validation loss:  2.214\n",
      "Epoch  29/100 Batch   57/70 - Loss:  1.226  - Validation loss:  2.212\n",
      "Epoch  29/100 Batch   58/70 - Loss:  1.366  - Validation loss:  2.208\n",
      "Epoch  29/100 Batch   59/70 - Loss:  1.851  - Validation loss:  2.207\n",
      "Epoch  29/100 Batch   60/70 - Loss:  1.350  - Validation loss:  2.208\n",
      "Epoch  29/100 Batch   61/70 - Loss:  1.362  - Validation loss:  2.208\n",
      "Epoch  29/100 Batch   62/70 - Loss:  2.034  - Validation loss:  2.206\n",
      "Epoch  29/100 Batch   63/70 - Loss:  1.893  - Validation loss:  2.208\n",
      "Epoch  29/100 Batch   64/70 - Loss:  1.838  - Validation loss:  2.210\n",
      "Epoch  29/100 Batch   65/70 - Loss:  1.837  - Validation loss:  2.210\n",
      "Epoch  29/100 Batch   66/70 - Loss:  2.257  - Validation loss:  2.208\n",
      "Epoch  29/100 Batch   67/70 - Loss:  1.853  - Validation loss:  2.205\n",
      "Epoch  29/100 Batch   68/70 - Loss:  2.041  - Validation loss:  2.205\n",
      "Epoch  29/100 Batch   69/70 - Loss:  1.579  - Validation loss:  2.206\n",
      "Epoch  30/100 Batch    1/70 - Loss:  2.020  - Validation loss:  2.207\n",
      "Epoch  30/100 Batch    2/70 - Loss:  1.859  - Validation loss:  2.212\n",
      "Epoch  30/100 Batch    3/70 - Loss:  1.767  - Validation loss:  2.214\n",
      "Epoch  30/100 Batch    4/70 - Loss:  1.889  - Validation loss:  2.211\n",
      "Epoch  30/100 Batch    5/70 - Loss:  1.651  - Validation loss:  2.204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  30/100 Batch    6/70 - Loss:  1.648  - Validation loss:  2.200\n",
      "Epoch  30/100 Batch    7/70 - Loss:  2.122  - Validation loss:  2.199\n",
      "Epoch  30/100 Batch    8/70 - Loss:  1.372  - Validation loss:  2.199\n",
      "Epoch  30/100 Batch    9/70 - Loss:  1.987  - Validation loss:  2.198\n",
      "Epoch  30/100 Batch   10/70 - Loss:  1.509  - Validation loss:  2.202\n",
      "Epoch  30/100 Batch   11/70 - Loss:  1.290  - Validation loss:  2.208\n",
      "Epoch  30/100 Batch   12/70 - Loss:  1.592  - Validation loss:  2.208\n",
      "Epoch  30/100 Batch   13/70 - Loss:  1.728  - Validation loss:  2.203\n",
      "Epoch  30/100 Batch   14/70 - Loss:  1.708  - Validation loss:  2.198\n",
      "Epoch  30/100 Batch   15/70 - Loss:  1.545  - Validation loss:  2.197\n",
      "Epoch  30/100 Batch   16/70 - Loss:  1.691  - Validation loss:  2.199\n",
      "Epoch  30/100 Batch   17/70 - Loss:  1.456  - Validation loss:  2.198\n",
      "Epoch  30/100 Batch   18/70 - Loss:  1.585  - Validation loss:  2.199\n",
      "Epoch  30/100 Batch   19/70 - Loss:  1.775  - Validation loss:  2.204\n",
      "Epoch  30/100 Batch   20/70 - Loss:  1.685  - Validation loss:  2.209\n",
      "Epoch  30/100 Batch   21/70 - Loss:  1.975  - Validation loss:  2.208\n",
      "Epoch  30/100 Batch   22/70 - Loss:  1.427  - Validation loss:  2.202\n",
      "Epoch  30/100 Batch   23/70 - Loss:  1.268  - Validation loss:  2.201\n",
      "Epoch  30/100 Batch   24/70 - Loss:  1.469  - Validation loss:  2.203\n",
      "Epoch  30/100 Batch   25/70 - Loss:  2.076  - Validation loss:  2.203\n",
      "Epoch  30/100 Batch   26/70 - Loss:  1.725  - Validation loss:  2.201\n",
      "Epoch  30/100 Batch   27/70 - Loss:  1.635  - Validation loss:  2.201\n",
      "Epoch  30/100 Batch   28/70 - Loss:  1.808  - Validation loss:  2.203\n",
      "Epoch  30/100 Batch   29/70 - Loss:  1.696  - Validation loss:  2.204\n",
      "Epoch  30/100 Batch   30/70 - Loss:  1.501  - Validation loss:  2.203\n",
      "Epoch  30/100 Batch   31/70 - Loss:  1.535  - Validation loss:  2.200\n",
      "Epoch  30/100 Batch   32/70 - Loss:  1.548  - Validation loss:  2.199\n",
      "Epoch  30/100 Batch   33/70 - Loss:  1.624  - Validation loss:  2.199\n",
      "Epoch  30/100 Batch   34/70 - Loss:  1.775  - Validation loss:  2.197\n",
      "Epoch  30/100 Batch   35/70 - Loss:  1.923  - Validation loss:  2.195\n",
      "Epoch  30/100 Batch   36/70 - Loss:  1.893  - Validation loss:  2.196\n",
      "Epoch  30/100 Batch   37/70 - Loss:  1.721  - Validation loss:  2.202\n",
      "Epoch  30/100 Batch   38/70 - Loss:  1.590  - Validation loss:  2.208\n",
      "Epoch  30/100 Batch   39/70 - Loss:  1.435  - Validation loss:  2.206\n",
      "Epoch  30/100 Batch   40/70 - Loss:  2.114  - Validation loss:  2.198\n",
      "Epoch  30/100 Batch   41/70 - Loss:  1.962  - Validation loss:  2.195\n",
      "Epoch  30/100 Batch   42/70 - Loss:  2.038  - Validation loss:  2.197\n",
      "Epoch  30/100 Batch   43/70 - Loss:  2.190  - Validation loss:  2.196\n",
      "Epoch  30/100 Batch   44/70 - Loss:  1.949  - Validation loss:  2.192\n",
      "Epoch  30/100 Batch   45/70 - Loss:  1.759  - Validation loss:  2.196\n",
      "Epoch  30/100 Batch   46/70 - Loss:  1.692  - Validation loss:  2.206\n",
      "Epoch  30/100 Batch   47/70 - Loss:  1.550  - Validation loss:  2.213\n",
      "Epoch  30/100 Batch   48/70 - Loss:  1.760  - Validation loss:  2.210\n",
      "Epoch  30/100 Batch   49/70 - Loss:  1.725  - Validation loss:  2.200\n",
      "Epoch  30/100 Batch   50/70 - Loss:  1.656  - Validation loss:  2.194\n",
      "Epoch  30/100 Batch   51/70 - Loss:  1.935  - Validation loss:  2.194\n",
      "Epoch  30/100 Batch   52/70 - Loss:  2.114  - Validation loss:  2.194\n",
      "Epoch  30/100 Batch   53/70 - Loss:  1.765  - Validation loss:  2.193\n",
      "Epoch  30/100 Batch   54/70 - Loss:  1.035  - Validation loss:  2.195\n",
      "Epoch  30/100 Batch   55/70 - Loss:  1.356  - Validation loss:  2.202\n",
      "Epoch  30/100 Batch   56/70 - Loss:  1.740  - Validation loss:  2.209\n",
      "Epoch  30/100 Batch   57/70 - Loss:  1.216  - Validation loss:  2.210\n",
      "Epoch  30/100 Batch   58/70 - Loss:  1.356  - Validation loss:  2.208\n",
      "Epoch  30/100 Batch   59/70 - Loss:  1.842  - Validation loss:  2.204\n",
      "Epoch  30/100 Batch   60/70 - Loss:  1.342  - Validation loss:  2.203\n",
      "Epoch  30/100 Batch   61/70 - Loss:  1.351  - Validation loss:  2.202\n",
      "Epoch  30/100 Batch   62/70 - Loss:  2.021  - Validation loss:  2.202\n",
      "Epoch  30/100 Batch   63/70 - Loss:  1.881  - Validation loss:  2.204\n",
      "Epoch  30/100 Batch   64/70 - Loss:  1.829  - Validation loss:  2.205\n",
      "Epoch  30/100 Batch   65/70 - Loss:  1.825  - Validation loss:  2.204\n",
      "Epoch  30/100 Batch   66/70 - Loss:  2.241  - Validation loss:  2.203\n",
      "Epoch  30/100 Batch   67/70 - Loss:  1.840  - Validation loss:  2.202\n",
      "Epoch  30/100 Batch   68/70 - Loss:  2.030  - Validation loss:  2.202\n",
      "Epoch  30/100 Batch   69/70 - Loss:  1.569  - Validation loss:  2.201\n",
      "Epoch  31/100 Batch    1/70 - Loss:  2.005  - Validation loss:  2.203\n",
      "Epoch  31/100 Batch    2/70 - Loss:  1.847  - Validation loss:  2.207\n",
      "Epoch  31/100 Batch    3/70 - Loss:  1.755  - Validation loss:  2.208\n",
      "Epoch  31/100 Batch    4/70 - Loss:  1.876  - Validation loss:  2.206\n",
      "Epoch  31/100 Batch    5/70 - Loss:  1.639  - Validation loss:  2.201\n",
      "Epoch  31/100 Batch    6/70 - Loss:  1.637  - Validation loss:  2.196\n",
      "Epoch  31/100 Batch    7/70 - Loss:  2.109  - Validation loss:  2.194\n",
      "Epoch  31/100 Batch    8/70 - Loss:  1.361  - Validation loss:  2.194\n",
      "Epoch  31/100 Batch    9/70 - Loss:  1.974  - Validation loss:  2.194\n",
      "Epoch  31/100 Batch   10/70 - Loss:  1.499  - Validation loss:  2.196\n",
      "Epoch  31/100 Batch   11/70 - Loss:  1.279  - Validation loss:  2.201\n",
      "Epoch  31/100 Batch   12/70 - Loss:  1.579  - Validation loss:  2.203\n",
      "Epoch  31/100 Batch   13/70 - Loss:  1.714  - Validation loss:  2.200\n",
      "Epoch  31/100 Batch   14/70 - Loss:  1.696  - Validation loss:  2.195\n",
      "Epoch  31/100 Batch   15/70 - Loss:  1.534  - Validation loss:  2.193\n",
      "Epoch  31/100 Batch   16/70 - Loss:  1.678  - Validation loss:  2.194\n",
      "Epoch  31/100 Batch   17/70 - Loss:  1.444  - Validation loss:  2.193\n",
      "Epoch  31/100 Batch   18/70 - Loss:  1.573  - Validation loss:  2.194\n",
      "Epoch  31/100 Batch   19/70 - Loss:  1.763  - Validation loss:  2.198\n",
      "Epoch  31/100 Batch   20/70 - Loss:  1.672  - Validation loss:  2.203\n",
      "Epoch  31/100 Batch   21/70 - Loss:  1.961  - Validation loss:  2.204\n",
      "Epoch  31/100 Batch   22/70 - Loss:  1.416  - Validation loss:  2.201\n",
      "Epoch  31/100 Batch   23/70 - Loss:  1.260  - Validation loss:  2.200\n",
      "Epoch  31/100 Batch   24/70 - Loss:  1.461  - Validation loss:  2.199\n",
      "Epoch  31/100 Batch   25/70 - Loss:  2.062  - Validation loss:  2.198\n",
      "Epoch  31/100 Batch   26/70 - Loss:  1.713  - Validation loss:  2.197\n",
      "Epoch  31/100 Batch   27/70 - Loss:  1.625  - Validation loss:  2.197\n",
      "Epoch  31/100 Batch   28/70 - Loss:  1.796  - Validation loss:  2.198\n",
      "Epoch  31/100 Batch   29/70 - Loss:  1.684  - Validation loss:  2.198\n",
      "Epoch  31/100 Batch   30/70 - Loss:  1.488  - Validation loss:  2.198\n",
      "Epoch  31/100 Batch   31/70 - Loss:  1.523  - Validation loss:  2.198\n",
      "Epoch  31/100 Batch   32/70 - Loss:  1.538  - Validation loss:  2.198\n",
      "Epoch  31/100 Batch   33/70 - Loss:  1.613  - Validation loss:  2.197\n",
      "Epoch  31/100 Batch   34/70 - Loss:  1.763  - Validation loss:  2.194\n",
      "Epoch  31/100 Batch   35/70 - Loss:  1.908  - Validation loss:  2.191\n",
      "Epoch  31/100 Batch   36/70 - Loss:  1.881  - Validation loss:  2.191\n",
      "Epoch  31/100 Batch   37/70 - Loss:  1.712  - Validation loss:  2.195\n",
      "Epoch  31/100 Batch   38/70 - Loss:  1.580  - Validation loss:  2.203\n",
      "Epoch  31/100 Batch   39/70 - Loss:  1.424  - Validation loss:  2.205\n",
      "Epoch  31/100 Batch   40/70 - Loss:  2.102  - Validation loss:  2.198\n",
      "Epoch  31/100 Batch   41/70 - Loss:  1.951  - Validation loss:  2.191\n",
      "Epoch  31/100 Batch   42/70 - Loss:  2.024  - Validation loss:  2.193\n",
      "Epoch  31/100 Batch   43/70 - Loss:  2.177  - Validation loss:  2.194\n",
      "Epoch  31/100 Batch   44/70 - Loss:  1.938  - Validation loss:  2.190\n",
      "Epoch  31/100 Batch   45/70 - Loss:  1.750  - Validation loss:  2.190\n",
      "Epoch  31/100 Batch   46/70 - Loss:  1.681  - Validation loss:  2.200\n",
      "Epoch  31/100 Batch   47/70 - Loss:  1.540  - Validation loss:  2.212\n",
      "Epoch  31/100 Batch   48/70 - Loss:  1.747  - Validation loss:  2.213\n",
      "Epoch  31/100 Batch   49/70 - Loss:  1.715  - Validation loss:  2.202\n",
      "Epoch  31/100 Batch   50/70 - Loss:  1.647  - Validation loss:  2.193\n",
      "Epoch  31/100 Batch   51/70 - Loss:  1.923  - Validation loss:  2.190\n",
      "Epoch  31/100 Batch   52/70 - Loss:  2.100  - Validation loss:  2.191\n",
      "Epoch  31/100 Batch   53/70 - Loss:  1.754  - Validation loss:  2.190\n",
      "Epoch  31/100 Batch   54/70 - Loss:  1.029  - Validation loss:  2.191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  31/100 Batch   55/70 - Loss:  1.348  - Validation loss:  2.196\n",
      "Epoch  31/100 Batch   56/70 - Loss:  1.730  - Validation loss:  2.203\n",
      "Epoch  31/100 Batch   57/70 - Loss:  1.208  - Validation loss:  2.208\n",
      "Epoch  31/100 Batch   58/70 - Loss:  1.346  - Validation loss:  2.211\n",
      "Epoch  31/100 Batch   59/70 - Loss:  1.833  - Validation loss:  2.206\n",
      "Epoch  31/100 Batch   60/70 - Loss:  1.336  - Validation loss:  2.200\n",
      "Epoch  31/100 Batch   61/70 - Loss:  1.342  - Validation loss:  2.197\n",
      "Epoch  31/100 Batch   62/70 - Loss:  2.009  - Validation loss:  2.198\n",
      "Epoch  31/100 Batch   63/70 - Loss:  1.869  - Validation loss:  2.202\n",
      "Epoch  31/100 Batch   64/70 - Loss:  1.821  - Validation loss:  2.203\n",
      "Epoch  31/100 Batch   65/70 - Loss:  1.817  - Validation loss:  2.200\n",
      "Epoch  31/100 Batch   66/70 - Loss:  2.228  - Validation loss:  2.199\n"
     ]
    }
   ],
   "source": [
    "# Split data to training and validation sets\n",
    "train_source = source_letter_ids[batch_size:]\n",
    "train_target = target_letter_ids[batch_size:]\n",
    "valid_source = source_letter_ids[:batch_size]\n",
    "valid_target = target_letter_ids[:batch_size]\n",
    "(valid_targets_batch, valid_sources_batch, valid_targets_lengths, valid_sources_lengths) = \\\n",
    "                  next(get_batches(valid_target, valid_source, batch_size))\n",
    "\n",
    "display_step = 1 # Check training loss after every 20 batches\n",
    "\n",
    "checkpoint = \"./best_model.ckpt\" \n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    for epoch_i in range(1, epochs+1):\n",
    "        for batch_i, (targets_batch, sources_batch, targets_lengths, sources_lengths) in enumerate(\n",
    "                get_batches(train_target, train_source, batch_size)):\n",
    "            \n",
    "            # Training step\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data:sources_batch,\n",
    "                 targets: targets_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: targets_lengths,\n",
    "                 source_sequence_length: sources_lengths})\n",
    "\n",
    "            # Debug message updating us on the status of the training\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                \n",
    "                # Calculate validation cost\n",
    "                validation_loss = sess.run(\n",
    "                [cost],\n",
    "                {input_data: valid_sources_batch,\n",
    "                 targets: valid_targets_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: valid_targets_lengths,\n",
    "                 source_sequence_length: valid_sources_lengths})\n",
    "                \n",
    "                print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}  - Validation loss: {:>6.3f}'\n",
    "                      .format(epoch_i,\n",
    "                              epochs, \n",
    "                              batch_i, \n",
    "                              len(train_source) // batch_size, \n",
    "                              loss, \n",
    "                              validation_loss[0]))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, checkpoint)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def source_to_seq(text):\n",
    "    '''Prepare the text for the model'''\n",
    "    sequence_length = 20\n",
    "    return [source_letter_to_int.get(word, source_letter_to_int[_UNK]) for word in text]+ [source_letter_to_int[_PAD]]*(sequence_length-len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'I usually eat the very large salad.'\n",
    "text = []\n",
    "text.append(basic_tokenizer(input_sentence))\n",
    "text, sample_src_seq_lens = data_to_token_ids(\n",
    "        text, source_letter_to_int,max_seq_len=20 ,normalize_digits=True)\n",
    "\n",
    "checkpoint = \"./best_model.ckpt\"\n",
    "text=text[0]\n",
    "print(text)\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    source_sequence_length = loaded_graph.get_tensor_by_name('source_sequence_length:0')\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "    \n",
    "    #Multiply by batch_size to match the model's input parameters\n",
    "    answer_logits = sess.run(logits, {input_data: [text]*batch_size, \n",
    "                                      target_sequence_length: [len(text)]*batch_size, \n",
    "                                      source_sequence_length: [len(text)]*batch_size})[0] \n",
    "\n",
    "\n",
    "pad = source_letter_to_int[_PAD] \n",
    "\n",
    "print('Original Text:', input_sentence)\n",
    "\n",
    "print('\\nSource')\n",
    "print('  Word Ids:    {}'.format([i for i in text]))\n",
    "print('  Input Words: {}'.format(([source_int_to_letter[i] for i in text])))\n",
    "\n",
    "print('\\nTarget')\n",
    "print('  Word Ids:       {}'.format([i for i in answer_logits if i != pad]))\n",
    "print('  Response Words: {}'.format(([target_int_to_letter[i] for i in answer_logits if i != pad])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "128*51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
