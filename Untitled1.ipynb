{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_PAD = b\"_PAD\"\n",
    "_GO = b\"_GO\"\n",
    "_EOS = b\"_EOS\"\n",
    "_UNK = b\"_UNK\"\n",
    "_START_VOCAB = [_PAD, _GO, _EOS, _UNK]\n",
    "\n",
    "PAD_ID = 0\n",
    "GO_ID = 1\n",
    "EOS_ID = 2\n",
    "UNK_ID = 3\n",
    "\n",
    "_WORD_SPLIT = re.compile(\"([.,!?\\\"':;)(])\")\n",
    "_DIGIT_RE = re.compile(R\"\\d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_tokenizer(sentence):\n",
    "    \"\"\" Split sentence into list of tokens \"\"\"\n",
    "    words = []\n",
    "    for space_separated_item in sentence.strip().split():\n",
    "        words.extend(_WORD_SPLIT.split(space_separated_item))\n",
    "    return [w for w in words if w] # if w removes the \"\"\n",
    "\n",
    "def get_vocab(tokenized, max_vocab_size):\n",
    "    \"\"\"\n",
    "    Get vocab_list, vocab_dict and rev_vocab_dict given the\n",
    "    tokenized sentences.\n",
    "    \"\"\"\n",
    "    # Replace word count\n",
    "    vocab = {}\n",
    "    for sentence in tokenized:\n",
    "        for word in sentence:\n",
    "            if word in vocab:\n",
    "                vocab[word] += 1\n",
    "            else:\n",
    "                vocab[word] = 1\n",
    "    vocab_list = _START_VOCAB + sorted(vocab, key=vocab.get, reverse=True)\n",
    "    if len(vocab_list) > max_vocab_size:\n",
    "        vocab_list = vocab_list[:max_vocab_size]\n",
    "\n",
    "    # Get vocab dict (word -> token) and rev dict (token -> word)\n",
    "    vocab_dict = dict([(x,y) for (y,x) in enumerate(vocab_list)])\n",
    "    rev_vocab_dict = {v: k for k, v in vocab_dict.items()}\n",
    "\n",
    "    return vocab_list, vocab_dict, rev_vocab_dict\n",
    "\n",
    "def sentence_to_token_ids(sentence, vocab_dict, target_lang,\n",
    "    normalize_digits=True):\n",
    "    \"\"\"\n",
    "    Convert a single sentence of words to token ids. If it is the target\n",
    "    language, we will append an EOS token to the end.\n",
    "    \"\"\"\n",
    "    if not normalize_digits:\n",
    "        # replace words not in vocab_dict with UNK_ID\n",
    "        tokens = [vocab_dict.get(w, UNK_ID) for w in sentence]\n",
    "    else:\n",
    "        tokens = [vocab_dict.get(_DIGIT_RE.sub(b\"0\", w), UNK_ID)\n",
    "            for w in sentence]\n",
    "\n",
    "    # Append EOS token if target langauge sentence\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def data_to_token_ids(tokenized, vocab_dict, max_seq_len, normalize_digits=True):\n",
    "    \"\"\"\n",
    "    Convert tokens into ids used vocab_dict and normalize all digits\n",
    "    to 0.\n",
    "    \"\"\"\n",
    "    data_as_tokens = []\n",
    "    seq_lens = []\n",
    "    #max_len = max(len(sentence) for sentence in tokenized) + 1 # +1 for EOS\n",
    "    max_len=max_seq_len+1\n",
    "    for sentence in tokenized:\n",
    "        sentence=sentence[:max_seq_len]\n",
    "        token_ids = sentence_to_token_ids(sentence, vocab_dict, normalize_digits)\n",
    "        # Padding\n",
    "        data_as_tokens.append(token_ids + [PAD_ID]*(max_len - len(token_ids)))\n",
    "        # Store original sequence length\n",
    "        seq_lens.append(len(token_ids))\n",
    "\n",
    "    return np.array(data_as_tokens), np.array(seq_lens)\n",
    "\n",
    "def process_data(datafile, max_vocab_size,max_seq_len):\n",
    "    \"\"\"\n",
    "    Read the sentences from our datafiles.\n",
    "    \"\"\"\n",
    "    with open(datafile, 'rb') as f:\n",
    "        sentences = pickle.load(f)\n",
    "\n",
    "    # Split into tokens\n",
    "    tokenized = []\n",
    "    for i in range(len(sentences)):\n",
    "        tokenized.append(basic_tokenizer(sentences[i]))\n",
    "\n",
    "    # Get vocab information\n",
    "    vocab_list, vocab_dict, rev_vocab_dict = get_vocab(tokenized,\n",
    "        max_vocab_size)\n",
    "\n",
    "    # Convert data to token ids\n",
    "    data_as_tokens, seq_lens = data_to_token_ids(tokenized, vocab_dict, max_seq_len,normalize_digits=True)\n",
    "\n",
    "    return data_as_tokens, seq_lens, vocab_dict, rev_vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_token_ids, tar_seq_lens, tar_vocab_dict, tar_rev_vocab_dict = \\\n",
    "        process_data('oliver_twist/original.p', max_vocab_size=8000,max_seq_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_token_ids = np.zeros(tar_token_ids.shape,dtype=np.int)\n",
    "src_seq_lens=tar_seq_lens.copy()\n",
    "\n",
    "for x in range(tar_token_ids.shape[0]):\n",
    "    for y in range(0, tar_token_ids.shape[1]):\n",
    "        if tar_token_ids[x, y]==6 or tar_token_ids[x, y]==11:\n",
    "            src_token_ids[x,y]=6 if random.random()<0.5 else 11\n",
    "        else:\n",
    "            src_token_ids[x,y]=tar_token_ids[x,y]\n",
    "    tar_token_ids[x,tar_seq_lens[x]]=EOS_ID\n",
    "    tar_seq_lens[x]+=1\n",
    "\n",
    "src_vocab_dict, src_rev_vocab_dict=tar_vocab_dict, tar_rev_vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(en_token_ids, sp_token_ids,\n",
    "    en_seq_lens, sp_seq_len, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Split the into train and validation sets.\n",
    "    \"\"\"\n",
    "\n",
    "    decoder_inputs = []\n",
    "    targets = []\n",
    "    # Add go token to decoder inputs and create targets\n",
    "    for sentence in sp_token_ids:\n",
    "        decoder_inputs.append(np.array([GO_ID] + list(sentence)))\n",
    "        targets.append(np.array(([GO_ID] + list(sentence))[1:] + [0]))\n",
    "\n",
    "    sp_token_ids = np.array(decoder_inputs)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    # Splitting index\n",
    "    last_train_index = int(0.8*len(en_token_ids))\n",
    "\n",
    "    train_encoder_inputs = en_token_ids[:last_train_index]\n",
    "    train_decoder_inputs = sp_token_ids[:last_train_index]\n",
    "    train_targets = targets[:last_train_index]\n",
    "    train_en_seq_lens = en_seq_lens[:last_train_index]\n",
    "    train_sp_seq_len = sp_seq_len[:last_train_index]\n",
    "\n",
    "    valid_encoder_inputs = en_token_ids[last_train_index:]\n",
    "    valid_decoder_inputs = sp_token_ids[last_train_index:]\n",
    "    valid_targets = targets[last_train_index:]\n",
    "    valid_en_seq_lens = en_seq_lens[last_train_index:]\n",
    "    valid_sp_seq_len = sp_seq_len[last_train_index:]\n",
    "\n",
    "    print(\"%i training samples and %i validations samples\" % (\n",
    "        len(train_encoder_inputs), len(valid_encoder_inputs)))\n",
    "\n",
    "    return train_encoder_inputs, train_decoder_inputs, train_targets, \\\n",
    "        train_en_seq_lens, train_sp_seq_len, \\\n",
    "        valid_encoder_inputs, valid_decoder_inputs, valid_targets, \\\n",
    "        valid_en_seq_lens, valid_sp_seq_len\n",
    "\n",
    "def generate_epoch(encoder_inputs, decoder_inputs, targets, en_seq_lens, sp_seq_lens,\n",
    "    num_epochs, batch_size):\n",
    "\n",
    "    for epoch_num in range(num_epochs):\n",
    "        yield generate_batch(encoder_inputs, decoder_inputs, targets,\n",
    "            en_seq_lens, sp_seq_lens, batch_size)\n",
    "\n",
    "def generate_batch(encoder_inputs, decoder_inputs, targets,\n",
    "    en_seq_lens, sp_seq_lens, batch_size):\n",
    "\n",
    "    data_size = len(encoder_inputs)\n",
    "\n",
    "    num_batches = (data_size // batch_size)\n",
    "    for batch_num in range(num_batches):\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "\n",
    "        yield encoder_inputs[start_index:end_index], \\\n",
    "            decoder_inputs[start_index:end_index], \\\n",
    "            targets[start_index:end_index], \\\n",
    "            en_seq_lens[start_index:end_index], \\\n",
    "            sp_seq_lens[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rnn_cell(FLAGS, dropout, scope):\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        # Get the cell type\n",
    "        if FLAGS.rnn_unit == 'rnn':\n",
    "            rnn_cell_type = tf.nn.rnn_cell.BasicRNNCell\n",
    "        elif FLAGS.rnn_unit == 'gru':\n",
    "            rnn_cell_type = tf.nn.rnn_cell.GRUCell\n",
    "        elif FLAGS.rnn_unit == 'lstm':\n",
    "            rnn_cell_type = tf.nn.rnn_cell.BasicLSTMCell\n",
    "        else:\n",
    "            raise Exception(\"Choose a valid RNN unit type.\")\n",
    "\n",
    "        # Single cell\n",
    "        single_cell = rnn_cell_type(FLAGS.num_hidden_units)\n",
    "\n",
    "        # Dropout\n",
    "        single_cell = tf.nn.rnn_cell.DropoutWrapper(single_cell,\n",
    "            output_keep_prob=1-dropout)\n",
    "\n",
    "        # Each state as one cell\n",
    "        stacked_cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "            [single_cell] * FLAGS.num_layers)\n",
    "\n",
    "    return stacked_cell\n",
    "\n",
    "def rnn_inputs(FLAGS, input_data, vocab_size, scope):\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=True):\n",
    "        W_input = tf.get_variable(\"W_input\",\n",
    "            [vocab_size, FLAGS.num_hidden_units])\n",
    "\n",
    "    # embeddings will be shape [input_data dimensions, num_hidden units]\n",
    "    embeddings = tf.nn.embedding_lookup(W_input, input_data)\n",
    "    return embeddings\n",
    "\n",
    "def rnn_softmax(FLAGS, outputs, scope):\n",
    "    with tf.variable_scope(scope, reuse=True):\n",
    "        W_softmax = tf.get_variable(\"W_softmax\",\n",
    "            [FLAGS.num_hidden_units, FLAGS.tar_vocab_size])\n",
    "        b_softmax = tf.get_variable(\"b_softmax\", [FLAGS.tar_vocab_size])\n",
    "\n",
    "    logits = tf.matmul(outputs, W_softmax) + b_softmax\n",
    "    return logits\n",
    "\n",
    "class model(object):\n",
    "\n",
    "    def __init__(self, FLAGS):\n",
    "\n",
    "        # Placeholders\n",
    "        self.encoder_inputs = tf.placeholder(tf.int32, shape=[None, None],\n",
    "            name='encoder_inputs')\n",
    "        self.decoder_inputs = tf.placeholder(tf.int32, shape=[None, None],\n",
    "            name='decoder_inputs')\n",
    "        self.targets = tf.placeholder(tf.int32, shape=[None, None],\n",
    "            name='targets')\n",
    "        self.src_seq_lens = tf.placeholder(tf.int32, shape=[None, ],\n",
    "            name=\"src_seq_lens\")\n",
    "        self.tar_seq_lens = tf.placeholder(tf.int32, shape=[None, ],\n",
    "            name=\"tar_seq_lens\")\n",
    "        self.dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "        with tf.variable_scope('encoder') as scope:\n",
    "\n",
    "            # Encoder RNN cell\n",
    "            self.encoder_stacked_cell = rnn_cell(FLAGS, self.dropout,\n",
    "                scope=scope)\n",
    "\n",
    "            # Embed encoder inputs\n",
    "            W_input = tf.get_variable(\"W_input\",\n",
    "                [FLAGS.src_vocab_size, FLAGS.num_hidden_units])\n",
    "            self.embedded_encoder_inputs = rnn_inputs(FLAGS,\n",
    "                self.encoder_inputs, FLAGS.src_vocab_size, scope=scope)\n",
    "            #initial_state = encoder_stacked_cell.zero_state(FLAGS.batch_size, tf.float32)\n",
    "\n",
    "            # Outputs from encoder RNN\n",
    "            self.all_encoder_outputs, self.encoder_state = tf.nn.dynamic_rnn(\n",
    "                cell=self.encoder_stacked_cell,\n",
    "                inputs=self.embedded_encoder_inputs,\n",
    "                sequence_length=self.src_seq_lens, time_major=False,\n",
    "                dtype=tf.float32)\n",
    "\n",
    "        '''\n",
    "        # Convert to list of tensors\n",
    "        self.encoder_outputs = tf.unpack(self.all_outputs, axis=0) # annotations\n",
    "        self.encoder_state = tf.unpack(self.state, axis=0)\n",
    "\n",
    "        # First calculate a concatenation of encoder outputs to put attention on.\n",
    "        self.top_states = [tf.reshape(e, [-1, 1,\n",
    "            self.stacked_cell.output_size]) for e in self.encoder_outputs]\n",
    "        self.attention_states = tf.concat(1, self.top_states)\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        # Decoder (use last relevant state from encoder as initial state)\n",
    "        self.initial_decoder_state = self.encoder_state[0]\n",
    "\n",
    "        '''\n",
    "\n",
    "        with tf.variable_scope('decoder') as scope:\n",
    "\n",
    "            # Initial state is last relevant state from encoder\n",
    "            self.decoder_initial_state = self.encoder_state\n",
    "\n",
    "            # Decoder RNN cell\n",
    "            self.decoder_stacked_cell = rnn_cell(FLAGS, self.dropout,\n",
    "                scope=scope)\n",
    "\n",
    "            # Embed decoder RNN inputs\n",
    "            W_input = tf.get_variable(\"W_input\",\n",
    "                [FLAGS.tar_vocab_size, FLAGS.num_hidden_units])\n",
    "            self.embedded_decoder_inputs = rnn_inputs(FLAGS, self.decoder_inputs,\n",
    "                FLAGS.tar_vocab_size, scope=scope)\n",
    "\n",
    "            # Outputs from encoder RNN\n",
    "            self.all_decoder_outputs, self.decoder_state = tf.nn.dynamic_rnn(\n",
    "                cell=self.decoder_stacked_cell,\n",
    "                inputs=self.embedded_decoder_inputs,\n",
    "                sequence_length=self.tar_seq_lens, time_major=False,\n",
    "                initial_state=self.decoder_initial_state)\n",
    "\n",
    "            # Softmax on decoder RNN outputs\n",
    "            W_softmax = tf.get_variable(\"W_softmax\",\n",
    "                [FLAGS.num_hidden_units, FLAGS.tar_vocab_size])\n",
    "            b_softmax = tf.get_variable(\"b_softmax\", [FLAGS.tar_vocab_size])\n",
    "\n",
    "            # Logits\n",
    "            self.decoder_outputs_flat = tf.reshape(self.all_decoder_outputs,\n",
    "                [-1, FLAGS.num_hidden_units])\n",
    "            self.logits_flat = rnn_softmax(FLAGS, self.decoder_outputs_flat,\n",
    "                scope=scope)\n",
    "\n",
    "            # Loss with masking\n",
    "            targets_flat = tf.reshape(self.targets, [-1])\n",
    "            losses_flat = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits=self.logits_flat, labels=targets_flat)\n",
    "            mask = tf.sign(tf.to_float(targets_flat))\n",
    "            masked_losses = mask * losses_flat\n",
    "            masked_losses = tf.reshape(masked_losses,  tf.shape(self.targets))\n",
    "            self.loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(masked_losses, reduction_indices=1))\n",
    "\n",
    "        # Optimization\n",
    "        self.lr = tf.Variable(0.0, trainable=False)\n",
    "        trainable_vars = tf.trainable_variables()\n",
    "        # clip the gradient to avoid vanishing or blowing up gradients\n",
    "        grads, _ = tf.clip_by_global_norm(\n",
    "            tf.gradients(self.loss, trainable_vars), FLAGS.max_gradient_norm)\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_optimizer = optimizer.apply_gradients(\n",
    "            zip(grads, trainable_vars))\n",
    "\n",
    "\n",
    "    def step(self, sess, FLAGS, batch_encoder_inputs, batch_decoder_inputs,\n",
    "        batch_targets, batch_en_seq_lens, batch_sp_seq_lens, dropout):\n",
    "\n",
    "        input_feed = {self.encoder_inputs: batch_encoder_inputs,\n",
    "            self.decoder_inputs: batch_decoder_inputs,\n",
    "            self.targets: batch_targets,\n",
    "            self.src_seq_lens: batch_en_seq_lens,\n",
    "            self.tar_seq_lens: batch_sp_seq_lens,\n",
    "            self.dropout: dropout}\n",
    "        output_feed = [self.loss, self.train_optimizer]\n",
    "        outputs = sess.run(output_feed, input_feed)\n",
    "\n",
    "        return outputs[0], outputs[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parameters(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Holds all the parameters for NMT.\n",
    "        \"\"\"\n",
    "\n",
    "        self.max_src_vocab_size = 8000\n",
    "        self.max_tar_vocab_size = 8000\n",
    "\n",
    "        self.num_epochs = 1000\n",
    "        self.batch_size = 256\n",
    "\n",
    "        self.rnn_unit = 'gru'\n",
    "        self.num_hidden_units = 500\n",
    "        self.num_layers = 1\n",
    "        self.dropout = 0.5\n",
    "        self.learning_rate = 1e-3\n",
    "        self.learning_rate_decay_factor = 0.99\n",
    "        self.max_gradient_norm = 5.0\n",
    "\n",
    "def create_model(sess, FLAGS):\n",
    "\n",
    "    tf_model = model(FLAGS)\n",
    "    print(\"Created a new model\")\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    return tf_model\n",
    "\n",
    "def train(FLAGS):\n",
    "\n",
    "\n",
    "    # Split into train and validation sets\n",
    "    train_encoder_inputs, train_decoder_inputs, train_targets, \\\n",
    "        train_src_seq_lens, train_tar_seq_lens, \\\n",
    "        valid_encoder_inputs, valid_decoder_inputs, valid_targets, \\\n",
    "        valid_src_seq_lens, valid_tar_seq_len = \\\n",
    "        split_data(src_token_ids, tar_token_ids, src_seq_lens, tar_seq_lens,\n",
    "            train_ratio=0.8)\n",
    "\n",
    "    # Update parameters\n",
    "    FLAGS.src_vocab_size = len(src_vocab_dict)\n",
    "    FLAGS.tar_vocab_size = len(tar_vocab_dict)\n",
    "\n",
    "    # Start session\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Create new model or load old one\n",
    "        model = create_model(sess, FLAGS)\n",
    "\n",
    "        # Training begins\n",
    "        losses = []\n",
    "        for epoch_num, epoch in enumerate(generate_epoch(train_encoder_inputs,\n",
    "            train_decoder_inputs, train_targets,\n",
    "            train_src_seq_lens, train_tar_seq_lens,\n",
    "            FLAGS.num_epochs, FLAGS.batch_size)):\n",
    "\n",
    "            print(\"EPOCH: %i\" % (epoch_num))\n",
    "            # Decay learning rate\n",
    "            sess.run(tf.assign(model.lr, FLAGS.learning_rate * \\\n",
    "                (FLAGS.learning_rate_decay_factor ** epoch_num)))\n",
    "\n",
    "            batch_loss = []\n",
    "\n",
    "            for batch_num, (batch_encoder_inputs, batch_decoder_inputs,\n",
    "                batch_targets, batch_en_seq_lens,\n",
    "                batch_sp_seq_lens) in enumerate(epoch):\n",
    "\n",
    "                loss, _ = model.step(sess, FLAGS,\n",
    "                    batch_encoder_inputs, batch_decoder_inputs, batch_targets,\n",
    "                    batch_en_seq_lens, batch_sp_seq_lens,\n",
    "                    FLAGS.dropout)\n",
    "\n",
    "                batch_loss.append(loss)\n",
    "\n",
    "            losses.append(np.mean(batch_loss))\n",
    "\n",
    "        plt.plot(losses, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7303 training samples and 1826 validations samples\n",
      "Created a new model\n",
      "WARNING:tensorflow:From C:\\Users\\ygao\\Anaconda3\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "EPOCH: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-578021a88470>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mFLAGS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-cc7a593f17c5>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(FLAGS)\u001b[0m\n\u001b[0;32m     65\u001b[0m                     \u001b[0mbatch_encoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_decoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[0mbatch_en_seq_lens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sp_seq_lens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                     FLAGS.dropout)\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-5087ecd859a6>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, sess, FLAGS, batch_encoder_inputs, batch_decoder_inputs, batch_targets, batch_en_seq_lens, batch_sp_seq_lens, dropout)\u001b[0m\n\u001b[0;32m    166\u001b[0m             self.dropout: dropout}\n\u001b[0;32m    167\u001b[0m         \u001b[0moutput_feed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_optimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_feed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "FLAGS = parameters()\n",
    "train(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
